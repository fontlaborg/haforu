Project Structure:
ğŸ“ haforu
â”œâ”€â”€ ğŸ“ .github
â”‚   â””â”€â”€ ğŸ“ workflows
â”‚       â”œâ”€â”€ ğŸ“„ ci.yml
â”‚       â””â”€â”€ ğŸ“„ release.yml
â”œâ”€â”€ ğŸ“ benches
â”‚   â””â”€â”€ ğŸ“„ cli.rs
â”œâ”€â”€ ğŸ“ docs
â”‚   â”œâ”€â”€ ğŸ“„ CLI-USAGE.md
â”‚   â””â”€â”€ ğŸ“„ REPOSITORY.md
â”œâ”€â”€ ğŸ“ examples
â”‚   â”œâ”€â”€ ğŸ“ python
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ batch_demo.py
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ error_handling_demo.py
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ metrics_demo.py
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ numpy_demo.py
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ streaming_demo.py
â”‚   â”‚   â””â”€â”€ ğŸ“„ varsweep_demo.py
â”‚   â””â”€â”€ ğŸ“„ smoke_test.rs
â”œâ”€â”€ ğŸ“ issues
â”œâ”€â”€ ğŸ“ python
â”‚   â”œâ”€â”€ ğŸ“ haforu
â”‚   â””â”€â”€ ğŸ“ tests
â”‚       â”œâ”€â”€ ğŸ“„ test_batch.py
â”‚       â”œâ”€â”€ ğŸ“„ test_errors.py
â”‚       â”œâ”€â”€ ğŸ“„ test_numpy.py
â”‚       â””â”€â”€ ğŸ“„ test_streaming.py
â”œâ”€â”€ ğŸ“ reference
â”œâ”€â”€ ğŸ“ scripts
â”‚   â”œâ”€â”€ ğŸ“„ batch_smoke.sh
â”‚   â”œâ”€â”€ ğŸ“„ build.sh
â”‚   â”œâ”€â”€ ğŸ“„ jobs_smoke.jsonl
â”‚   â”œâ”€â”€ ğŸ“„ profile-cli.sh
â”‚   â”œâ”€â”€ ğŸ“„ regression-test.sh
â”‚   â”œâ”€â”€ ğŸ“„ run.sh
â”‚   â”œâ”€â”€ ğŸ“„ sync-version.sh
â”‚   â””â”€â”€ ğŸ“„ test-cli-parity.sh
â”œâ”€â”€ ğŸ“ src
â”‚   â”œâ”€â”€ ğŸ“ python
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ batch.rs
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ errors.rs
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ image_ops.rs
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ mod.rs
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ streaming.rs
â”‚   â”‚   â””â”€â”€ ğŸ“„ types.rs
â”‚   â”œâ”€â”€ ğŸ“„ batch.rs
â”‚   â”œâ”€â”€ ğŸ“„ bufpool.rs
â”‚   â”œâ”€â”€ ğŸ“„ cache.rs
â”‚   â”œâ”€â”€ ğŸ“„ error.rs
â”‚   â”œâ”€â”€ ğŸ“„ fonts.rs
â”‚   â”œâ”€â”€ ğŸ“„ image_ops.rs
â”‚   â”œâ”€â”€ ğŸ“„ input.rs
â”‚   â”œâ”€â”€ ğŸ“„ lib.rs
â”‚   â”œâ”€â”€ ğŸ“„ main.rs
â”‚   â”œâ”€â”€ ğŸ“„ output.rs
â”‚   â”œâ”€â”€ ğŸ“„ render.rs
â”‚   â”œâ”€â”€ ğŸ“„ security.rs
â”‚   â”œâ”€â”€ ğŸ“„ shaping.rs
â”‚   â””â”€â”€ ğŸ“„ varsweep.rs
â”œâ”€â”€ ğŸ“ target
â”‚   â”œâ”€â”€ ğŸ“ debug
â”‚   â”‚   â”œâ”€â”€ ğŸ“ deps
â”‚   â”‚   â”œâ”€â”€ ğŸ“ examples
â”‚   â”‚   â””â”€â”€ ğŸ“ incremental
â”‚   â”‚       â”œâ”€â”€ ğŸ“ cli_stats-34uwdyqqhe43m
â”‚   â”‚       â”‚   â””â”€â”€ ğŸ“ s-hczqpc21bb-07yzz83-4dypcdwvvzkv3pi6ljqpqoj7k
â”‚   â”‚       â”œâ”€â”€ ğŸ“ haforu-08zf1nnuqulfd
â”‚   â”‚       â”‚   â””â”€â”€ ğŸ“ s-hczqpb3fek-14mmksn-bcosaf1zdsh6ew39daoxl340y
â”‚   â”‚       â”œâ”€â”€ ğŸ“ haforu-0rbv9x69y580h
â”‚   â”‚       â”‚   â””â”€â”€ ğŸ“ s-hczg4b7xcj-1pd759l-aioxgobbvymw7zkgxdklpnn9p
â”‚   â”‚       â”œâ”€â”€ ğŸ“ haforu-1gfyf1h42fl5j
â”‚   â”‚       â”‚   â””â”€â”€ ğŸ“ s-hczg4c2apk-1807kfv-76hjdokiix5z0ou4o2n04mdps
â”‚   â”‚       â”œâ”€â”€ ğŸ“ haforu-1lg919h4gfvc5
â”‚   â”‚       â”‚   â””â”€â”€ ğŸ“ s-hczs408aiz-12fcawo-2czwaydl1zfjayct64xy3ooc8
â”‚   â”‚       â”œâ”€â”€ ğŸ“ haforu-2bk6jiyvnoozg
â”‚   â”‚       â”‚   â””â”€â”€ ğŸ“ s-hczqpb3eve-0pmv54u-cb4fel52mw8xnz6x87xbrsieh
â”‚   â”‚       â”œâ”€â”€ ğŸ“ haforu-2kxd8htbh9i7m
â”‚   â”‚       â”‚   â””â”€â”€ ğŸ“ s-hczqpc22ji-0t8c96j-8bivgdz3hujwlvcqyshrkvwdf
â”‚   â”‚       â”œâ”€â”€ ğŸ“ haforu-2qf2tmg8datww
â”‚   â”‚       â”‚   â””â”€â”€ ğŸ“ s-hczqpc2164-1t64bux-6q9shwaymm4btahxtro9ehmlx
â”‚   â”‚       â””â”€â”€ ğŸ“ smoke_test-1l1n0kvfmtt2i
â”‚   â”‚           â””â”€â”€ ğŸ“ s-hczqpc221t-0spqxt4-9rxk15u9rzj8a9w7bmun9v92j
â”‚   â”œâ”€â”€ ğŸ“ doc
â”‚   â”‚   â”œâ”€â”€ ğŸ“ haforu
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“ batch
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“ error
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“ fonts
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“ output
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“ render
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“ security
â”‚   â”‚   â”‚   â””â”€â”€ ğŸ“ shaping
â”‚   â”‚   â”œâ”€â”€ ğŸ“ search.index
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“ alias
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“ crateNames
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“ desc
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“ entry
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“ function
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“ generic_inverted_index
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“ name
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“ normalizedName
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“ path
â”‚   â”‚   â”‚   â””â”€â”€ ğŸ“ type
â”‚   â”‚   â”œâ”€â”€ ğŸ“ skrifa
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“ attribute
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“ charmap
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“ color
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ ğŸ“ transform
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“ font
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“ instance
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“ metrics
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“ outline
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“ autohint
â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ ğŸ“ instance
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“ error
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“ glyf
â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ ğŸ“ hint
â”‚   â”‚   â”‚   â”‚   â”‚       â””â”€â”€ ğŸ“ error
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“ hint
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“ path
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ ğŸ“ pen
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“ patchmap
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“ prelude
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“ provider
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“ setting
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“ string
â”‚   â”‚   â”‚   â””â”€â”€ ğŸ“ variation
â”‚   â”‚   â”œâ”€â”€ ğŸ“ src
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“ haforu
â”‚   â”‚   â”‚   â””â”€â”€ ğŸ“ skrifa
â”‚   â”‚   â”‚       â”œâ”€â”€ ğŸ“ color
â”‚   â”‚   â”‚       â””â”€â”€ ğŸ“ outline
â”‚   â”‚   â”‚           â”œâ”€â”€ ğŸ“ autohint
â”‚   â”‚   â”‚           â”‚   â””â”€â”€ ğŸ“ latin
â”‚   â”‚   â”‚           â”œâ”€â”€ ğŸ“ cff
â”‚   â”‚   â”‚           â””â”€â”€ ğŸ“ glyf
â”‚   â”‚   â”‚               â””â”€â”€ ğŸ“ hint
â”‚   â”‚   â”‚                   â””â”€â”€ ğŸ“ engine
â”‚   â”‚   â”œâ”€â”€ ğŸ“ static.files
â”‚   â”‚   â”œâ”€â”€ ğŸ“ trait.impl
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“ core
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“ clone
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“ cmp
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“ convert
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“ default
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“ error
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“ fmt
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“ hash
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“ iter
â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ ğŸ“ traits
â”‚   â”‚   â”‚   â”‚   â”‚       â”œâ”€â”€ ğŸ“ collect
â”‚   â”‚   â”‚   â”‚   â”‚       â””â”€â”€ ğŸ“ iterator
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“ marker
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“ ops
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“ arith
â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ ğŸ“ deref
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ ğŸ“ panic
â”‚   â”‚   â”‚   â”‚       â””â”€â”€ ğŸ“ unwind_safe
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“ serde_core
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“ de
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ ğŸ“ ser
â”‚   â”‚   â”‚   â””â”€â”€ ğŸ“ skrifa
â”‚   â”‚   â”‚       â”œâ”€â”€ ğŸ“ outline
â”‚   â”‚   â”‚       â”‚   â””â”€â”€ ğŸ“ pen
â”‚   â”‚   â”‚       â””â”€â”€ ğŸ“ provider
â”‚   â”‚   â””â”€â”€ ğŸ“ type.impl
â”‚   â”‚       â”œâ”€â”€ ğŸ“ core
â”‚   â”‚       â”‚   â””â”€â”€ ğŸ“ result
â”‚   â”‚       â”œâ”€â”€ ğŸ“ font_types
â”‚   â”‚       â”‚   â”œâ”€â”€ ğŸ“ bbox
â”‚   â”‚       â”‚   â””â”€â”€ ğŸ“ fixed
â”‚   â”‚       â””â”€â”€ ğŸ“ skrifa
â”‚   â”‚           â””â”€â”€ ğŸ“ setting
â”‚   â”œâ”€â”€ ğŸ“ maturin
â”‚   â”œâ”€â”€ ğŸ“ release
â”‚   â”‚   â”œâ”€â”€ ğŸ“ deps
â”‚   â”‚   â”œâ”€â”€ ğŸ“ examples
â”‚   â”‚   â””â”€â”€ ğŸ“ incremental
â”‚   â”‚       â”œâ”€â”€ ğŸ“ cli-2osw21mn0ve1l
â”‚   â”‚       â”‚   â””â”€â”€ ğŸ“ s-hczg7kumom-0fokd5f-7tqw0f5unvu6hu34iwueo9i0q
â”‚   â”‚       â”œâ”€â”€ ğŸ“ cli_stats-3uyvfb36nevlg
â”‚   â”‚       â”‚   â””â”€â”€ ğŸ“ s-hczsgz8yaz-1ghvgej-26yeaw79rr1wn09pfgfo0ybek
â”‚   â”‚       â”œâ”€â”€ ğŸ“ haforu-0q8n9rcgm0cpc
â”‚   â”‚       â”‚   â””â”€â”€ ğŸ“ s-hczsghg1t6-1wlnzqm-d4d3mla3j69erbb27pgxvarqy
â”‚   â”‚       â”œâ”€â”€ ğŸ“ haforu-165x78hkw2rho
â”‚   â”‚       â”‚   â””â”€â”€ ğŸ“ s-hczs6yz4vg-0t9wcdv-3nj9gth1w5cedgmkd0zk13ohb
â”‚   â”‚       â”œâ”€â”€ ğŸ“ haforu-16g4lvxg9q5ay
â”‚   â”‚       â”‚   â””â”€â”€ ğŸ“ s-hczrczc5a8-0geu15r-3dtefu4euswalkzt3mbn2098x
â”‚   â”‚       â”œâ”€â”€ ğŸ“ haforu-1drx57gxmo9xw
â”‚   â”‚       â”‚   â””â”€â”€ ğŸ“ s-hczsozesxb-161kvzu-9oc2rxoexefgtf8ko5beianqo
â”‚   â”‚       â”œâ”€â”€ ğŸ“ haforu-1j4j0i4xwcba8
â”‚   â”‚       â”‚   â””â”€â”€ ğŸ“ s-hczsgmk6fk-0zycvjs-58grijse25vl6j9f9erfvw0eu
â”‚   â”‚       â”œâ”€â”€ ğŸ“ haforu-1l12g9es5z0a7
â”‚   â”‚       â”‚   â””â”€â”€ ğŸ“ s-hczg7krw75-1d5p5tn-b4ba0092v6nvvl7pwbch3o1ds
â”‚   â”‚       â”œâ”€â”€ ğŸ“ haforu-1vjcwkp54ay0f
â”‚   â”‚       â”‚   â””â”€â”€ ğŸ“ s-hd0ivrr9s4-03wo7q9-cgn6bsbvaq4u7al9ppercpb43
â”‚   â”‚       â”œâ”€â”€ ğŸ“ haforu-27m2q2j5boqkh
â”‚   â”‚       â”‚   â””â”€â”€ ğŸ“ s-hczsl51zmi-0o2xufx-2v7qft8cdnksrnq3a5i19dsvn
â”‚   â”‚       â”œâ”€â”€ ğŸ“ haforu-27p0lf0y0l8tw
â”‚   â”‚       â”‚   â””â”€â”€ ğŸ“ s-hczsa4k3p3-0cuihcq-91xpruyf4lab6cs0izndk2se4
â”‚   â”‚       â”œâ”€â”€ ğŸ“ haforu-28w7b28sz541f
â”‚   â”‚       â”‚   â””â”€â”€ ğŸ“ s-hczsgz8yq5-0u4jfr0-2st87uhbr274dmgqaysqfm6ub
â”‚   â”‚       â”œâ”€â”€ ğŸ“ haforu-29d0sq4sgt3n7
â”‚   â”‚       â”‚   â””â”€â”€ ğŸ“ s-hczskt0kjf-1pgaydb-0ma8bjpahdestdbm296bnkcts
â”‚   â”‚       â”œâ”€â”€ ğŸ“ haforu-2df4uopghd3ob
â”‚   â”‚       â”‚   â””â”€â”€ ğŸ“ s-hd05pz99bt-1nuu42t-acuhqqx5x63ged8u1brow1r3o
â”‚   â”‚       â”œâ”€â”€ ğŸ“ haforu-2fb67dixdogp3
â”‚   â”‚       â”‚   â””â”€â”€ ğŸ“ s-hczsguz3dm-1g38rv1-d5p6kfmdfy6hd8dclmour2psc
â”‚   â”‚       â”œâ”€â”€ ğŸ“ haforu-2s4lo2coqi1y3
â”‚   â”‚       â”‚   â””â”€â”€ ğŸ“ s-hczg7klfi5-1xvokh9-bqzi55jezwhcthhoj9ny6dnd0
â”‚   â”‚       â”œâ”€â”€ ğŸ“ haforu-2w98643ew4hsq
â”‚   â”‚       â”‚   â””â”€â”€ ğŸ“ s-hczrbz3fnf-1ki1gxt-btdwz737k9cocic9ojwiak7yo
â”‚   â”‚       â”œâ”€â”€ ğŸ“ haforu-3002vez00oonz
â”‚   â”‚       â”‚   â””â”€â”€ ğŸ“ s-hczrcevi93-1omtugk-edzm2153rvvb0ztfy2ntei5ot
â”‚   â”‚       â”œâ”€â”€ ğŸ“ haforu-3201lk299trz7
â”‚   â”‚       â”‚   â””â”€â”€ ğŸ“ s-hczsghg1t4-0a4ow1f-7tdrjqi9q3tr7p0d0wz2ave5g
â”‚   â”‚       â”œâ”€â”€ ğŸ“ haforu-3bg9xrxjbg3mk
â”‚   â”‚       â”‚   â””â”€â”€ ğŸ“ s-hczs6o1r1c-0t8asr7-3o8san52egckqebn13nnqf02k
â”‚   â”‚       â”œâ”€â”€ ğŸ“ haforu-3l0mulv3ej1mz
â”‚   â”‚       â”‚   â””â”€â”€ ğŸ“ s-hczg7klfi7-0djl7zb-epuwmapnzex5kipbbeqx8ba3d
â”‚   â”‚       â”œâ”€â”€ ğŸ“ haforu-3okrdq68lieta
â”‚   â”‚       â”‚   â””â”€â”€ ğŸ“ s-hczrbzjrxk-06syavp-5x5svhd66s5uuf8e59aq6ln79
â”‚   â”‚       â”œâ”€â”€ ğŸ“ haforu-3orrzumlwtfvw
â”‚   â”‚       â”‚   â””â”€â”€ ğŸ“ s-hczrcp1u58-1tt2bko-baitlpb1njb8ikm8c73iqeyqv
â”‚   â”‚       â”œâ”€â”€ ğŸ“ haforu-3pcmymtpk80e6
â”‚   â”‚       â”‚   â””â”€â”€ ğŸ“ s-hczs9tnkvc-1akjonb-2fx23h1kqcr771fww7pw0hh15
â”‚   â”‚       â”œâ”€â”€ ğŸ“ haforu-3rn41senhi1gm
â”‚   â”‚       â”‚   â””â”€â”€ ğŸ“ s-hczs8alsfo-00ncpix-8b727ebd7tfq2hmbry5d793y8
â”‚   â”‚       â””â”€â”€ ğŸ“ smoke_test-1y5ez3zgfzi7v
â”‚   â”‚           â””â”€â”€ ğŸ“ s-hczsguz2rl-1obonja-29rq372hzugodosv2tpkljhge
â”‚   â”œâ”€â”€ ğŸ“ tmp
â”‚   â””â”€â”€ ğŸ“ wheels
â”œâ”€â”€ ğŸ“ testdata
â”‚   â””â”€â”€ ğŸ“ fonts
â”œâ”€â”€ ğŸ“ tests
â”‚   â”œâ”€â”€ ğŸ“„ __init__.py
â”‚   â”œâ”€â”€ ğŸ“„ cli_stats.rs
â”‚   â”œâ”€â”€ ğŸ“„ test_batch.py
â”‚   â”œâ”€â”€ ğŸ“„ test_errors.py
â”‚   â”œâ”€â”€ ğŸ“„ test_numpy.py
â”‚   â””â”€â”€ ğŸ“„ test_streaming.py
â”œâ”€â”€ ğŸ“„ .gitignore
â”œâ”€â”€ ğŸ“„ ARCHITECTURE.md
â”œâ”€â”€ ğŸ“„ build.sh
â”œâ”€â”€ ğŸ“„ Cargo.toml
â”œâ”€â”€ ğŸ“„ DEPENDENCIES.md
â”œâ”€â”€ ğŸ“„ llms.sh
â”œâ”€â”€ ğŸ“„ NEXTTASK.md
â”œâ”€â”€ ğŸ“„ PLAN.md
â”œâ”€â”€ ğŸ“„ pyproject.toml
â”œâ”€â”€ ğŸ“„ README.md
â”œâ”€â”€ ğŸ“„ run.sh
â”œâ”€â”€ ğŸ“„ SIMPLIFICATION-SUMMARY.md
â”œâ”€â”€ ğŸ“„ smoke_test.rs
â””â”€â”€ ğŸ“„ TODO.md


<documents>
<document index="1">
<source>.github/workflows/ci.yml</source>
<document_content>
# this_file: .github/workflows/ci.yml

name: CI

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]
  workflow_dispatch:

env:
  CARGO_TERM_COLOR: always
  RUST_BACKTRACE: 1

jobs:
  # Rust tests
  rust-test:
    name: Rust Tests (${{ matrix.os }})
    runs-on: ${{ matrix.os }}
    strategy:
      matrix:
        os: [ubuntu-latest, macos-latest, windows-latest]
        rust: [stable]
    steps:
      - uses: actions/checkout@v4

      - name: Setup Rust
        uses: dtolnay/rust-toolchain@master
        with:
          toolchain: ${{ matrix.rust }}
          components: rustfmt, clippy

      - name: Cache cargo
        uses: actions/cache@v4
        with:
          path: |
            ~/.cargo/registry/index
            ~/.cargo/registry/cache
            ~/.cargo/git
            target/
          key: ${{ runner.os }}-cargo-${{ hashFiles('**/Cargo.lock') }}
          restore-keys: ${{ runner.os }}-cargo-

      - name: Check formatting
        run: cargo fmt --all -- --check

      - name: Run clippy
        run: cargo clippy --all-features -- -D warnings

      - name: Build
        run: cargo build --verbose --all-features

      - name: Run tests
        run: cargo test --verbose --all-features

      - name: Run smoke test
        if: runner.os != 'Windows'
        run: |
          cargo build --release
          bash scripts/batch_smoke.sh

  # Python tests
  python-test:
    name: Python Tests (${{ matrix.os }}, Python ${{ matrix.python }})
    runs-on: ${{ matrix.os }}
    strategy:
      matrix:
        os: [ubuntu-latest, macos-latest, windows-latest]
        python: ['3.8', '3.12']
    steps:
      - uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python }}

      - name: Setup Rust
        uses: dtolnay/rust-toolchain@stable

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install maturin pytest numpy fire

      - name: Build and install package
        run: |
          maturin develop --release --features python

      - name: Run Python tests
        run: |
          pytest python/tests -v

      - name: Test CLI
        run: |
          python -m haforu version
          python -m haforu --help

  # Documentation
  docs:
    name: Documentation
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Setup Rust
        uses: dtolnay/rust-toolchain@stable

      - name: Build documentation
        run: cargo doc --all-features --no-deps

      - name: Check documentation
        run: cargo test --doc

  # Benchmarks (optional, runs on main branch only)
  benchmark:
    name: Performance Benchmark
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'
    steps:
      - uses: actions/checkout@v4

      - name: Setup Rust
        uses: dtolnay/rust-toolchain@stable

      - name: Build release
        run: cargo build --release

      - name: Run performance test
        run: |
          echo "Running performance benchmark..."
          time bash scripts/run.sh perf

      - name: Upload benchmark results
        uses: actions/upload-artifact@v4
        with:
          name: benchmark-results
          path: |
            *.json
            *.txt
        if: always()

  # Security audit
  security:
    name: Security Audit
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Setup Rust
        uses: dtolnay/rust-toolchain@stable

      - name: Install cargo-audit
        run: cargo install cargo-audit

      - name: Run security audit
        run: cargo audit

  # Coverage (optional)
  coverage:
    name: Code Coverage
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Setup Rust
        uses: dtolnay/rust-toolchain@stable

      - name: Install tarpaulin
        run: cargo install cargo-tarpaulin

      - name: Run coverage
        run: cargo tarpaulin --out xml --all-features

      - name: Upload coverage to Codecov
        uses: codecov/codecov-action@v4
        with:
          files: ./cobertura.xml
          fail_ci_if_error: false
        continue-on-error: true
</document_content>
</document>

<document index="2">
<source>.github/workflows/release.yml</source>
<document_content>
# this_file: .github/workflows/release.yml

name: Release

on:
  push:
    tags:
      - 'v*'
  workflow_dispatch:
    inputs:
      tag:
        description: 'Tag to release (e.g., v2.1.0)'
        required: true
        type: string

env:
  CARGO_TERM_COLOR: always
  PYTHON_VERSION: '3.12'

jobs:
  # Extract version and changelog
  prepare:
    name: Prepare Release
    runs-on: ubuntu-latest
    outputs:
      version: ${{ steps.version.outputs.version }}
      changelog: ${{ steps.changelog.outputs.changelog }}
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Extract version
        id: version
        run: |
          if [[ "${{ github.event_name }}" == "workflow_dispatch" ]]; then
            VERSION="${{ github.event.inputs.tag }}"
          else
            VERSION="${GITHUB_REF#refs/tags/}"
          fi
          echo "version=${VERSION#v}" >> $GITHUB_OUTPUT
          echo "Version: ${VERSION#v}"

      - name: Extract changelog
        id: changelog
        run: |
          VERSION="${{ steps.version.outputs.version }}"
          # Extract the section for this version from CHANGELOG.md
          awk "/## ${VERSION}/,/## [0-9]/" CHANGELOG.md | head -n -2 > changelog.txt || echo "No changelog found for ${VERSION}" > changelog.txt
          echo "changelog<<EOF" >> $GITHUB_OUTPUT
          cat changelog.txt >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT

  # Build Rust binaries
  rust-binaries:
    name: Build Rust Binary (${{ matrix.os }})
    runs-on: ${{ matrix.runner }}
    strategy:
      matrix:
        include:
          - os: linux-x64
            runner: ubuntu-latest
            target: x86_64-unknown-linux-gnu
            artifact: haforu-linux-x64

          - os: linux-arm64
            runner: ubuntu-latest
            target: aarch64-unknown-linux-gnu
            artifact: haforu-linux-arm64

          - os: macos-x64
            runner: macos-13
            target: x86_64-apple-darwin
            artifact: haforu-macos-x64

          - os: macos-arm64
            runner: macos-14
            target: aarch64-apple-darwin
            artifact: haforu-macos-arm64

          - os: windows-x64
            runner: windows-latest
            target: x86_64-pc-windows-msvc
            artifact: haforu-windows-x64

    steps:
      - uses: actions/checkout@v4

      - name: Setup Rust
        uses: dtolnay/rust-toolchain@stable
        with:
          targets: ${{ matrix.target }}

      - name: Setup cross-compilation (Linux ARM64)
        if: matrix.target == 'aarch64-unknown-linux-gnu'
        run: |
          sudo apt-get update
          sudo apt-get install -y gcc-aarch64-linux-gnu
          echo "CARGO_TARGET_AARCH64_UNKNOWN_LINUX_GNU_LINKER=aarch64-linux-gnu-gcc" >> $GITHUB_ENV

      - name: Build binary
        run: |
          cargo build --release --target ${{ matrix.target }} --bin haforu

      - name: Package binary (Unix)
        if: runner.os != 'Windows'
        run: |
          cd target/${{ matrix.target }}/release
          tar czf ${{ matrix.artifact }}.tar.gz haforu
          mv ${{ matrix.artifact }}.tar.gz ../../../

      - name: Package binary (Windows)
        if: runner.os == 'Windows'
        run: |
          cd target/${{ matrix.target }}/release
          7z a ${{ matrix.artifact }}.zip haforu.exe
          mv ${{ matrix.artifact }}.zip ../../../

      - name: Upload artifact
        uses: actions/upload-artifact@v4
        with:
          name: ${{ matrix.artifact }}
          path: |
            *.tar.gz
            *.zip

  # Build Python wheels
  python-wheels:
    name: Build Python Wheels (${{ matrix.os }})
    runs-on: ${{ matrix.runner }}
    strategy:
      matrix:
        include:
          - os: linux
            runner: ubuntu-latest
            artifact: wheels-linux

          - os: macos
            runner: macos-14
            artifact: wheels-macos

          - os: windows
            runner: windows-latest
            artifact: wheels-windows

    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0  # Need full history for hatch-vcs

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install maturin build

      - name: Build wheels (Linux)
        if: runner.os == 'Linux'
        uses: PyO3/maturin-action@v1
        with:
          command: build
          args: --release --features python -o dist
          manylinux: auto
          target: x86_64

      - name: Build wheels (macOS)
        if: runner.os == 'macOS'
        uses: PyO3/maturin-action@v1
        with:
          command: build
          args: --release --features python --universal2 -o dist
          target: universal2-apple-darwin

      - name: Build wheels (Windows)
        if: runner.os == 'Windows'
        uses: PyO3/maturin-action@v1
        with:
          command: build
          args: --release --features python -o dist
          target: x64

      - name: Upload wheels
        uses: actions/upload-artifact@v4
        with:
          name: ${{ matrix.artifact }}
          path: dist/*.whl

  # Build source distribution
  sdist:
    name: Build Source Distribution
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install maturin build

      - name: Build sdist
        run: maturin sdist -o dist

      - name: Upload sdist
        uses: actions/upload-artifact@v4
        with:
          name: sdist
          path: dist/*.tar.gz

  # Create GitHub Release
  github-release:
    name: Create GitHub Release
    runs-on: ubuntu-latest
    needs: [prepare, rust-binaries, python-wheels, sdist]
    permissions:
      contents: write
    steps:
      - uses: actions/checkout@v4

      - name: Download all artifacts
        uses: actions/download-artifact@v4
        with:
          path: artifacts

      - name: Organize artifacts
        run: |
          mkdir release
          find artifacts -type f \( -name "*.tar.gz" -o -name "*.zip" -o -name "*.whl" \) -exec mv {} release/ \;
          ls -la release/

      - name: Create Release
        uses: softprops/action-gh-release@v1
        with:
          tag_name: v${{ needs.prepare.outputs.version }}
          name: Release v${{ needs.prepare.outputs.version }}
          body: |
            ## Haforu v${{ needs.prepare.outputs.version }}

            ### Changes
            ${{ needs.prepare.outputs.changelog }}

            ### Installation

            #### Rust CLI
            Download the appropriate binary for your platform and add it to your PATH.

            #### Python Package
            ```bash
            pip install haforu
            ```

            ### Assets
            - **Rust Binaries**: Pre-compiled binaries for Linux, macOS, and Windows
            - **Python Wheels**: Platform-specific wheels for easy installation
            - **Source Distribution**: For building from source

          files: release/*
          draft: false
          prerelease: false

  # Publish to PyPI
  publish-pypi:
    name: Publish to PyPI
    runs-on: ubuntu-latest
    needs: [github-release]
    environment:
      name: pypi
      url: https://pypi.org/project/haforu/
    permissions:
      id-token: write  # For trusted publishing
    steps:
      - name: Download wheels and sdist
        uses: actions/download-artifact@v4
        with:
          pattern: wheels-*
          path: dist
          merge-multiple: true

      - name: Download sdist
        uses: actions/download-artifact@v4
        with:
          name: sdist
          path: dist

      - name: Publish to PyPI
        uses: pypa/gh-action-pypi-publish@release/v1
        with:
          packages-dir: dist/
          skip-existing: true

  # Publish to crates.io
  publish-crates:
    name: Publish to crates.io
    runs-on: ubuntu-latest
    needs: [prepare, github-release]
    steps:
      - uses: actions/checkout@v4

      - name: Setup Rust
        uses: dtolnay/rust-toolchain@stable

      - name: Update version in Cargo.toml
        run: |
          VERSION="${{ needs.prepare.outputs.version }}"
          sed -i "s/^version = .*/version = \"$VERSION\"/" Cargo.toml

      - name: Publish to crates.io
        run: cargo publish --token ${{ secrets.CARGO_REGISTRY_TOKEN }}
        continue-on-error: true  # Don't fail if already published
</document_content>
</document>

<document index="3">
<source>.gitignore</source>
<document_content>
# this_file: .gitignore

# Rust
/target
**/*.rs.bk
*.pdb
Cargo.lock

# Python
__pycache__/
*.py[cod]
*$py.class
*.so
.Python
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
*.egg-info/
.installed.cfg
*.egg
.python-version

# Maturin
python/haforu/*.so
python/haforu/*.pyd

# Generated version file
python/haforu/_version.py

# IDEs
.vscode/
.idea/
*.swp
*.swo
*~

# Testing
.pytest_cache/
.coverage
htmlcov/
.tox/

# OS
.DS_Store
Thumbs.db
reference/

# Build artifacts
*.tar.gz
*.zip
target/dist/
target/completions/
target/wheels/

# CI/CD cache
.github/workflows/.cache/

# Documentation builds
site/
docs/_build/

# Logs
*.log
npm-debug.log*
yarn-debug.log*
yarn-error.log*

# Temporary files
tmp/
temp/
*.tmp
.venv/
</document_content>
</document>

<document index="4">
<source>ARCHITECTURE.md</source>
<document_content>
# Haforu2: Comprehensive Architectural Analysis

**Date:** 2025-11-11  
**Project:** FontSimi v3 + Haforu2 Integration  
**Status:** H2.1-H2.7 Implementation Planning (Ready to Begin)

---

## Executive Summary

**Problem Statement:**
- FontSimi must render 5.5 million glyphs (250 fonts Ã— 85 instances Ã— 5 segments Ã— 52 glyphs)
- Current Python renderers: 5+ hours, 86GB RAM, frequent OOM crashes
- Root cause: Individual Pythonâ†’Native boundary crossings (object alloc/dealloc per render)

**Haforu2 Solution:**
- Rust-native batch font renderer processing thousands of jobs in one subprocess call
- Memory-mapped fonts (zero-copy)
- Single native boundary crossing per batch
- Expected: 100Ã— speedup (5h â†’ 3m), 97% memory reduction (86GB â†’ <2GB)

**Integration Model:**
- **Phase H1:** âœ… Python HaforuRenderer class (subprocess communication, JSONâ†’JSONL)
- **Phase H2:** â¸ï¸ Haforu2 Rust implementation (12-18 days)
- **Phase H3:** Python batch analysis pipeline
- **Phase H4:** Streaming mode for deep matching
- **Phase H5:** Performance validation

---

## Section 1: FontSimi Bottleneck Analysis

### 1.1 Current Performance Metrics

| Metric | Value | Problem |
|--------|-------|---------|
| **Total Render Calls** | 5.5M | Each crosses Pythonâ†’Native |
| **Fonts** | 250 | Most static, some variable with 2-16 axes |
| **Variable Instances** | 85 | Intermediate: wght, wdth, opsz mostly |
| **Script Segments** | 5 | Latn, ULAT, Cyrl, UCYR, Grek, etc. |
| **Glyphs per Segment** | 52 | Single glyph per render: "a", "b", "c", etc. |
| **Runtime** | 5+ hours | Dominated by render overhead, not computation |
| **Memory Peak** | 86GB | 5.5M images Ã— 1.5MB each (uncompressed) |
| **OOM Crashes** | Frequent | During peak font loading + rendering |

### 1.2 Root Cause: Pythonâ†’Native Boundary Overhead

**Current Architecture (Python):**
```
for font in fonts:
  for instance_coords in instances:
    for segment in segments:
      for glyph in glyphs:
        image = renderer.render_text(glyph)  # â† Native call (high overhead)
```

**Per-Call Overhead:**
- Python function call â†’ C/Rust native boundary
- Object allocation (PIL Image, numpy array)
- Object deallocation (garbage collection trigger)
- Native function execution (typically <5ms)
- **Total overhead per call:** ~50-100ms (10-20Ã— computation cost)

**Memory Explosion:**
- Each render produces ~1.5MB uncompressed grayscale image
- No shared buffer pool; each image is separate allocation
- Python GC pressure causes pause stops
- Result: 5.5M Ã— 1.5MB Ã· compression â‰ˆ 86GB peak (uncompressed)

### 1.3 Current Python Renderer Implementations

| Renderer | Backend | Mechanism | Per-Call Overhead | Bottleneck |
|----------|---------|-----------|------------------|-----------|
| **HarfBuzz** | libharfbuzz | Python/C boundary | 40ms | Shaping + rasterization |
| **CoreText** | macOS | Objective-C bridge | 60ms | ObjC boundary crossing |
| **Skia** | libskia | Python/C boundary | 80ms | Heavy graphics library |
| **Pillow** | pure Python | 100% Python | 20ms | CPU rasterization but no C boundary |
| **Haforu (current)** | subprocess | stdin/stdout JSON | 500ms | Subprocess spawn overhead |

### 1.4 FontSimi's Unique Daidot Metrics

**4-Metric Model (simplified from 8D):**
1. `width_rhythm` - Horizontal character spacing consistency
2. `rendered_aspect` - Visual height/width ratio
3. `density` - Overall pixel coverage
4. `consistency` - Variance across glyphs

**Why This Matters for Haforu:**
- Only need grayscale images (no color rendering)
- 1000pt font size standard (high resolution for metric stability)
- 3000Ã—1200 canvas typical (fixed for consistent metrics)
- Single glyph per image (no shaping complexity)
- No kerning, ligatures, or complex scripts needed

---

## Section 2: Haforu2 Design Requirements

### 2.1 FontSimi Integration Requirements

**Batch Job Specification Format:**
```json
{
  "version": "1.0",
  "mode": "batch",
  "config": {
    "max_memory_mb": 2000,
    "output_format": "base64",
    "include_metrics": false
  },
  "jobs": [
    {
      "id": "font1_wght600_Latn_a",
      "font": {
        "path": "/path/to/font.ttf",
        "size": 1000,
        "variations": {"wght": 600, "wdth": 100},
        "face_index": 0
      },
      "text": {
        "content": "a",
        "script": "Latn",
        "direction": "ltr",
        "language": "en"
      },
      "rendering": {
        "format": "pgm",
        "encoding": "binary",
        "width": 3000,
        "height": 1200
      }
    }
    // ... 5000+ more jobs
  ]
}
```

**Expected Job Characteristics:**
- Batch size: 1000-5000 jobs per invocation
- Jobs per second: 500-1000 (target: 3m for 5.5M Ã· 30 batches)
- Memory per job: ~1.5KB JSON + 1.5MB rendered (not held simultaneously)
- Variable fonts: 60% of jobs (rest static)

**JSONL Output Format:**
```jsonl
{"id":"font1_wght600_Latn_a","status":"success","rendering":{"format":"pgm","encoding":"base64","data":"Rjk1CjMwMDAg...","width":3000,"height":1200,"actual_bbox":[500,200,800,600]},"timing":{"shape_ms":2.1,"render_ms":4.3,"total_ms":8.5},"memory":{"font_cache_mb":1.2,"total_mb":45.6}}
{"id":"font1_wght600_Latn_b","status":"success","rendering":{...},"timing":{...}}
```

### 2.2 Haforu2 Architectural Principles

**Core Design:**
1. **Stateless Job Processing:** Each job is independent; no cross-job state
2. **Memory-Mapped Fonts:** Zero-copy font loading via memmap2 crate
3. **Font Instance Caching:** LRU cache of (path, variations) â†’ skrifa FontRef
4. **Parallel Job Processing:** rayon parallelism across jobs
5. **Streaming Output:** Write JSONL immediately as jobs complete
6. **Subprocess Communication:** stdin JSON â†’ stdout JSONL (simple Unix pipes)

**Why This Design:**
- **Stateless:** Easy to scale horizontally (no shared state)
- **Memory-mapped:** 250 fonts Ã— 1MB each = 250MB (not 86GB)
- **Streaming:** Python can start processing results while Haforu still working
- **Subprocess:** Simple to invoke, no Python/Rust FFI complexity
- **Parallel:** rayon handles NUMA and thread pool automatically

### 2.3 Haforu2 Feature Matrix

| Feature | Phase | Priority | FontSimi Requirement | Notes |
|---------|-------|----------|----------------------|-------|
| JSON job parsing | H2.1 | CRITICAL | 5000+ jobs/batch | Must parse in <500ms |
| Font loading (static) | H2.2 | CRITICAL | 250 fonts | Must load in <1ms each |
| Font loading (variable) | H2.2 | CRITICAL | 85 instances | Must apply coords in <5ms |
| Font caching | H2.2 | CRITICAL | 512 font instances | LRU, >90% hit rate |
| Text shaping | H2.3 | CRITICAL | 52 glyphs/segment | HarfRust (one char) |
| Glyph rasterization | H2.4 | CRITICAL | 3000Ã—1200 grayscale | skrifaâ†’zeno path |
| PGM P5 output | H2.5 | HIGH | FontSimi format | 8-bit grayscale binary |
| Base64 encoding | H2.5 | HIGH | JSON compatibility | JSONL string embedding |
| Bounding box calc | H2.5 | MEDIUM | Metric stability | For crop optimization |
| Error handling | H2.7 | HIGH | Partial failure recovery | Continue on bad fonts |
| Streaming JSON output | H2.6 | CRITICAL | Progressive results | Flush per job |
| Streaming mode (persistent process) | H4 | MEDIUM | Deep matching speedup | Future optimization |

### 2.4 Haforu2 Standalone Value Proposition

Beyond FontSimi, Haforu2 is useful for:

**1. Font Development (FontLab, ufo, Glyphs):**
- Batch render instances during design iteration
- Compare rendering across sizes/weights quickly
- Export to analysis tools

**2. Quality Assurance:**
- Regression test suite: render known fonts, compare outputs
- Smoke tests: verify no crashes on corpus of 10K fonts
- Rendering consistency check: static vs variable instances

**3. Content Generation:**
- Generate glyph preview images for web (emoji, symbol fonts)
- Create specimen PDFs with batch rendered instances
- Font matching service backend

**4. Performance Testing:**
- Benchmark new font rasterizers
- Profile memory usage under load
- Compare rendering quality (PNG diff)

**Design for Standalone Use:**
- No FontSimi-specific code (generic fontâ†’glyphâ†’image pipeline)
- Pluggable output formats (PGM, PNG, SVG, metrics JSON)
- Generic job ID scheme (user can choose naming)
- Configurable font cache size, max memory, parallel workers

---

## Section 3: Haforu2 Technical Architecture

### 3.1 Module Structure

```
external/haforu2/
â”œâ”€â”€ Cargo.toml                 # Rust dependencies
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.rs               # Entry point, CLI arg parsing
â”‚   â”œâ”€â”€ lib.rs                # Public API (for future PyO3)
â”‚   â”œâ”€â”€ json_parser.rs        # JobSpec/Job deserialization + validation
â”‚   â”œâ”€â”€ error.rs              # Error types and conversion
â”‚   â”œâ”€â”€ mmap_font.rs          # Memory-mapped font loading
â”‚   â”œâ”€â”€ font_cache.rs         # LRU font instance cache
â”‚   â”œâ”€â”€ shaping.rs            # HarfRust text shaping
â”‚   â”œâ”€â”€ rasterize.rs          # Glyph rasterization (skrifaâ†’zeno)
â”‚   â”œâ”€â”€ output.rs             # PGM format and base64 encoding
â”‚   â”œâ”€â”€ orchestrator.rs       # Job processing pipeline
â”‚   â””â”€â”€ stats.rs              # Metrics and statistics
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ integration_tests.rs  # End-to-end tests
â”‚   â””â”€â”€ unit_tests.rs         # Per-module unit tests
â””â”€â”€ fonts/                     # Test fonts (TTF, OTF, VF)
```

### 3.2 Data Flow: Batch Mode

```
User Input (FontSimi Python)
     â†“
[stdin] JSON (5000 jobs)
     â†“
Haforu2 Process (Arc<Haforu>)
     â”œâ”€ json_parser::parse_stdin()
     â”œâ”€ For each job (parallel via rayon):
     â”‚  â”œâ”€ font_cache.get_or_load_instance(path, coords)
     â”‚  â”œâ”€ shaping::shape_text(font, "a")
     â”‚  â”œâ”€ rasterize::render_glyphs(shaped)
     â”‚  â”œâ”€ output::encode_pgm_base64(pixels)
     â”‚  â””â”€ JobResult { id, status, rendering, timing }
     â””â”€ Write JSONL line to stdout
     â†“
[stdout] JSONL (5000 results)
     â†“
FontSimi Python (parse JSONL, extract images)
```

### 3.3 Implementation Roadmap: H2.1 - H2.7

**Total Estimated Time:** 12-18 days

| Phase | Tasks | Time | Dependencies |
|-------|-------|------|--------------|
| H2.1 | JSON parsing, validation, stdin reading | 2-3d | None |
| H2.2 | Font loading, variations, caching | 2-3d | H2.1 (file I/O) |
| H2.3 | Text shaping (HarfRust) | 2-3d | H2.2 (fonts) |
| H2.4 | Glyph rasterization (skrifa+zeno) | 3-4d | H2.3 (shaped glyphs) |
| H2.5 | PGM output, base64, bounding box | 1-2d | H2.4 (pixels) |
| H2.6 | JSONL formatting, streaming output | 1-2d | H2.5 (output) |
| H2.7 | Error handling, edge cases, tests | 1-2d | All above |

**Critical Path:** H2.1 â†’ H2.2 â†’ H2.3 â†’ H2.4 â†’ H2.5 â†’ H2.6 â†’ H2.7 â†’ Testing

### 3.4 Key Dependencies & Justification

| Dependency | Version | Why Chosen | Alternatives |
|------------|---------|-----------|--------------|
| `serde` | Latest | JSON parsing (proven, fast) | json5, toml |
| `serde_json` | Latest | JSON serialization | jsonc, ron |
| `read-fonts` | Latest | Zero-copy font parsing | fonttools (Python), fontparts |
| `skrifa` | Latest | Variable font support | freetype-py, harfbuzz only |
| `harfbuzz-rs` | Latest | Text shaping | rustybuzz (pure Rust, slower) |
| `zeno` | Latest | CPU rasterization | pathfinder (heavier), tiny-skia |
| `memmap2` | Latest | Memory-mapped I/O | mmap crate (older), std::fs |
| `rayon` | Latest | Parallel job processing | crossbeam (lower-level), tokio (async) |
| `anyhow` | Latest | Error handling | thiserror (more verbose), failure (older) |
| `clap` | Latest | CLI argument parsing | structopt (deprecated for clap v4) |

### 3.5 Performance Targets

**Per-Job Performance:**
- Parse JSON: <100Âµs per job (5M jobs in 500ms)
- Load font: 1ms first time, <0.1ms cache hit
- Shape text: 0.5-2ms (single character is fast)
- Rasterize: 2-5ms (3000Ã—1200 at 1000pt)
- Encode PGM+base64: 5-10ms (compression, not typical)
- **Total per job:** ~10-15ms (100-150 jobs/sec with 8 threads)

**Batch Performance:**
- 5000 jobs: ~5 minutes (sequential, 10ms/job)
- 5000 jobs: ~30-40 seconds (parallel, 8 threads, ~500 jobs/sec)
- Memory: <2GB (250 fonts in cache + 1-2 in-flight renders)

**FontSimi Integration:**
- 5.5M glyphs Ã· 5000 jobs/batch = 1100 batches
- 1100 batches Ã— 40s = 44,000s = 12.2 hours (naive sequential)
- 1100 batches Ã— 40s Ã· 30 parallel processes = ~20 minutes (if parallelized)
- But: Process can be parallelized across machines/containers

**Optimizations Not in H2 (Future):**
- Streaming mode: keep process alive, render on-demand for deep matching
- Distributed mode: split batch across N machines
- Storage backend: pack renders into compressed shards (reduce I/O)

---

## Section 4: Integration Points with FontSimi

### 4.1 Phase H1 (Complete): HaforuRenderer Python Class

**File:** `src/fontsimi/renderers/haforu.py` (348 lines, âœ… tested)

**Responsibilities:**
- Discover haforu binary (env var or repo path)
- Generate JSON job spec
- Spawn subprocess, pass JSON via stdin
- Read JSONL from stdout
- Parse results, extract base64 PGM
- Decode to numpy array
- Clean up temp files

**Key Methods:**
```python
class HaforuRenderer(BaseRenderer):
    def render_text(self, text: str) -> np.ndarray[uint8]:
        """Render single text string, return grayscale image."""
        # 1. Generate job JSON
        # 2. Spawn haforu subprocess
        # 3. Pass JSON via stdin
        # 4. Read JSONL from stdout
        # 5. Decode base64 PGM
        # 6. Return numpy array
```

**Current Status:**
- âœ… JSON generation working
- âœ… Subprocess communication working
- âœ… JSONL parsing working
- â¸ï¸ Haforu Rust returns "pending" (not rendering yet)
- âœ… 38 unit tests passing

### 4.2 Phase H2 (In Progress): Haforu2 Rust Implementation

**Goal:** Make Haforu actually render fonts

**Success Criteria:**
- Parses JSON in <500ms for 5000 jobs
- Renders 500 jobs/sec (8 threads)
- Memory <2GB peak
- Daidot metrics identical to CoreText/HarfBuzz (pixel perfect)
- All error cases handled gracefully

### 4.3 Phase H3 (Ready After H2): FontSimi Batch Pipeline

**File:** `src/fontsimi/daidot/daidot_analyzer.py`

**Changes:**
- Collect render jobs instead of rendering immediately
- Generate 5500K jobs in batches of 5000
- Invoke haforu subprocess per batch
- Parse JSONL results
- Compute Daidot metrics from images
- Store in cache

**Expected Timeline:** 5-9 days after H2 complete

### 4.4 Phase H4 (Future): Streaming Mode

**Improvement:** Keep haforu process alive during deep matching optimization

**Benefit:** Eliminate subprocess spawn overhead (500ms â†’ 20ms per render)

**Expected Timeline:** 6-9 days after H3 complete

### 4.5 Phase H5 (Validation): Performance Targets

**Metrics to Verify:**
- Analysis: 5h â†’ 3m (100Ã— speedup) âœ…
- Memory: 86GB â†’ <2GB (97% reduction) âœ…
- Deep matching: 30s â†’ 0.6s per pair (50Ã— speedup) âœ…
- Reliability: Zero OOM crashes âœ…

**Expected Timeline:** 3-5 days after H4 complete

---

## Section 5: Design Decisions & Trade-offs

### 5.1 Subprocess Communication vs FFI

**Choice:** Subprocess (stdin JSON â†’ stdout JSONL)

**Reasons:**
- No Python/Rust FFI complexity (no PyO3, maturin)
- Simple testing (echo JSON files)
- Language-agnostic (could invoke from Java, Go, etc.)
- Process isolation prevents crashes from affecting FontSimi
- Easier debugging (strace, stderr logging)

**Trade-offs:**
- Subprocess spawn overhead ~500ms (Phase H4 streaming mode fixes)
- JSON serialization overhead (negligible vs rendering time)
- Large JSONL output (compressed with gzip in production)

### 5.2 Memory-Mapped Fonts vs Heap Loading

**Choice:** Memory-mapped (memmap2 crate)

**Reasons:**
- 250 fonts Ã— 1MB = 250MB (vs 86GB for all renders)
- OS page cache reuses across processes
- Zero-copy to skrifa/read-fonts
- Automatic paging in/out

**Trade-offs:**
- Slightly more complex code (unsafe blocks for lifetime transmute)
- MMAP not available on very constrained systems (rare)
- File descriptor limits for 1000+ fonts (non-issue for 250)

### 5.3 LRU Font Cache vs Always-Reload

**Choice:** LRU cache with 512 font instance entries

**Reasons:**
- 85 variable instances Ã— 3 coordinate sets = 255 instance variations
- 512 gives 2Ã— safety margin
- Cache hit rate >90% in typical FontSimi workload

**Trade-offs:**
- Slightly more complex code (lru crate dependency)
- Memory overhead for cache bookkeeping (negligible)
- Eviction policy (LRU) deterministic and testable

### 5.4 Parallel Job Processing vs Sequential

**Choice:** Parallel (rayon with adaptive work stealing)

**Reasons:**
- 8-16 cores typical on development machines
- Font loading is I/O-bound, rendering is CPU-bound (good parallelism)
- rayon handles thread pool, load balancing automatically
- 8Ã— speedup typical (500 jobs/sec Ã— 8 threads)

**Trade-offs:**
- Slightly less deterministic (thread scheduling)
- DETERMINISM: Job results arrive out-of-order in JSONL (fixed by job ID)
- More complex debugging (thread interleaving)

### 5.5 Streaming JSONL Output vs Batch

**Choice:** Streaming (write JSONL immediately as jobs complete)

**Reasons:**
- Python can start processing results while Haforu working
- Progress reporting ("50% complete")
- Early error detection (fail fast)
- Better memory usage (don't hold all results in memory)

**Trade-offs:**
- Results arrive out-of-order (fixed by job ID correlation)
- Stdout buffer management needed (1MB typical, sufficient)

### 5.6 PGM P5 Format vs PNG

**Choice:** PGM P5 (binary) with base64 encoding

**Reasons:**
- PGM P5: Simple binary format, no decompression needed
- 8-bit grayscale: Exactly matches Daidot requirements
- Base64: JSON-safe, universally supported
- 10Ã— smaller than PNG for grayscale (no filter, compression)

**Trade-offs:**
- PNG would be 30% smaller (better compression)
- PNG requires libpng dependency (PGM is trivial)
- PNG slower to decode (PNG decompression vs base64)

**Decision Rationale:** Speed > size for batch rendering

---

## Section 6: Risk Analysis & Mitigation

### 6.1 Risks & Mitigation Strategies

| Risk | Severity | Likelihood | Mitigation |
|------|----------|-----------|-----------|
| Haforu binary not found | HIGH | MEDIUM | Fall back to CoreText/HarfBuzz |
| JSON parsing error on malformed input | MEDIUM | HIGH | Validate JSON size, reject >100MB |
| Font file corruption/missing | HIGH | LOW | Graceful error in JSONL, retry individually |
| Memory spike during image compositing | HIGH | MEDIUM | Stream images to disk, don't hold in memory |
| Thread pool deadlock (rayon) | MEDIUM | LOW | Use default thread pool (rayon handles) |
| Out-of-order JSONL results confusing Python | MEDIUM | HIGH | Use job ID correlation in Python |
| Variable font coordinate clamping issues | LOW | MEDIUM | Log warnings, include in timing metrics |
| Zeno rasterization gaps/overlap | LOW | LOW | Manual testing on known glyphs, compare pixel-perfect |

### 6.2 Testing Strategy

**Unit Tests (per module):**
- json_parser: parse valid/invalid JSON, edge cases
- mmap_font: load static/variable/TTC fonts
- font_cache: LRU eviction, hit rate
- shaping: single glyph, empty string, complex scripts
- rasterize: blank glyph, filled glyph, large canvas
- output: PGM format, base64 encoding, bounding box

**Integration Tests:**
- End-to-end: 100 jobs â†’ JSONL results
- Variable fonts: apply coords, verify rendering changes
- Error handling: missing fonts, invalid JSON, corrupted files
- Performance: 5000 jobs < 40 seconds

**Regression Tests (FontSimi side):**
- Daidot metrics identical to CoreText/HarfBuzz (pixel tolerance <0.1%)
- Match results unchanged (top-10 matches identical)
- No OOM crashes on full 250-font set

---

## Section 7: Implementation Phases

### 7.1 Phase H2: Haforu2 Rust (12-18 days)

**Deliverables:**
1. H2.1: JSON job processing (2-3 days)
2. H2.2: Font loading & variations (2-3 days)
3. H2.3: Text shaping (2-3 days)
4. H2.4: Glyph rasterization (3-4 days)
5. H2.5: PGM output format (1-2 days)
6. H2.6: JSONL streaming output (1-2 days)
7. H2.7: Error handling & tests (1-2 days)

**Success Criteria:**
- All tests passing (100%)
- Batch of 5000 jobs completes <40s
- Memory <2GB
- Daidot metrics identical to baseline

### 7.2 Phase H3: FontSimi Batch Pipeline (5-9 days)

**Location:** `src/fontsimi/daidot/daidot_analyzer.py`

**Deliverables:**
1. H3.1: Batch job generation (1-2 days)
2. H3.2: Result processing (2-3 days)
3. H3.3: Cache integration (1-2 days)
4. H3.4: Error recovery (1-2 days)

**Success Criteria:**
- Full analysis: 5.5M glyphs in <3 minutes
- Memory <2GB
- All metrics cached correctly

### 7.3 Phase H4: Streaming Mode (6-9 days)

**Location:** Both repos

**Deliverables:**
1. H4.1: Haforu streaming mode (2-3 days)
2. H4.2: HaforuStreamingRenderer class (2-3 days)
3. H4.3: Deep matcher integration (2-3 days)

**Success Criteria:**
- Deep match: 30s â†’ 0.6s per pair (50Ã— speedup)
- Process reuse: <0.1% overhead

### 7.4 Phase H5: Validation (3-5 days)

**Location:** Both repos + benchmarks

**Deliverables:**
1. H5.1: Performance benchmarking (2 days)
2. H5.2: Documentation (1 day)
3. H5.3: Fallback & compatibility (1-2 days)

**Success Criteria:**
- 100Ã— speedup verified
- 97% memory reduction verified
- All tests passing

---

## Section 8: Haforu2 Standalone Architecture

Beyond FontSimi, Haforu2 should be designed as a general-purpose tool.

### 8.1 Generic Batch Rendering API

**Core Abstraction:**
```rust
pub struct RenderJob {
    pub id: String,
    pub font_path: PathBuf,
    pub font_size: f32,
    pub text: String,
    pub output_format: OutputFormat,  // PGM, PNG, SVG, JSON
    pub variations: HashMap<String, f32>,
}

pub struct RenderResult {
    pub job_id: String,
    pub status: Status,  // Success, Error
    pub output: OutputData,  // Enum: PgmBinary, PngBinary, SvgString, MetricsJson
    pub timing: TimingInfo,
}

pub fn render_batch(jobs: Vec<RenderJob>) -> Vec<RenderResult>
```

### 8.2 Output Format Plugins

**Supported Formats:**
- `pgm`: P5 binary grayscale (FontSimi)
- `png`: PNG compressed color (web)
- `svg`: Scalable vector (future)
- `metrics`: JSON with computed metrics (QA)

### 8.3 Standalone CLI Usage

```bash
# Single batch
cat jobs.json | haforu2 process --render --format pgm > results.jsonl

# Multiple batches (GNU parallel)
parallel < batch_list.txt | haforu2 process --render --format png --parallel 4

# Streaming mode (keeps process alive)
haforu2 --streaming < /dev/stdin > /dev/stdout
```

### 8.4 Future Extensions

**Possible plugins (not in H2-H5):**
- Distributed rendering (MPI, Ray)
- GPU rasterization (Vello/wgpu backend)
- Web service (actix-web)
- Python bindings (PyO3/maturin)

---

## Section 9: Conclusion & Next Steps

### 9.1 Haforu2 Value Proposition

**For FontSimi:**
- 100Ã— performance improvement
- 97% memory reduction
- Architectural foundation for future scaling

**For Font Developers:**
- General-purpose batch rendering tool
- Suitable for specimen generation, QA, benchmarking
- Extensible output formats and plugins

**For Ecosystem:**
- Rust native font rendering (no C FFI)
- Zero-copy design (memory efficient)
- Streaming architecture (progressive results)

### 9.2 Critical Success Factors

1. **Get H2.1-H2.4 right:** Core rendering pipeline is foundation
2. **Exhaustive unit tests:** Catch edge cases early
3. **FontSimi validation:** Ensure Daidot metrics pixel-perfect
4. **Performance profiling:** Measure per-stage bottlenecks
5. **Documentation:** Examples, troubleshooting, API docs

### 9.3 Recommended Implementation Order

1. **Start H2.1 immediately:** JSON parsing (lowest risk, high value)
2. **Parallelize H2.2-H2.4:** Font loading and rendering (deep work)
3. **Validate against FontSimi:** Compare Daidot metrics pixel-perfect
4. **Then proceed to H3:** Batch pipeline (depends on H2)
5. **Then proceed to H4-H5:** Streaming & optimization (polish)

### 9.4 Timeline Estimate

- **H2 (Rust):** 12-18 days (2-3 weeks)
- **H2 Validation:** 4 days
- **H3 (Python batch):** 5-9 days (1-2 weeks)
- **H4 (Streaming):** 6-9 days (1-2 weeks)
- **H5 (Validation):** 3-5 days
- **Total:** 4-6 weeks

---

## Appendix A: File Structure Reference

```
external/haforu2/                    # New Rust project
â”œâ”€â”€ Cargo.toml
â”œâ”€â”€ Cargo.lock
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.rs                      # CLI entry point
â”‚   â”œâ”€â”€ lib.rs                       # Public library API
â”‚   â”œâ”€â”€ json_parser.rs               # JobSpec, validation
â”‚   â”œâ”€â”€ error.rs                     # Error types
â”‚   â”œâ”€â”€ mmap_font.rs                 # Memory-mapped font loading
â”‚   â”œâ”€â”€ font_cache.rs                # LRU font instance cache
â”‚   â”œâ”€â”€ shaping.rs                   # HarfRust text shaping
â”‚   â”œâ”€â”€ rasterize.rs                 # Glyph rasterization
â”‚   â”œâ”€â”€ output.rs                    # PGM format, base64
â”‚   â”œâ”€â”€ orchestrator.rs              # Job pipeline
â”‚   â””â”€â”€ stats.rs                     # Performance metrics
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ integration_tests.rs
â”‚   â””â”€â”€ unit_tests.rs
â”œâ”€â”€ fonts/                           # Test fonts
â”‚   â”œâ”€â”€ Arial.ttf                    # Static
â”‚   â”œâ”€â”€ Roboto[wght].ttf             # Variable (one axis)
â”‚   â””â”€â”€ Inter[slnt,wght].ttf         # Variable (two axes)
â”œâ”€â”€ README.md                        # Usage guide
â”œâ”€â”€ PLAN.md                          # Implementation plan
â”œâ”€â”€ TODO.md                          # Task list
â””â”€â”€ WORK.md                          # Work log
```

---

**Document Version:** 1.0  
**Last Updated:** 2025-11-11  
**Status:** Ready for Implementation
</document_content>
</document>

<document index="5">
<source>Cargo.toml</source>
<document_content>
# this_file: Cargo.toml

[package]
name = "haforu"
version = "2.0.0"
edition = "2021"
authors = ["FontSimi Team"]
description = "High-performance batch font renderer for FontSimi"
license = "Apache-2.0"
rust-version = "1.70"

[lib]
name = "haforu"
crate-type = ["cdylib", "rlib"]

[[bin]]
name = "haforu"
path = "src/main.rs"

[[bench]]
name = "cli"
harness = false

[dependencies]
# CLI and argument parsing
clap = { version = "4.5", features = ["derive", "cargo"] }

# Error handling
thiserror = "1.0"
anyhow = "1.0"

# Serialization
serde = { version = "1.0", features = ["derive"] }
serde_json = "1.0"

# Font handling - using fontations ecosystem
read-fonts = "0.36"
skrifa = "0.39"

# Text shaping
harfbuzz_rs = "2.0"

# Rasterization
zeno = "0.3"

# Image output
image = { version = "0.25", features = ["png", "jpeg"] }

# Memory mapping for zero-copy font loading
memmap2 = "0.9"

# Base64 encoding for JSONL output
base64 = "0.22"

# Logging
log = "0.4"
env_logger = "0.11"

# Parallel processing
rayon = "1.10"

# LRU cache for font instances
lru = "0.12"

# Concurrent hash map for lock-free font caching
dashmap = "6.1"

# Stack-allocated small vectors for cache keys
smallvec = { version = "1.13", features = ["serde"] }

# Path utilities
camino = { version = "1.1", features = ["serde1"] }

# Python bindings
pyo3 = { version = "0.22", optional = true, features = ["extension-module"] }
numpy = { version = "0.22", optional = true }

[dev-dependencies]
tempfile = "3.10"
approx = "0.5"
insta = "1.39"
assert_cmd = "2.0"
predicates = "3.1"
criterion = "0.5"

[features]
default = []
python = ["pyo3", "numpy"]

[profile.release]
opt-level = 3
lto = true
codegen-units = 1
strip = true

[profile.dev]
opt-level = 0
debug = true
</document_content>
</document>

<document index="6">
<source>DEPENDENCIES.md</source>
<document_content>
---
this_file: DEPENDENCIES.md
---

# Dependency Rationale

## Rust Crate

- **clap** â€” battle-tested CLI arg parsing so we can expose batch/stream/render/diagnostics switches without writing our own parser.
- **rayon** â€” lock-free parallel iterator runtime powering batch rendering throughput and Python iterator fan-out.
- **harfbuzz_rs** + **skrifa/read-fonts** â€” production-grade shaping + variable font handling; no bespoke font math.
- **zeno** + **image** â€” raster + image encoding so we emit deterministic base64 payloads without custom encoders.
- **memmap2** â€” zero-copy font loading to keep RSS flat while cycling through 1000s of fonts.
- **env_logger/log** â€” structured logging (JSON/text) for CLI, smoke scripts, and integration debugging.

## Python Package

- **PyO3/maturin** â€” exposes the Rust engine to Python with shared glyph cache + streaming session.
- **fire** â€” lightweight CLI surface matching the Rust commands; keeps parity without manual argparse plumbing.
- **numpy** â€” optional zero-copy path for `StreamingSession.render_to_numpy`.

Each dependency keeps Haforu lean: we offload parsing/shaping/rasterization to maintained libraries instead of re-implementing fragile infrastructure.
</document_content>
</document>

<document index="7">
<source>NEXTTASK.md</source>
<document_content>
NEXT TASK: Sprint forward to complete the work on 'haforu' as outlined in @./PLAN.md and @./TODO.md . Use the file @./WORK.md as the scratchpad for notes, but clean these files once youâ€™ve completed a task, and also check off the completed tasks in @./PLAN.md and @./TODO.md ;; NOTE: '@' denotes the start of a path but is not itself part of a path ;; NOTE: KEEP this NEXTTASK.md file as is, DONâ€™T CHANGE IT! ;; 
</document_content>
</document>

<document index="8">
<source>PLAN.md</source>
<document_content>
---
this_file: PLAN.md
---

# Haforu Development Plan

## Project Status (v2.0.x, 2025-11-15)

**âœ… PRODUCTION READY** - All critical work complete!

- **Performance:** Sub-millisecond rendering with SIMD optimizations âœ“
- **Quality:** Reliable, deterministic output across all platforms âœ“
- **Architecture:** Dual-purpose: CLI binary + Python bindings (PyO3) âœ“
- **Integration:** Powering fontsimi's 35-60Ã— total speedup âœ“

## Project Scope (One Sentence)

Deliver a fast, reliable font renderer for CLI and Python with deterministic output, validated variation coordinates, and sub-millisecond performance for both text rendering and image processing.

---

## Dual-Purpose Architecture

### Purpose 1: Image Processing (PRIMARY for FontSimi)

**Python Bindings (PyO3):**
- **Operations:** `align_and_compare()`, `resize_bilinear()`
- **Performance:** 3-5x speedup vs Python/numpy
- **Usage:** Deep matching hot paths in fontsimi
- **Zero overhead:** Direct memory access, no subprocess calls
- **Build:** `maturin develop --release --features python`

**Why Python bindings for image ops?**
- Hot-path operations benefit from Rust optimization
- Eliminates Python marshalling overhead
- Direct memory access vs subprocess spawn (~20ms overhead)
- Perfect for tight loops (30-180 calls per font match)

### Purpose 2: Text Rendering (FALLBACK for FontSimi)

**CLI Binary:**
- **Batch processing:** 150-200 jobs/sec in parallel
- **Fallback renderer:** When CoreText/HarfBuzz/Skia unavailable (rare)
- **Good for:** Batch analysis (100+ fonts)
- **Poor for:** Per-call rendering (subprocess overhead ~21ms)
- **Build:** `cargo build --release`

**Why CLI as fallback only?**
- Native renderers are 176Ã— faster for per-call rendering
- CoreText (macOS): 0.12ms vs Haforu CLI: 21.04ms
- Subprocess overhead dominates small jobs
- Excellent for batch scenarios (amortizes overhead)

---

## Performance Achievements âœ…

### Actual Performance (v2.0.x with SIMD)

| Mode | Throughput | Status |
|------|-----------|--------|
| CLI Batch | 150-200 jobs/sec | âœ… Production |
| Python Bindings | 1000-2000 jobs/sec | âœ… SIMD-accelerated |
| Metrics Mode | 10,000-20,000 jobs/sec | âœ… SIMD-accelerated |
| Batch Variation Sweep | ~30-40 coords/ms | âœ… Parallel |

### Detailed Timings

- **Single render (CLI):** <10ms cold, ~5ms warm
- **Single render (Python):** <1ms warmed cache with SIMD
- **Batch 1000 jobs (CLI):** <5s on 8 cores
- **Metrics mode:** <0.05ms per job (4-8Ã— faster with SIMD)
- **Variation sweep (80 coords):** ~2-3ms on 8 cores
- **Memory:** <500MB for 1000 renders

### Image Processing (Python Bindings)

| Operation | Python/NumPy | Haforu (Rust) | Speedup |
|-----------|--------------|---------------|---------|
| `align_and_compare()` | ~5-8ms | 1.6ms | **3-5x** |
| `resize_bilinear()` | ~1ms | 0.3ms | **2-3x** |

**Call frequency in fontsimi:** 30-180 calls per font match
**Total impact:** 3-5Ã— speedup for deep matching pipeline

---

## Key Optimizations (v2.0+)

### Phase 1: Core Rendering (Completed)
1. **Lock-Free Font Cache** (20% speedup)
   - DashMap replaces Mutex<LruCache>
   - Eliminates lock contention on high thread counts
   - Location: `src/fonts.rs`

2. **HarfBuzz Font Caching** (20% speedup)
   - Cache HarfBuzz Font objects in FontInstance
   - Eliminate repeated Face/Font creation
   - Location: `src/fonts.rs`

3. **Variable Font Fast Path** (15% speedup)
   - Fixed single-char rendering to support variable fonts
   - Use variation-aware metrics from HVAR/gvar
   - Location: `src/shaping.rs`

### Phase 2: SIMD + Parallel (Completed)
4. **SIMD-Accelerated Metrics** (4-8Ã— speedup)
   - AVX2 for density/beam calculations on x86_64
   - Portable fallback for other platforms
   - Location: `src/render.rs`

5. **Thread-Local Buffer Pools** (10-15% speedup)
   - Pool canvas buffers per thread
   - Eliminates allocation overhead
   - Location: `src/bufpool.rs`

6. **Batch Variation Sweep API** (5-8Ã— speedup)
   - Parallel rendering at multiple coordinates
   - Optimized for font matching loops
   - Location: `src/varsweep.rs`

### Phase 3: Image Processing (Completed)
7. **`align_and_compare()`** (3-5Ã— speedup for fontsimi)
   - Align images and compute pixel delta in single Rust call
   - Center alignment, Gaussian-weighted delta
   - Location: `python/src/lib.rs`

8. **`resize_bilinear()`** (2-3Ã— speedup for fontsimi)
   - Native Rust bilinear interpolation
   - Replaces OpenCV wrapper overhead
   - Location: `python/src/lib.rs`

---

## Optional Future Enhancements

**âš ï¸ Important:** Only pursue if explicitly requested. Current system production-ready.

### Error Handling (Nice to Have)
- [ ] Comprehensive malformed input testing (CLI batch/stream, Python bindings)
- [ ] Regression tests for edge cases

### Coordinate Validation (Nice to Have)
- [ ] `validate_coordinates()` in `src/fonts.rs`
- [ ] Clamp wght/wdth to valid ranges
- [ ] Warn on unknown axes

### Documentation (Incremental)
- [ ] Python quick start examples
- [ ] Batch vs stream mode use case guide
- [ ] Performance comparison tables
- [ ] Real-world integration examples

### Image Processing (Future)
- [ ] Integrated rendering metrics (return density/aspect during rendering)
- [ ] Multi-component scoring (weighted score calculation in Rust)
- [ ] SSIM computation (structural similarity)
- [ ] Full objective function (complete pipeline in Rust)

---

## Testing Strategy

**Unit Tests:** Rust modules (`cargo test`) - 41 tests passing âœ…
**Integration Tests:** `scripts/batch_smoke.sh` - validates CLI contract in <2s âœ…
**Performance Tests:** `scripts/profile-cli.sh` - catches regressions âœ…
**Edge Cases:** Empty text, zero canvas, missing fonts, invalid variations âœ…

---

## Performance Targets

### Achieved (v2.0.x with SIMD) âœ…

- âœ… CLI batch (1000 jobs): <5s on 8 cores
- âœ… CLI streaming: <5ms per job including startup
- âœ… Python StreamingSession: <1ms per job (warmed cache, SIMD)
- âœ… Metrics mode: <0.05ms per job (SIMD-accelerated)
- âœ… Batch variation sweep (80 coords): ~2-3ms on 8 cores

---

## Success Criteria âœ… ALL MET

### Performance âœ…
- [x] CLI batch: 40-50% faster than baseline
- [x] Python bindings: <1ms per render (exceeded - SIMD)
- [x] Metrics mode: 4-8Ã— speedup with SIMD
- [x] Batch variation sweep: 5-8Ã— speedup with parallelism

### Correctness âœ…
- [x] CLI never drops jobs silently
- [x] All 41 Rust unit tests pass
- [x] Variation coordinates validated (via skrifa)
- [x] Cross-platform: macOS tested

### Integration with FontSimi âœ…
- [x] `align_and_compare()` working (3-5Ã— speedup)
- [x] `resize_bilinear()` working (2-3Ã— speedup)
- [x] Automatic fallback to Python/numpy
- [x] End-to-end speedup: 35-60Ã— total

---

## Non-Goals (Scope Boundary)

- âŒ No new output formats beyond PGM/PNG/metrics
- âŒ No retry logic, circuit breakers, or resilience patterns
- âŒ No analytics, monitoring, or telemetry systems
- âŒ No color, emoji, or subpixel rendering
- âŒ No complex configuration systems
- âŒ No automatic version tagging or release automation
- âŒ No repository structure reorganization

---

## Build Instructions (Reference)

### Python Bindings (Recommended for FontSimi)

```bash
cd haforu-src
source /path/to/venv/bin/activate
uvx maturin develop --release --features python
python -c "import haforu; print('Version:', haforu.__version__)"
```

### CLI Binary (Already Built)

```bash
cd haforu-src
cargo build --release
./target/release/haforu --version
```

### Verification

```bash
# Run Rust tests
cargo test

# Verify Python bindings
python -c "import haforu; print('Available:', haforu.is_available())"

# Test CLI smoke test
./scripts/batch_smoke.sh
```

---

**Status:** Production Ready
**Version:** v2.0.x
**Last Updated:** 2025-11-15
</document_content>
</document>

<document index="9">
<source>README.md</source>
<document_content>
---
this_file: README.md
---

# Haforu: Fast Font Renderer

**Status:** Production Ready (v2.0.x)

Fast, deterministic font rendering with dual-purpose architecture: Python bindings for image processing (PRIMARY) and CLI binary for batch/fallback text rendering.

---

## What It Does

Haforu serves **two complementary purposes**:

### 1. Image Processing (PRIMARY for FontSimi)

**Python bindings (PyO3)** provide Rust-optimized image operations:
- `align_and_compare()` - Align images and compute pixel delta (3-5Ã— faster than Python/numpy)
- `resize_bilinear()` - Bilinear image scaling (2-3Ã— faster than OpenCV)
- **Zero overhead:** Direct memory access, no subprocess calls
- **Perfect for:** Hot-path operations in tight loops (30-180 calls per font match)

### 2. Text Rendering (FALLBACK for FontSimi)

**CLI binary** provides batch processing and fallback rendering:
- Render glyphs to PGM/PNG/metrics with sub-millisecond performance
- **Good for:** Batch processing (100+ jobs), amortizes subprocess overhead
- **Poor for:** Per-call rendering (21ms overhead vs 0.12ms for CoreText)
- **Use when:** Native renderers (CoreText/HarfBuzz/Skia) unavailable (rare)

---

## Why Both Backends?

**They serve complementary purposes - NOT competing!**

| Use Case | Backend | Performance | When to Use |
|----------|---------|-------------|-------------|
| **Image processing** | Python bindings | 1.6ms | âœ… PRIMARY for fontsimi (hot paths) |
| **Text rendering** | Native (CoreText) | 0.12ms | âœ… PRIMARY for fontsimi (text) |
| **Text rendering** | Haforu CLI | 21ms | âš ï¸ FALLBACK only (native unavailable) |
| **Batch processing** | Haforu CLI | 150-200 jobs/sec | âœ… Good for batch (100+ fonts) |

**Key insight:** Subprocess overhead (~21ms) makes CLI poor for per-call rendering, but excellent for batch. Python bindings have zero subprocess overhead, perfect for hot paths.

---

## Install

### Python Bindings (Recommended for FontSimi)

```bash
# Using pip (if published)
pip install haforu

# Or build from source
cd haforu-src
source /path/to/venv/bin/activate
uvx maturin develop --release --features python

# Verify installation
python -c "import haforu; print('Version:', haforu.__version__)"
```

### CLI Binary

```bash
# Using cargo (if published)
cargo install haforu

# Or build from source
cd haforu-src
cargo build --release
./target/release/haforu --version
```

### Requirements

- **For Python bindings:** Python 3.8+, Rust 1.70+ (build-time only)
- **For CLI binary:** Rust 1.70+
- **Runtime:** No compiler needed for pip-installed wheels

---

## Quick Start

### Python Bindings (Image Processing)

```python
import haforu
import numpy as np

# Image alignment and comparison (3-5Ã— faster than Python)
img1 = np.random.randint(0, 256, (200, 1200), dtype=np.uint8)
img2 = np.random.randint(0, 256, (200, 1200), dtype=np.uint8)

result = haforu.align_and_compare(img1, img2, method="center")
print(f"Pixel delta: {result.pixel_delta:.4f}")
print(f"Center-weighted delta: {result.center_weighted_delta:.4f}")

# Image scaling (2-3Ã— faster than OpenCV)
scaled = haforu.resize_bilinear(img1, multiplier=0.5)
print(f"Scaled to: {scaled.width}Ã—{scaled.height}")

# Text rendering with streaming session (<1ms per render)
import json

with haforu.StreamingSession(max_fonts=512, max_glyphs=2048) as session:
    # Render to JSON
    job = {
        "id": "test",
        "font": {"path": "/path/to/font.ttf", "size": 1000},
        "text": {"content": "A"},
        "rendering": {"format": "pgm", "encoding": "base64", "width": 3000, "height": 1200}
    }
    result = session.render(json.dumps(job))

    # Or render directly to numpy array (zero-copy)
    image = session.render_to_numpy(
        font_path="/path/to/font.ttf",
        text="A",
        size=1000.0,
        width=3000,
        height=1200,
        variations={"wght": 600.0}
    )
    # Returns numpy.ndarray, shape (height, width), dtype uint8
```

### CLI Binary (Text Rendering)

```bash
# Single render
haforu render -f font.ttf -t "Hello" -s 72 -o output.pgm

# Batch processing (best use case for CLI)
echo '{
  "version": "1.0",
  "jobs": [{
    "id": "test1",
    "font": {"path": "/path/to/font.ttf", "size": 1000},
    "text": {"content": "A"},
    "rendering": {"format": "pgm", "encoding": "base64", "width": 3000, "height": 1200}
  }]
}' | haforu batch > results.jsonl

# Streaming mode (line-by-line JSONL)
haforu stream < jobs.jsonl > results.jsonl

# Metrics only (10,000-20,000 jobs/sec)
haforu render -f font.ttf -t "A" -s 256 --format metrics
```

---

## Architecture

### Rendering Pipeline

```
Input: Font + Text + Parameters
  â†“
FontLoader (memory-mapped, LRU cached)
  â†“
HarfBuzz Shaping
  â†“
Zeno Rasterization
  â†“
Output: PGM/PNG/Metrics JSON
```

**Key Features:**
- **Memory-mapped fonts:** Zero-copy loading via memmap2
- **LRU font cache:** 512 entries default (DashMap - lock-free)
- **Parallel batch processing:** Rayon for multi-core
- **Deterministic JSONL I/O:** Every error returns JSON, no crashes
- **SIMD optimizations:** AVX2 on x86_64, portable fallback

### Python Bindings (PyO3)

**Image Processing Operations:**

```python
# align_and_compare(img_a, img_b, method="center")
# â†’ AlignCompareResult {
#     aligned_a, aligned_b,  # Aligned images
#     pixel_delta,           # Mean absolute difference
#     center_weighted_delta, # Gaussian-weighted delta
#     density_a, density_b,  # Ink density
#     aspect_a, aspect_b     # Width/height ratio
#   }

# resize_bilinear(image, multiplier)
# â†’ ResizeResult { image, width, height }
```

**Text Rendering:**
- `StreamingSession` - Persistent session with font/glyph caching
- `render()` - Render job, return JSONL result
- `render_to_numpy()` - Render directly to numpy array (zero-copy)
- `warm_up()`, `ping()`, `cache_stats()` - Session management

---

## Performance

### Actual Performance (v2.0.x with SIMD)

| Mode | Throughput | Use Case |
|------|-----------|----------|
| **CLI Batch** | 150-200 jobs/sec | âœ… Batch analysis (100+ fonts) |
| **Python Bindings** | 1000-2000 jobs/sec | âœ… Hot paths (SIMD-accelerated) |
| **Metrics Mode** | 10,000-20,000 jobs/sec | âœ… Feature extraction (SIMD) |
| **Variation Sweep** | ~30-40 coords/ms | âœ… Font matching optimization |

### Detailed Timings

**CLI:**
- Single render: <10ms cold, ~5ms warm
- Batch (1000 jobs): <5s on 8 cores (40-50% faster than baseline)
- Memory: <500MB for 1000 renders

**Python Bindings:**
- Single render: <1ms warmed cache with SIMD
- Metrics mode: <0.05ms per job (4-8Ã— faster with SIMD)
- Variation sweep (80 coords): ~2-3ms on 8 cores
- Image alignment: 1.6ms (was ~5-8ms in Python/numpy)
- Image scaling: 0.3ms (was ~1ms in OpenCV)

### Key Optimizations

1. **SIMD-Accelerated Metrics** (4-8Ã— speedup)
   - AVX2 for density/beam calculations on x86_64
   - Portable fallback for other platforms

2. **Lock-Free Font Cache** (20% speedup)
   - DashMap eliminates lock contention
   - Scales linearly on high thread counts

3. **Thread-Local Buffer Pools** (10-15% speedup)
   - Eliminates allocation overhead in tight loops

4. **Batch Variation Sweep** (5-8Ã— speedup)
   - Parallel rendering across cores
   - Optimized for font matching (30-180 calls per font)

5. **HarfBuzz Font Caching** (20% speedup)
   - Caches HarfBuzz Font objects
   - Eliminates repeated Face/Font creation

---

## CLI Commands

### batch

Read full JSON, process in parallel:

```bash
haforu batch [--max-fonts N] [--max-glyphs N] [--jobs N] [--stats]
```

### stream

Line-by-line JSONL processing:

```bash
haforu stream [--max-fonts N] [--max-glyphs N]
```

### render

Single text render (HarfBuzz-compatible):

```bash
haforu render -f FONT -t TEXT [-s SIZE] [-o OUTPUT] [--format pgm|png|metrics]
```

### diagnostics

Show system info and defaults:

```bash
haforu diagnostics [--format text|json]
```

### validate

Check job specification:

```bash
haforu validate < jobs.json
```

**Cache Tuning:**
- `--max-fonts N` - Font cache size (default: 512)
- `--max-glyphs N` - Glyph cache size (default: 2048, 0 to disable)
- `--jobs N` - Parallel workers (default: CPU count)

---

## Python API

### `haforu.align_and_compare(img_a, img_b, method="center")`

Align images and compute pixel delta (3-5Ã— faster than Python/numpy).

**Parameters:**
- `img_a, img_b` - numpy arrays (uint8, 2D)
- `method` - Alignment method: "center" (default)

**Returns:** `AlignCompareResult` with aligned images, pixel delta, density, aspect

### `haforu.resize_bilinear(image, multiplier)`

Bilinear image scaling (2-3Ã— faster than OpenCV).

**Parameters:**
- `image` - numpy array (uint8, 2D)
- `multiplier` - Scale factor (float)

**Returns:** `ResizeResult` with scaled image, width, height

### `haforu.StreamingSession(max_fonts=512, max_glyphs=2048)`

Persistent rendering session with font/glyph caching.

**Methods:**
- `render(job_json: str) -> str` - Render job, return JSONL result
- `render_to_numpy(...) -> np.ndarray` - Render directly to numpy array (zero-copy)
- `warm_up(font_path: str) -> bool` - Warm up cache
- `ping() -> bool` - Liveness check
- `cache_stats() -> dict` - Inspect cache state
- `set_cache_size(n: int)` - Resize font cache
- `set_glyph_cache_size(n: int)` - Resize glyph cache
- `close()` - Release resources

### `haforu.is_available() -> bool`

Check if native extension is available.

### Batch Variation Sweep API

Optimized for font matching - render same glyph at multiple variation coordinates in parallel.

```python
from haforu.varsweep import SweepConfig, render_variation_sweep
from haforu import FontLoader, ExecutionOptions

# Generate variation coordinates
coord_sets = []
for wght in range(100, 950, 50):
    coord_sets.append({"wght": float(wght)})

config = SweepConfig(
    font_path="/path/to/font.ttf",
    font_size=1000,
    text="A",
    width=3000,
    height=1200,
    coord_sets=coord_sets,  # Render at all coordinates in parallel
)

font_loader = FontLoader(512)
options = ExecutionOptions(None, None)
options.set_glyph_cache_capacity(2048)

# Parallel rendering across cores (5-8Ã— speedup)
results = render_variation_sweep(config, font_loader, options)

for point in results:
    print(f"wght={point.coords['wght']}: density={point.metrics.density:.4f}")
```

**Performance:** Renders 80 coordinates in ~2-3ms on 8 cores (vs ~16ms sequential).

See `examples/python/varsweep_demo.py` for complete examples.

---

## Job Format

### Input (Batch)

```json
{
  "version": "1.0",
  "jobs": [{
    "id": "unique_id",
    "font": {
      "path": "/path/to/font.ttf",
      "size": 1000,
      "variations": {"wght": 600.0}
    },
    "text": {"content": "A", "script": "Latn"},
    "rendering": {
      "format": "pgm",
      "encoding": "base64",
      "width": 3000,
      "height": 1200
    }
  }]
}
```

### Output (JSONL)

```json
{"id": "unique_id", "status": "success", "rendering": {...}, "timing": {...}}
{"id": "unique_id", "status": "error", "error": "Font not found", "timing": {...}}
```

### Metrics Output

```json
{
  "id": "unique_id",
  "status": "success",
  "metrics": {"density": 0.48, "beam": 0.012},
  "timing": {"shape_ms": 1.1, "render_ms": 0.7, "total_ms": 2.0}
}
```

---

## Building from Source

### CLI Binary

```bash
cargo build --release
export HAFORU_BIN="$PWD/target/release/haforu"
```

### Python Bindings

```bash
# Dev build (fast iteration)
pip install maturin
maturin develop

# Release build
maturin develop --release --features python

# Wheels for distribution
maturin build --release
```

---

## Testing

```bash
# Rust tests (41 tests)
cargo test

# Python tests
pip install -e .
pytest python/tests

# Smoke test (validates CLI contract in ~2s)
./scripts/batch_smoke.sh
```

---

## Error Handling

All errors return JSON with `status: "error"` and descriptive messages. No crashes, no silent failures.

**Common Errors:**
- Font not found â†’ `"Font file not found: /path/to/font.ttf"`
- Invalid variation â†’ `"Unknown variation axis: slnt"`
- Shaping failed â†’ `"Text shaping failed for 'text'"`

---

## Integration with FontSimi

Haforu powers FontSimi's font matching pipeline with **10-20Ã— speedup** through optimization-specific APIs:

### Primary Use: Image Processing (Python Bindings)

```python
import haforu

# Align and compare images (3-5Ã— faster than Python/numpy)
result = haforu.align_and_compare(original_img, candidate_img, method="center")
pixel_delta = result.pixel_delta

# Scale images (2-3Ã— faster than OpenCV)
scaled = haforu.resize_bilinear(image, multiplier=0.9)
```

**Call frequency:** 30-180 calls per font match
**Total impact:** 3-5Ã— speedup for deep matching pipeline

### Secondary Use: Text Rendering Fallback (CLI)

Only when CoreText/HarfBuzz/Skia unavailable (rare). Use case: batch processing 100+ fonts.

Set `HAFORU_BIN` environment variable to use CLI mode, or import `haforu` for Python bindings.

---

## Use Cases

### 1. Font Matching Optimization (PRIMARY)

**Problem:** FontSimi needs to render same glyph at 80+ variation coordinates during optimization.

**Solution:** Batch variation sweep API + Python bindings

**Performance:** 80 coords in ~2-3ms (parallel) vs ~16ms (sequential) = **5-8Ã— speedup**

```python
from haforu.varsweep import render_variation_sweep

# Generate coordinates
coord_sets = [{"wght": w} for w in range(100, 950, 50)]

# Parallel rendering
results = render_variation_sweep(config, font_loader, options)
```

### 2. Image Processing Hot Paths

**Problem:** Python/numpy image operations (align, scale, compare) in tight loops.

**Solution:** Rust-optimized Python bindings

**Performance:** 3-5Ã— speedup for alignment, 2-3Ã— for scaling

```python
# 30-180 calls per font match
for iteration in optimization_loop:
    aligned = haforu.align_and_compare(original, candidate, "center")
    scaled = haforu.resize_bilinear(image, multiplier)
```

### 3. Batch Font Analysis (FALLBACK)

**Problem:** Analyze 100+ fonts when native renderers unavailable.

**Solution:** Haforu CLI batch mode

**Performance:** 150-200 jobs/sec on 8 cores

```bash
# Generate jobs for all fonts
generate_jobs > jobs.json

# Batch processing (amortizes subprocess overhead)
haforu batch < jobs.json > results.jsonl
```

---

## Dependencies

**Core:** read-fonts 0.22, skrifa 0.22, harfbuzz_rs 2.0, zeno 0.3, memmap2 0.9, dashmap 6.1, rayon 1.10

**Python:** pyo3 0.22, numpy 0.22

---

## License

MIT OR Apache-2.0

---

**Status:** Production Ready
**Version:** v2.0.x
**Last Updated:** 2025-11-15
</document_content>
</document>

<document index="10">
<source>SIMPLIFICATION-SUMMARY.md</source>
<document_content>
---
this_file: SIMPLIFICATION-SUMMARY.md
---

# Haforu Documentation Simplification - Summary

**Date:** 2025-11-14
**Goal:** Remove enterprise bloat, focus on core mission: fast font rendering for CLI and Python

## Changes Made

### File-by-File Breakdown

| File | Before | After | Change | Key Improvements |
|------|--------|-------|--------|------------------|
| CLAUDE.md | 64 lines | 153 lines | +89 (+139%) | More detailed but focused guide, removed enterprise mindset |
| PLAN.md | 106 lines | 94 lines | -12 (-11%) | Removed Phase 3 infrastructure tasks, focus on core features |
| TODO.md | 56 lines | 54 lines | -2 (-4%) | Flat actionable list, removed project management overhead |
| WORK.md | 263 lines | 53 lines | -210 (-80%) | Removed historical logs, simple current work tracker |
| README.md | 595 lines | 278 lines | -317 (-53%) | Essential documentation only, massive simplification |
| **Total** | **1084 lines** | **632 lines** | **-452 (-42%)** | **Much clearer focus** |

### What Was Removed

#### From PLAN.md
- âœ‚ï¸ Phase 3: Repository Canonicalization
- âœ‚ï¸ Phase 3: Build Reliability (Local & GitHub Actions)
- âœ‚ï¸ Phase 3: Automatic SemVer & Tag-Driven Releases
- âœ‚ï¸ All "enterprise infrastructure" tasks

#### From TODO.md
- âœ‚ï¸ Repository canonicalization checklist
- âœ‚ï¸ Build reliability tasks
- âœ‚ï¸ Automatic semver tasks
- âœ‚ï¸ Complex CI/CD workflow items

#### From WORK.md
- âœ‚ï¸ 200+ lines of historical work logs
- âœ‚ï¸ Phase 3 completion summaries
- âœ‚ï¸ Detailed profiling results archives
- âœ‚ï¸ CLI documentation completion notes

#### From README.md
- âœ‚ï¸ Redundant examples (reduced 5+ examples to 2 essential ones)
- âœ‚ï¸ Excessive CLI documentation (moved to separate doc)
- âœ‚ï¸ Over-detailed explanations
- âœ‚ï¸ Troubleshooting section (kept essentials in Error Handling)
- âœ‚ï¸ H2-H5 roadmap references
- âœ‚ï¸ Multiple installation methods (consolidated)

### What Remains (Core Focus)

#### CLAUDE.md (Development Guide)
- Core mission statement
- Project structure
- What we do (and don't do)
- Simple development workflow
- Code principles
- Performance targets
- Common tasks
- Anti-patterns to avoid

#### PLAN.md (Focused Roadmap)
1. Error handling consistency
2. Variation coordinate validation
3. Metrics-only output reliability
4. Python StreamingSession reliability
5. Cross-platform build verification

#### TODO.md (Actionable Tasks)
- 54 concrete, actionable items
- Organized by plan section
- No project management overhead
- Simple checkboxes

#### WORK.md (Current Session)
- Current work tracker
- Simple template for logging work
- No historical archives

#### README.md (Essential Documentation)
- What it does (1 section)
- How to install (1 section)
- Quick start (CLI + Python)
- Architecture (simple diagram)
- Performance numbers
- CLI commands reference
- Python API reference
- Job format spec
- Building from source
- Testing

## Core Mission (Reaffirmed)

**Haforu is:** A fast font renderer for CLI and Python

**Haforu does:**
1. Render glyphs to PGM/PNG/metrics
2. Process batches in parallel via CLI
3. Stream jobs continuously
4. Provide <2ms Python bindings with caching

**Haforu does NOT:**
- Build complex release infrastructure
- Implement analytics or monitoring
- Reorganize repository structure
- Add enterprise patterns
- Support features beyond core rendering

## Validation

âœ… Project builds successfully: `cargo build --release`
âœ… All file references updated with `this_file` annotations
âœ… Documentation is consistent and focused
âœ… No functionality removed, only documentation simplified

## Next Steps

Refer to `TODO.md` for the next actionable task. The focus is now purely on:
1. Making rendering more reliable
2. Making rendering faster
3. Making rendering work cross-platform

Everything else is out of scope.

---

**Delete this file after review** - it's just a transition summary.
</document_content>
</document>

<document index="11">
<source>TODO.md</source>
<document_content>
---
this_file: TODO.md
---

# Haforu Task List

## âœ… PRODUCTION READY

All critical work complete! Haforu serving dual purposes successfully:
1. **Image processing** (Python bindings) - PRIMARY use in fontsimi
2. **Text rendering** (CLI) - FALLBACK use in fontsimi

### Performance Achievements âœ…
- Metrics mode: <0.05ms per job (SIMD-accelerated) âœ“
- Python bindings: <1ms per render (warmed cache) âœ“
- Batch (1000 jobs): <5s on 8 cores âœ“
- Image operations: 3-5x faster than Python/numpy âœ“

### Optimizations Complete âœ…
- [x] SIMD-accelerated metrics (density, beam, bbox) - 4-8Ã— speedup
- [x] Thread-local buffer pooling - 10-15% speedup
- [x] Batch variation sweep API - 5-8Ã— speedup
- [x] Lock-free font cache (DashMap) - 20% speedup
- [x] HarfBuzz font caching - 20% speedup
- [x] `align_and_compare()` for fontsimi - 3-5Ã— speedup
- [x] `resize_bilinear()` for fontsimi - 2-3Ã— speedup

---

## Optional Future Enhancements

**Note:** Only pursue if explicitly requested. Current system production-ready.

### Error Handling (Nice to Have)
- [ ] Test CLI batch mode with malformed JSON - ensure error JobResults
- [ ] Test CLI stream mode with invalid JSONL - ensure error JobResults per line
- [ ] Test Python bindings with invalid jobs - ensure error JobResults returned
- [ ] Add regression tests for malformed inputs in `python/tests/test_errors.py`

### Variation Coordinate Validation (Nice to Have)
- [ ] Implement `validate_coordinates()` in `src/fonts.rs`
- [ ] Clamp `wght` to [100, 900] with warnings
- [ ] Clamp `wdth` to [50, 200] with warnings
- [ ] Warn and drop unknown axes
- [ ] Wire validation into `FontLoader::load_font`
- [ ] Surface sanitized coordinates in JobResult
- [ ] Add unit tests (in-range, out-of-range, unknown axes)

### Documentation (Incremental)
- [ ] Add Python quick start examples to README
- [ ] Document batch vs stream mode use cases
- [ ] Add performance comparison table
- [ ] Document cache tuning best practices
- [ ] Add real-world integration examples

### Cross-Platform Testing
- [ ] Test `cargo build --release` on Linux
- [ ] Test `cargo build --release` on Windows
- [ ] Test `maturin build` produces correct wheels for all platforms
- [ ] Verify wheels install without compiler
- [ ] Ensure `scripts/batch_smoke.sh` passes on all platforms

---

## Success Criteria - ALL MET âœ…

### Performance âœ…
- [x] CLI batch (1000 jobs): <5s on 8 cores (40-50% faster)
- [x] Python StreamingSession: <1ms per render (warmed)
- [x] Metrics mode: <0.05ms per job (4-8Ã— faster with SIMD)
- [x] Batch variation sweep (80 coords): ~2-3ms on 8 cores

### Correctness âœ…
- [x] All 41 Rust unit tests pass
- [x] CLI never drops jobs silently
- [x] Variation coordinates validated (skrifa handles this)
- [x] Cross-platform: macOS tested, Linux/Windows pending

### Integration with FontSimi âœ…
- [x] `align_and_compare()` working - 3-5Ã— speedup
- [x] `resize_bilinear()` working - 2-3Ã— speedup
- [x] Automatic fallback to Python/numpy when unavailable
- [x] End-to-end fontsimi speedup: 35-60Ã— total

---

## Image Processing Functions (Reference)

### Completed âœ…
- [x] **7A: align_and_compare()** - 1.6ms avg (3-5Ã— faster than Python)
- [x] **7C: resize_bilinear()** - 0.3ms avg (2-3Ã— faster than Python)

### Optional Future Work
- [ ] **7B: Integrated Rendering Metrics** - Return density/aspect during rendering
- [ ] **7D: Multi-Component Scoring** - Weighted score calculation in Rust
- [ ] **7E: SSIM Computation** - Structural similarity index
- [ ] **7F: Full Objective Function** - Complete renderâ†’score pipeline in Rust

---

## Non-Goals (Scope Boundary)

- âŒ No new output formats beyond PGM/PNG/metrics
- âŒ No retry logic, circuit breakers, or resilience patterns
- âŒ No analytics, monitoring, or telemetry systems
- âŒ No color, emoji, or subpixel rendering
- âŒ No complex configuration systems
- âŒ No automatic version tagging or release automation

---

**Status:** Production Ready
**Version:** v2.0.x
**Last Updated:** 2025-11-15
</document_content>
</document>

# File: /Users/adam/Developer/vcs/github.fontlaborg/haforu/benches/cli.rs
# Language: rust



<document index="12">
<source>build.sh</source>
<document_content>
#!/bin/bash
set -e

echo "Building Rust CLI and Python package..."
cargo build --release
uv pip install --system --upgrade -e .

echo "Running tests..."
cargo test
uvx hatch test

echo "Building wheels..."
rm -rf target/wheels
uvx maturin build --release

echo "Done."
</document_content>
</document>

<document index="13">
<source>docs/CLI-USAGE.md</source>
<document_content>
---
this_file: docs/CLI-USAGE.md
---

# Haforu CLI Usage Guide

Complete reference for the haforu command-line interface. Both Rust CLI (`haforu`) and Python CLI (`python -m haforu`) support identical commands and JSON contracts.

## Table of Contents

- [Quick Start](#quick-start)
- [Commands](#commands)
  - [batch](#batch---batch-processing)
  - [stream](#stream---streaming-mode)
  - [render](#render---single-render)
  - [validate](#validate---job-validation)
  - [diagnostics](#diagnostics---system-info)
  - [version](#version---version-display)
- [JSON Contract](#json-contract)
- [Streaming JSON (JSONL)](#streaming-json-jsonl)
- [Error Handling](#error-handling)
- [Performance Tuning](#performance-tuning)
- [Examples](#examples)

## Quick Start

```bash
# Render a single glyph (metrics only)
haforu render -f font.ttf -s 256 -t "A" --format metrics

# Batch process multiple jobs
echo '{"version":"1.0","jobs":[...]}' | haforu batch

# Stream JSONL jobs
cat jobs.jsonl | haforu stream

# Validate a job specification
haforu validate < jobs.json

# Display system diagnostics
haforu diagnostics
```

## Commands

### batch - Batch Processing

Process multiple rendering jobs from a single JSON input.

**Usage:**
```bash
haforu batch [OPTIONS] < input.json
```

**Options:**
- `--max-fonts <N>` - Maximum fonts to cache (default: 512)
- `--max-glyphs <N>` - Maximum glyphs to cache (default: 2048)
- `--jobs <N>` - Number of parallel workers (default: CPU count)
- `--timeout-ms <MS>` - Per-job timeout in milliseconds (0 = disabled)
- `--base-dir <PATH>` - Restrict font paths to this directory
- `--stats` - Emit throughput statistics to stderr

**Input Format:**
```json
{
  "version": "1.0",
  "jobs": [
    {
      "id": "job-1",
      "font": {
        "path": "/path/to/font.ttf",
        "size": 256,
        "variations": {"wght": 700, "wdth": 100}
      },
      "text": {
        "content": "A",
        "script": "Latn",
        "language": "en",
        "direction": "ltr",
        "features": ["liga=0", "kern"]
      },
      "rendering": {
        "format": "metrics",
        "encoding": "json",
        "width": 64,
        "height": 64
      }
    }
  ]
}
```

**Output:** JSONL stream (one result per line)
```json
{"id":"job-1","status":"success","metrics":{"density":0.627,"beam":0.0144},"font":{"path":"/path/to/font.ttf"},"timing":{"shape_ms":0.0,"render_ms":0.0,"total_ms":0.06}}
```

**Example:**
```bash
# Process batch with custom cache settings
haforu batch --max-fonts 128 --max-glyphs 1024 < jobs.json > results.jsonl

# With statistics
haforu batch --stats < jobs.json 2>stats.json > results.jsonl
```

### stream - Streaming Mode

Process jobs one at a time from JSONL input (no job array wrapper).

**Usage:**
```bash
haforu stream [OPTIONS] < input.jsonl
```

**Options:**
- `--max-fonts <N>` - Maximum fonts to cache (default: 512)
- `--max-glyphs <N>` - Maximum glyphs to cache (default: 2048)
- `--stats` - Emit statistics to stderr

**Input Format:** One job per line (JSONL)
```json
{"id":"job-1","font":{"path":"font.ttf","size":256,"variations":{}},"text":{"content":"A"},"rendering":{"format":"metrics","encoding":"json","width":64,"height":64}}
{"id":"job-2","font":{"path":"font.ttf","size":256,"variations":{}},"text":{"content":"B"},"rendering":{"format":"metrics","encoding":"json","width":64,"height":64}}
```

**Output:** JSONL stream (one result per line)
```json
{"id":"job-1","status":"success","metrics":{"density":0.627,"beam":0.0144},"font":{"path":"font.ttf"},"timing":{"shape_ms":0.0,"render_ms":0.0,"total_ms":0.05}}
{"id":"job-2","status":"success","metrics":{"density":0.523,"beam":0.0122},"font":{"path":"font.ttf"},"timing":{"shape_ms":0.0,"render_ms":0.0,"total_ms":0.04}}
```

**Example:**
```bash
# Stream processing
cat jobs.jsonl | haforu stream > results.jsonl

# With warm cache for maximum throughput
haforu stream --max-fonts 256 --max-glyphs 2048 < large-jobs.jsonl
```

### render - Single Render

Render a single text string (convenience command with HarfBuzz-compatible syntax).

**Usage:**
```bash
haforu render -f FONT -s SIZE -t TEXT [OPTIONS]
```

**Required Options:**
- `-f, --font-file <PATH>` - Path to font file
- `-s, --font-size <SIZE>` - Font size in points
- `-t, --text <TEXT>` - Text to render

**Optional:**
- `--format <FORMAT>` - Output format: pgm, png, metrics (default: pgm)
- `--variations <SPEC>` - Font variations: "wght=700,wdth=100" or JSON
- `--script <SCRIPT>` - Script hint (e.g., "Latn", "Arab")
- `--language <LANG>` - Language tag (e.g., "en", "ar")
- `--direction <DIR>` - Text direction: ltr, rtl, ttb, btt (default: ltr)
- `--features <FEATURES>` - OpenType features: "liga=0,kern"
- `--width <W>` - Canvas width in pixels (default: 800)
- `--height <H>` - Canvas height in pixels (default: 200)
- `-o, --output-file <PATH>` - Output file (stdout if not specified)

**Examples:**
```bash
# Metrics only (fast)
haforu render -f font.ttf -s 256 -t "A" --format metrics

# PGM image output
haforu render -f font.ttf -s 72 -t "Hello" --format pgm -o output.pgm

# Variable font with variations
haforu render -f variable.ttf -s 256 -t "A" \
  --variations "wght=700,wdth=100" --format metrics

# Arabic text with shaping
haforu render -f arabic.ttf -s 72 -t "Ù…Ø±Ø­Ø¨Ø§" \
  --script Arab --language ar --direction rtl --format png -o arabic.png

# With OpenType features
haforu render -f font.ttf -s 72 -t "ffi" \
  --features "liga=1" --format pgm
```

**HarfBuzz Compatibility:**
The `render` command uses HarfBuzz-compatible flag names for easy migration:
- `-f` / `--font-file` (like `hb-view --font-file`)
- `-s` / `--font-size` (like `hb-view --font-size`)
- `-t` / `--text` (like `hb-view --text`)
- `--variations` (like `hb-view --variations`)

Use `haforu render --help-harfbuzz` for migration examples.

### validate - Job Validation

Validate a JSON job specification without executing it.

**Usage:**
```bash
haforu validate [FILE]
```

**Example:**
```bash
# Validate from stdin
haforu validate < jobs.json

# Validate from file
haforu validate jobs.json

# Check if valid (exit code 0 = valid, 1 = invalid)
if haforu validate jobs.json; then
  echo "Valid"
fi
```

**Output on success:**
```
âœ“ Valid job specification
  Version: 1.0
  Jobs: 10
```

**Output on failure:**
```
Validation failed:
  - Job [2]: Missing 'font.path'
  - Job [5]: 'font.size' must be a number
```

### diagnostics - System Info

Display system diagnostics and default settings.

**Usage:**
```bash
haforu diagnostics [--format FORMAT]
```

**Options:**
- `--format <FORMAT>` - Output format: text (default) or json

**Example:**
```bash
# Human-readable
haforu diagnostics

# JSON format
haforu diagnostics --format json
```

**Output (text):**
```
haforu 2.0.0
Status       : ok
CPU threads  : 8
Cache defaults: fonts=512 glyphs=2048
Security     : max_json_size=100MB
```

**Output (JSON):**
```json
{
  "status": "ok",
  "version": "2.0.0",
  "cpu_count": 8,
  "cache_defaults": {
    "max_fonts": 512,
    "max_glyphs": 2048
  },
  "security": {
    "max_json_size": 104857600
  }
}
```

### version - Version Display

Print version information.

**Usage:**
```bash
haforu version
# or
haforu --version
```

**Output:**
```
haforu 2.0.0
```

## JSON Contract

### Job Specification

A complete job specification:

```json
{
  "id": "unique-job-id",
  "font": {
    "path": "/absolute/path/to/font.ttf",
    "size": 256,
    "variations": {
      "wght": 700.0,
      "wdth": 100.0
    }
  },
  "text": {
    "content": "A",
    "script": "Latn",
    "language": "en",
    "direction": "ltr",
    "features": ["liga=0", "kern"]
  },
  "rendering": {
    "format": "metrics",
    "encoding": "json",
    "width": 64,
    "height": 64
  }
}
```

**Field Reference:**

| Field | Type | Required | Description |
|-------|------|----------|-------------|
| `id` | string | Yes | Unique job identifier |
| `font.path` | string | Yes | Absolute path to font file |
| `font.size` | number | Yes | Font size in points (typically 256 for metrics) |
| `font.variations` | object | No | Variable font coordinates (axis â†’ value) |
| `text.content` | string | Yes | Text to render |
| `text.script` | string | No | Script hint (ISO 15924 code, e.g., "Latn", "Arab") |
| `text.language` | string | No | Language tag (e.g., "en", "ar") |
| `text.direction` | string | No | Text direction: "ltr", "rtl", "ttb", "btt" |
| `text.features` | array | No | OpenType features (e.g., ["liga=0", "kern"]) |
| `rendering.format` | string | Yes | Output format: "pgm", "png", "metrics" |
| `rendering.encoding` | string | Yes | Encoding: "base64" (images) or "json" (metrics) |
| `rendering.width` | number | Yes | Canvas width in pixels |
| `rendering.height` | number | Yes | Canvas height in pixels |

### Job Result

Successful result:

```json
{
  "id": "job-1",
  "status": "success",
  "metrics": {
    "density": 0.6270029105392156,
    "beam": 0.014404296875
  },
  "font": {
    "path": "/path/to/font.ttf",
    "variations": {"wght": 700.0}
  },
  "timing": {
    "shape_ms": 0.0,
    "render_ms": 0.0,
    "total_ms": 0.06
  }
}
```

Error result:

```json
{
  "id": "job-2",
  "status": "error",
  "error": "Font file not found: /missing/font.ttf"
}
```

**Result Fields:**

| Field | Type | Always Present | Description |
|-------|------|----------------|-------------|
| `id` | string | Yes | Job identifier (from input) |
| `status` | string | Yes | "success" or "error" |
| `error` | string | Only on error | Error message |
| `metrics` | object | Only on success (metrics mode) | Density and beam measurements |
| `rendering` | object | Only on success (image mode) | Image data and metadata |
| `font` | object | Only on success | Sanitized font info |
| `timing` | object | Only on success | Performance timings |

## Streaming JSON (JSONL)

Haforu uses **JSON Lines (JSONL)** format for streaming:
- One JSON object per line
- Each line is a complete, valid JSON object
- No commas between lines
- Newline-delimited (`\n`)

**Benefits:**
- âœ… Process jobs incrementally (low memory)
- âœ… Start producing results immediately
- âœ… Handle unlimited job counts
- âœ… Easy to generate/parse line-by-line

**Example Producer (Bash):**
```bash
#!/bin/bash
for i in {1..1000}; do
  cat <<EOF
{"id":"job-$i","font":{"path":"font.ttf","size":256,"variations":{}},"text":{"content":"$i"},"rendering":{"format":"metrics","encoding":"json","width":64,"height":64}}
EOF
done | haforu stream
```

**Example Consumer (Python):**
```python
import json
import sys

# Read JSONL results
for line in sys.stdin:
    result = json.loads(line)
    if result['status'] == 'success':
        print(f"{result['id']}: density={result['metrics']['density']:.4f}")
    else:
        print(f"{result['id']}: ERROR - {result['error']}", file=sys.stderr)
```

## Error Handling

Haforu guarantees that **every input line produces an output line**, even on errors.

### Error Categories

1. **Parse Errors** - Invalid JSON
```json
{"id":"unknown","status":"error","error":"Invalid JSON: expected value at line 1 column 1"}
```

2. **Validation Errors** - Missing required fields
```json
{"id":"job-1","status":"error","error":"Missing required field: font.path"}
```

3. **Font Errors** - Font file issues
```json
{"id":"job-2","status":"error","error":"Font file not found: /missing/font.ttf"}
```

4. **Rendering Errors** - Rendering failures
```json
{"id":"job-3","status":"error","error":"Failed to shape text: unsupported script"}
```

### Error Handling Patterns

**Pattern 1: Filter successful jobs**
```bash
haforu batch < jobs.json | jq 'select(.status == "success")'
```

**Pattern 2: Count errors**
```bash
haforu stream < jobs.jsonl | jq -r 'select(.status == "error") | .id' | wc -l
```

**Pattern 3: Separate success/error streams**
```bash
haforu batch < jobs.json | \
  tee >(jq 'select(.status == "success")' > success.jsonl) | \
  jq 'select(.status == "error")' > errors.jsonl
```

**Pattern 4: Retry failed jobs**
```bash
# Extract failed job IDs
haforu batch < jobs.json | \
  jq -r 'select(.status == "error") | .id' > failed-ids.txt

# Regenerate and retry
cat jobs.json | jq '.jobs |= map(select(.id | IN($ids[])))' \
  --slurpfile ids failed-ids.txt | \
  haforu batch
```

## Performance Tuning

### Cache Configuration

**Rule of thumb:**
- `--max-fonts`: Number of unique fonts in your dataset
- `--max-glyphs`: ~50-100 per font for typical use

**Examples:**
```bash
# Small dataset (10 fonts, 50 glyphs each)
haforu batch --max-fonts 16 --max-glyphs 512 < jobs.json

# Large dataset (100 fonts, 1000 glyphs each)
haforu batch --max-fonts 128 --max-glyphs 2048 < jobs.json
```

### Parallel Processing

Use `--jobs` to control parallelism:

```bash
# Single-threaded (good for debugging)
haforu batch --jobs 1 < jobs.json

# Max parallelism (default: CPU count)
haforu batch --jobs 0 < jobs.json

# Custom worker count
haforu batch --jobs 4 < jobs.json
```

### Metrics-Only Mode

For fast bulk analysis, use `format: "metrics"`:

**Performance:**
- Metrics mode: ~0.2ms per job
- Image mode: ~2-5ms per job
- **Speedup: 10-25Ã—**

```bash
# Convert jobs to metrics-only
jq '.jobs[].rendering.format = "metrics"' < jobs.json | haforu batch
```

### Statistics Monitoring

Enable `--stats` to monitor throughput:

```bash
haforu batch --stats < large-jobs.json 2> stats.json > results.jsonl
```

**Stats output (JSON to stderr):**
```json
{
  "jobs_processed": 1000,
  "jobs_success": 985,
  "jobs_error": 15,
  "elapsed_ms": 2453.2,
  "jobs_per_sec": 407.6,
  "cache": {
    "fonts_loaded": 12,
    "fonts_cached": 12,
    "glyphs_cached": 850
  }
}
```

## Examples

### Example 1: Batch Process with Metrics

```bash
cat > jobs.json <<'EOF'
{
  "version": "1.0",
  "jobs": [
    {
      "id": "arial-A",
      "font": {"path": "Arial.ttf", "size": 256, "variations": {}},
      "text": {"content": "A"},
      "rendering": {"format": "metrics", "encoding": "json", "width": 64, "height": 64}
    },
    {
      "id": "arial-B",
      "font": {"path": "Arial.ttf", "size": 256, "variations": {}},
      "text": {"content": "B"},
      "rendering": {"format": "metrics", "encoding": "json", "width": 64, "height": 64}
    }
  ]
}
EOF

haforu batch < jobs.json | jq '.metrics'
```

**Output:**
```json
{"density":0.6270029105392156,"beam":0.014404296875}
{"density":0.5234375,"beam":0.01220703125}
```

### Example 2: Variable Font Exploration

```bash
# Generate jobs for different weights
for wght in 100 200 300 400 500 600 700 800 900; do
  cat <<EOF
{"id":"wght-$wght","font":{"path":"Variable.ttf","size":256,"variations":{"wght":$wght}},"text":{"content":"A"},"rendering":{"format":"metrics","encoding":"json","width":64,"height":64}}
EOF
done | haforu stream | jq '{id, density: .metrics.density}'
```

**Output:**
```json
{"id":"wght-100","density":0.421}
{"id":"wght-200","density":0.453}
{"id":"wght-300","density":0.489}
...
```

### Example 3: Parallel Batch with Error Handling

```bash
#!/bin/bash
set -euo pipefail

# Process jobs with error handling
haforu batch --jobs 8 --max-fonts 64 < large-jobs.json | \
  tee results.jsonl | \
  jq -r 'select(.status == "error") | "\(.id): \(.error)"' | \
  tee errors.log

# Check if any errors occurred
if [ -s errors.log ]; then
  echo "Errors occurred during processing:"
  cat errors.log
  exit 1
fi

echo "All jobs completed successfully"
```

### Example 4: Stream Processing Pipeline

```bash
# Generate jobs â†’ process â†’ aggregate metrics
seq 1 1000 | \
  awk '{print "{\"id\":\"" $1 "\",\"font\":{\"path\":\"font.ttf\",\"size\":256,\"variations\":{}},\"text\":{\"content\":\"" $1 "\"},\"rendering\":{\"format\":\"metrics\",\"encoding\":\"json\",\"width\":64,\"height\":64}}"}' | \
  haforu stream | \
  jq -s '{total: length, avg_density: ([.[].metrics.density] | add / length)}'
```

### Example 5: Font Comparison

```bash
# Compare same glyph across multiple fonts
for font in Font1.ttf Font2.ttf Font3.ttf; do
  haforu render -f "$font" -s 256 -t "A" --format metrics | \
    jq --arg font "$font" '{font: $font, density, beam}'
done
```

**Output:**
```json
{"font":"Font1.ttf","density":0.627,"beam":0.0144}
{"font":"Font2.ttf","density":0.543,"beam":0.0122}
{"font":"Font3.ttf","density":0.689,"beam":0.0156}
```

## See Also

- [Python API Documentation](./PYTHON-API.md)
- [Architecture Overview](../README.md#architecture)
- [Installation Guide](../INSTALL.md)
- [Performance Benchmarks](../WORK.md)

## Support

- **Issues**: https://github.com/fontlaborg/haforu/issues
- **Examples**: See `examples/` directory in the repository
- **Tests**: See `scripts/test-cli-parity.sh` for comprehensive CLI tests
</document_content>
</document>

<document index="14">
<source>docs/REPOSITORY.md</source>
<document_content>
---
this_file: docs/REPOSITORY.md
---

# Repository Structure & Best Practices

This document describes haforu's repository layout, build configuration, and adherence to Rust + PyO3 + Hatch best practices.

## Overview

Haforu is a **hybrid Rust + Python project** using:
- **Rust** - Core rendering engine (`src/`)
- **PyO3** - Python bindings (`src/python/`)
- **Maturin** - Build backend for Python wheels
- **Hatch** - Python testing and tooling
- **Fire** - Python CLI framework

## Directory Structure

```
haforu/
â”œâ”€â”€ .cargo/
â”‚   â””â”€â”€ config.toml          # Cargo configuration, build profiles, aliases
â”œâ”€â”€ .github/                  # GitHub Actions workflows (to be added)
â”œâ”€â”€ benches/
â”‚   â””â”€â”€ cli.rs               # Criterion benchmarks for CLI hot paths
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ CLI-USAGE.md         # Comprehensive CLI documentation
â”‚   â””â”€â”€ REPOSITORY.md        # This file
â”œâ”€â”€ examples/
â”‚   â””â”€â”€ python/              # Python usage examples
â”œâ”€â”€ python/
â”‚   â”œâ”€â”€ haforu/
â”‚   â”‚   â”œâ”€â”€ __init__.py      # Python package entry point
â”‚   â”‚   â”œâ”€â”€ __main__.py      # Fire CLI implementation
â”‚   â”‚   â””â”€â”€ _version.py      # Auto-generated version (hatch-vcs)
â”‚   â””â”€â”€ tests/               # Python test suite (pytest)
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ build.sh             # Comprehensive build script
â”‚   â”œâ”€â”€ run.sh               # Multi-mode test runner
â”‚   â”œâ”€â”€ profile-cli.sh       # Performance profiling
â”‚   â”œâ”€â”€ regression-test.sh   # Performance regression gates
â”‚   â””â”€â”€ test-cli-parity.sh   # Python/Rust CLI parity tests
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ batch.rs             # Job specification structs
â”‚   â”œâ”€â”€ error.rs             # Error types
â”‚   â”œâ”€â”€ fonts.rs             # Font loader with caching
â”‚   â”œâ”€â”€ lib.rs               # Public API
â”‚   â”œâ”€â”€ main.rs              # Rust CLI
â”‚   â”œâ”€â”€ output.rs            # Image output (PGM/PNG)
â”‚   â”œâ”€â”€ python/              # PyO3 bindings
â”‚   â”œâ”€â”€ render.rs            # Rasterization
â”‚   â”œâ”€â”€ security.rs          # Security validation
â”‚   â””â”€â”€ shaping.rs           # HarfBuzz shaping
â”œâ”€â”€ testdata/
â”‚   â””â”€â”€ fonts/               # Test fonts
â”œâ”€â”€ Cargo.toml               # Rust package manifest
â”œâ”€â”€ pyproject.toml           # Python package manifest
â”œâ”€â”€ CHANGELOG.md             # Release notes
â”œâ”€â”€ PLAN.md                  # Project planning
â”œâ”€â”€ TODO.md                  # Task tracking
â””â”€â”€ WORK.md                  # Work session notes
```

## Configuration Files

### Cargo.toml

**Purpose:** Rust package manifest and build configuration

**Key Sections:**
- `[package]` - Metadata (name, version, description, license)
- `[lib]` - Library configuration (`cdylib` for Python, `rlib` for Rust)
- `[[bin]]` - Binary target (haforu CLI)
- `[[bench]]` - Benchmark configuration
- `[dependencies]` - Production dependencies
- `[dev-dependencies]` - Test/benchmark dependencies
- `[features]` - Feature flags (default, python)
- `[profile.*]` - Build profiles (dev, release)

**Best Practices Applied:**
- âœ… Separate `cdylib` and `rlib` targets
- âœ… Explicit feature flags for Python bindings
- âœ… Optimized release profile (LTO, strip, single codegen-unit)
- âœ… Rust edition 2021
- âœ… MSRV documented (1.70)

### pyproject.toml

**Purpose:** Python package manifest and tool configuration

**Key Sections:**
- `[build-system]` - Maturin backend with hatch-vcs
- `[project]` - Package metadata
- `[project.scripts]` - Console entry points (`haforu-py`)
- `[tool.maturin]` - Maturin configuration
- `[tool.pytest.ini_options]` - Pytest configuration
- `[tool.hatch.version]` - VCS-based versioning
- `[tool.ruff]` - Linting configuration
- `[tool.mypy]` - Type checking configuration

**Best Practices Applied:**
- âœ… Dynamic versioning from git tags (hatch-vcs)
- âœ… Separate Python source directory (`python/`)
- âœ… Console entry point for CLI (`haforu-py`)
- âœ… Platform-specific optional dependencies
- âœ… Modern Python 3.8+ support
- âœ… Comprehensive metadata (classifiers, keywords)

### .cargo/config.toml

**Purpose:** Cargo build configuration and platform-specific settings

**Key Features:**
- Build profiles (dev, release, release-with-debug, bench, dist)
- Platform-specific rustflags
- Linker optimizations (LLD on Linux)
- Profiling support (frame pointers, debug symbols)
- Command aliases for convenience
- Network configuration (retries, git CLI)

**Best Practices Applied:**
- âœ… Frame pointers enabled for profiling
- âœ… Platform-specific optimizations
- âœ… Multiple build profiles for different use cases
- âœ… LTO and size optimizations for distribution
- âœ… Split debug info on macOS for faster builds
- âœ… Sparse registry protocol for faster downloads

## Build System

### Rust Build

```bash
# Development build
cargo build

# Release build (optimized)
cargo build --release

# With Python bindings
cargo build --release --features python

# Run tests
cargo test

# Run benchmarks
cargo bench
```

### Python Build

```bash
# Development install (editable)
pip install -e .

# Build wheels
maturin build --release

# Build and install
maturin develop --release

# Run tests
pytest python/tests/

# Or using hatch
hatch test
```

### Unified Build Script

```bash
# Comprehensive build + test + package
./scripts/build.sh

# Quick development build
./build.sh
```

## Version Management

### Current Approach

**Rust:** Manual versioning in `Cargo.toml`
- Version: `2.0.0`
- Updated manually for releases

**Python:** Dynamic versioning via hatch-vcs
- Reads from git tags
- Auto-generates `python/haforu/_version.py`
- Configured in `pyproject.toml`

### Recommended Approach (TODO)

Use **tag-driven versioning** for both:

1. Create git tag: `git tag -a v2.1.0 -m "Release 2.1.0"`
2. Push tag: `git push origin v2.1.0`
3. GitHub Actions:
   - Builds Rust binary
   - Builds Python wheels
   - Creates GitHub Release
   - Publishes to crates.io and PyPI

**Benefits:**
- Single source of truth (git tags)
- Automated releases
- No manual version bumps
- Consistent Rust + Python versions

## Testing Strategy

### Rust Tests

**Location:** Inline in `src/` modules
**Run:** `cargo test`

**Coverage:**
- 36 library tests (unit + integration)
- 13 main tests (CLI commands)
- Tests for: batch, fonts, render, streaming, output

### Python Tests

**Location:** `python/tests/`
**Run:** `pytest` or `hatch test`

**Coverage:**
- 65 tests total
- Tests for: batch, errors, numpy, streaming
- Includes bindings tests and CLI tests

### Integration Tests

**Scripts in `scripts/`:**
- `batch_smoke.sh` - Smoke tests for CLI contract
- `profile-cli.sh` - Performance profiling
- `regression-test.sh` - Performance regression detection
- `test-cli-parity.sh` - Python/Rust CLI parity (20 tests)

### Performance Tests

**Benchmarks:**
- `benches/cli.rs` - Criterion benchmarks (note: has serde version conflicts)
- `scripts/profile-cli.sh` - Hyperfine-based profiling
- `scripts/regression-test.sh` - Threshold-based gates

**Metrics:**
- Startup time: ~6.5ms
- Batch (100 jobs): ~7-8ms
- Streaming (1000 lines): ~10ms
- Metrics render: ~6ms
- PGM render: ~7.5ms

## Code Organization

### Rust Modules

**Principle:** Small, focused modules with clear responsibilities

- `batch.rs` - Data structures only (Job, JobSpec, JobResult)
- `fonts.rs` - Font loading and caching (FontLoader, FontInstance)
- `shaping.rs` - Text shaping (TextShaper, ShapedText)
- `render.rs` - Rasterization (GlyphRasterizer, Image)
- `output.rs` - Image encoding (ImageOutput, PGM/PNG)
- `error.rs` - Error types (Error, Result)
- `security.rs` - Security validation
- `lib.rs` - Public API and orchestration
- `main.rs` - CLI implementation

**Best Practices:**
- âœ… Separation of concerns
- âœ… Clear module boundaries
- âœ… Public API in `lib.rs`
- âœ… Minimal inter-module dependencies
- âœ… Comprehensive documentation

### Python Package

**Structure:**
- `python/haforu/__init__.py` - Public API (process_jobs, StreamingSession)
- `python/haforu/__main__.py` - Fire CLI (HaforuCLI class)
- `python/haforu/_version.py` - Auto-generated version
- `python/tests/` - Test suite

**Best Practices:**
- âœ… Clear public API
- âœ… Separate CLI implementation
- âœ… Type stubs for bindings
- âœ… Comprehensive tests

### PyO3 Bindings

**Location:** `src/python/`

**Pattern:**
- Thin wrappers around Rust API
- Python-friendly types (str, dict, list)
- Error conversion to Python exceptions (where appropriate)
- Iterator protocol for streaming

**Best Practices:**
- âœ… Minimal business logic in bindings
- âœ… Delegate to Rust core
- âœ… Pythonic API surface
- âœ… GIL release for CPU-intensive operations

## File Annotations

### `this_file` Convention

Every source file includes a header comment with its path relative to repository root:

**Rust:**
```rust
// this_file: src/main.rs
```

**Python:**
```python
# this_file: python/haforu/__init__.py
```

**Markdown:**
```markdown
---
this_file: docs/REPOSITORY.md
---
```

**Purpose:**
- Clear file identity
- Easy navigation
- Copy-paste context preservation
- LLM-friendly codebase exploration

## Development Workflow

### Local Development

1. **Clone repository:**
   ```bash
   git clone https://github.com/fontsimi/haforu.git
   cd haforu
   ```

2. **Build and test:**
   ```bash
   # Build everything
   ./scripts/build.sh

   # Run tests
   cargo test
   pytest python/tests/

   # Run smoke tests
   ./scripts/run.sh smoke
   ```

3. **Make changes:**
   - Edit Rust code in `src/`
   - Edit Python code in `python/haforu/`
   - Update tests
   - Update documentation

4. **Verify changes:**
   ```bash
   # Rust tests
   cargo test

   # Python tests
   hatch test

   # CLI parity
   ./scripts/test-cli-parity.sh

   # Performance
   ./scripts/regression-test.sh
   ```

5. **Update documentation:**
   - Update `CHANGELOG.md`
   - Update `WORK.md` with notes
   - Update `TODO.md` if applicable

### Release Workflow (Manual)

1. **Update versions:**
   - Bump version in `Cargo.toml`
   - Create git tag: `git tag -a v2.1.0 -m "Release 2.1.0"`

2. **Build and test:**
   ```bash
   ./scripts/build.sh
   cargo test
   hatch test
   ```

3. **Build artifacts:**
   ```bash
   # Rust binary
   cargo build --release

   # Python wheels
   maturin build --release
   ```

4. **Publish:**
   ```bash
   # Rust crate
   cargo publish

   # Python wheels
   maturin publish
   ```

5. **Tag and push:**
   ```bash
   git push origin v2.1.0
   ```

### Release Workflow (Automated - TODO)

GitHub Actions workflow triggered by `v*` tags:
1. Checkout code
2. Build Rust binary (multi-platform)
3. Build Python wheels (manylinux, macOS, Windows)
4. Run full test suite
5. Create GitHub Release
6. Publish to crates.io
7. Publish to PyPI

## Best Practices Compliance

### Rust Workspace Best Practices

âœ… **Applied:**
- Clear module structure
- Comprehensive Cargo.toml
- Feature flags for optional dependencies
- Optimized release profile
- Platform-specific configuration
- Benchmark configuration

âŒ **Not Applied (by design):**
- Workspace structure (single crate is appropriate for this project)
- Multiple binary targets (only one CLI needed)

### PyO3 Best Practices

âœ… **Applied:**
- Feature flag for Python bindings
- Separate source directory for Python code
- Type conversions at binding boundary
- GIL management
- Python-friendly API

âœ… **Excellent:**
- Streaming API with proper iterator protocol
- Error handling with custom exceptions
- Cache management from Python

### Hatch Best Practices

âœ… **Applied:**
- VCS-based versioning
- pytest configuration
- ruff configuration
- mypy configuration
- Development dependencies

âŒ **Not Applied (low priority):**
- Multiple test environments
- Matrix testing across Python versions

### Maturin Best Practices

âœ… **Applied:**
- Correct build backend configuration
- Python source directory specified
- Module name configured
- Feature selection

âœ… **Excellent:**
- Universal2 wheels for macOS
- Manylinux wheels for Linux
- Windows wheel support

## Deviations from Canonical Structure

### 1. Single Crate vs Workspace

**Current:** Single Rust crate at repository root
**Canonical:** Workspace with multiple crates

**Justification:**
- Project is cohesive single unit
- No need for sub-crates
- Simpler build and dependency management
- Appropriate for project size

### 2. PyO3 Bindings Location

**Current:** `src/python/` (within Rust crate)
**Alternative:** Separate `bindings/` directory

**Justification:**
- Keeps bindings close to Rust code
- Clear feature flag boundary
- Works well with Maturin
- Standard pattern for PyO3 projects

### 3. Python Package Location

**Current:** `python/` directory at root
**Alternative:** `py-haforu/` or separate repository

**Justification:**
- Maturin convention
- Clear separation from Rust source
- Supports independent Python development
- Recommended by Maturin documentation

## Performance Characteristics

### Build Times

**Rust (Release):**
- Clean build: ~2-3 minutes
- Incremental: ~10-30 seconds

**Python (Wheel):**
- Clean build: ~2-3 minutes (includes Rust)
- Maturin develop: ~30 seconds

**Full CI Build:**
- Estimated: ~10-15 minutes (multi-platform)

### Binary Sizes

**Rust Binary:**
- Release (stripped): ~2.4MB
- Release (with debug): ~15MB

**Python Wheel:**
- macOS (universal2): ~5-6MB
- Linux (manylinux): ~4-5MB
- Windows: ~3-4MB

### Runtime Performance

**CLI Startup:** ~6.5ms
**Throughput:** ~100k jobs/sec (streaming, metrics-only)
**Memory:** <100MB for typical workloads

## Known Issues

1. **Criterion Benchmarks:** serde_core version conflicts (low priority)
2. **Windows Testing:** Limited Windows CI coverage
3. **Documentation:** Some internal APIs undocumented

## Future Improvements

### High Priority
1. âœ… CLI documentation (DONE)
2. âœ… Performance profiling scripts (DONE)
3. âœ… CLI parity testing (DONE)
4. GitHub Actions CI/CD
5. Automated releases

### Medium Priority
1. Windows build testing
2. Cross-compilation support
3. Additional benchmarks
4. Coverage reporting

### Low Priority
1. Workspace structure (if project grows)
2. Separate PyO3 bindings crate
3. Cargo-vcs for Rust versioning
4. Pre-commit hooks

## See Also

- [CLI Usage Guide](./CLI-USAGE.md)
- [Installation Guide](../INSTALL.md)
- [Project Plan](../PLAN.md)
- [TODO List](../TODO.md)
</document_content>
</document>

# File: /Users/adam/Developer/vcs/github.fontlaborg/haforu/examples/python/batch_demo.py
# Language: python

import json
import sys
from pathlib import Path
import haforu

def main(()):


# File: /Users/adam/Developer/vcs/github.fontlaborg/haforu/examples/python/error_handling_demo.py
# Language: python

import json
import sys
from pathlib import Path
import haforu

def demo_batch_errors(()):

def demo_streaming_errors(()):

def demo_graceful_degradation(()):

def main(()):


# File: /Users/adam/Developer/vcs/github.fontlaborg/haforu/examples/python/metrics_demo.py
# Language: python

import json
import sys
from pathlib import Path
import haforu

def main(()) -> None:


# File: /Users/adam/Developer/vcs/github.fontlaborg/haforu/examples/python/numpy_demo.py
# Language: python

import sys
from pathlib import Path
import numpy as np
import haforu

def analyze_glyph_image((image: np.ndarray, glyph: str)) -> dict:

def main(()):


# File: /Users/adam/Developer/vcs/github.fontlaborg/haforu/examples/python/streaming_demo.py
# Language: python

import json
import sys
from pathlib import Path
import haforu

def main(()):


# File: /Users/adam/Developer/vcs/github.fontlaborg/haforu/examples/python/varsweep_demo.py
# Language: python

import sys
import time
from pathlib import Path
import haforu
from haforu import FontLoader, ExecutionOptions
from haforu.varsweep import SweepConfig, render_variation_sweep
import random
import traceback

def demo_weight_sweep(()):

def demo_multi_axis_sweep(()):

def demo_optimization_simulation(()):

def main(()):


# File: /Users/adam/Developer/vcs/github.fontlaborg/haforu/examples/smoke_test.rs
# Language: rust



<document index="15">
<source>llms.sh</source>
<document_content>
#!/usr/bin/env bash

cd "$(dirname "$0")"

llms . "*.txt,AGENTS.md,CLAUDE.md,GEMINI.md,LLXPRT.md,QWEN.md,WORK.md,issues,target,external,haforu"
</document_content>
</document>

<document index="16">
<source>pyproject.toml</source>
<document_content>
# this_file: pyproject.toml

[build-system]
requires = ["maturin>=1.0,<2.0", "hatch-vcs>=0.4.0"]
build-backend = "maturin"

[project]
name = "haforu"
dynamic = ["version"]
description = "High-performance batch font renderer for FontSimi"
readme = "README.md"
requires-python = ">=3.8"
license = { text = "MIT OR Apache-2.0" }
authors = [
    { name = "FontSimi Team" }
]
classifiers = [
    "Development Status :: 4 - Beta",
    "Intended Audience :: Developers",
    "License :: OSI Approved :: MIT License",
    "License :: OSI Approved :: Apache Software License",
    "Programming Language :: Python :: 3",
    "Programming Language :: Python :: 3.8",
    "Programming Language :: Python :: 3.9",
    "Programming Language :: Python :: 3.10",
    "Programming Language :: Python :: 3.11",
    "Programming Language :: Python :: 3.12",
    "Programming Language :: Rust",
    "Topic :: Multimedia :: Graphics",
    "Topic :: Software Development :: Libraries",
]
keywords = ["font", "rendering", "batch", "typography"]

dependencies = [
    "numpy>=1.20",
    "fire>=0.5.0",
]

[project.optional-dependencies]
dev = [
    "pytest>=7.0",
    "pytest-benchmark>=4.0",
    "pillow>=10.0",
    "hatch>=1.9.0",
]
# Platform-specific extras
mac = []  # macOS-specific dependencies (universal2 wheel)
windows = []  # Windows-specific dependencies
linux = []  # Linux-specific dependencies (manylinux wheel)
all = ["pillow>=10.0"]  # All optional dependencies

[project.urls]
Homepage = "https://github.com/fontsimi/haforu"
Repository = "https://github.com/fontsimi/haforu"

[project.scripts]
haforu-py = "haforu.__main__:main"

[tool.maturin]
features = ["python"]
python-source = "python"
module-name = "haforu._haforu"

[tool.pytest.ini_options]
testpaths = ["python/tests"]
python_files = ["test_*.py"]
python_classes = ["Test*"]
python_functions = ["test_*"]

[tool.ruff]
line-length = 100
target-version = "py38"

[tool.ruff.lint]
select = ["E", "F", "W", "I", "N", "UP", "YTT", "S", "B", "A", "C4", "T10", "T20", "Q"]
ignore = ["S101"]  # Allow assert in tests

[tool.mypy]
python_version = "3.8"
warn_return_any = true
warn_unused_configs = true
disallow_untyped_defs = true

[tool.hatch]

[tool.hatch.version]
source = "vcs"
raw-options = { root = "../.." }

[tool.hatch.build.hooks.vcs]
version-file = "python/haforu/_version.py"
</document_content>
</document>

# File: /Users/adam/Developer/vcs/github.fontlaborg/haforu/python/tests/test_batch.py
# Language: python

import json
import pytest
import haforu
import haforu
import haforu
import haforu
import haforu
import haforu
import haforu
import haforu
import haforu

def test_import_haforu(()):

def test_process_jobs_function_exists(()):

def test_process_jobs_empty_list(()):

def test_process_jobs_invalid_json(()):

def test_process_jobs_invalid_version(()):

def test_process_jobs_basic_structure(()):

def test_process_jobs_result_format(()):

def test_process_jobs_invalid_rendering_yields_error_payload(()):

def test_process_jobs_metrics_format_returns_metrics_payload(()):


# File: /Users/adam/Developer/vcs/github.fontlaborg/haforu/python/tests/test_errors.py
# Language: python

import json
import tempfile
from pathlib import Path
import pytest
import haforu

class TestMissingFontErrors:
    def test_process_jobs_missing_font((self)):
    def test_streaming_session_missing_font((self)):
    def test_render_to_numpy_missing_font((self)):

class TestInvalidFontErrors:
    def test_corrupted_font_file((self, tmp_path)):
    def test_empty_font_file((self, tmp_path)):

class TestJSONValidationErrors:
    def test_invalid_json_syntax((self)):
    def test_missing_version_field((self)):
    def test_invalid_version((self)):
    def test_empty_jobs_list((self)):
    def test_streaming_invalid_json((self)):

class TestRenderParameterValidation:
    def test_invalid_dimensions_zero_width((self)):
    def test_invalid_dimensions_zero_height((self)):
    def test_invalid_font_size_zero((self)):
    def test_invalid_font_size_negative((self)):

class TestEmptyTextHandling:
    def test_empty_text_content((self)):
    def test_whitespace_only_text((self)):

class TestVariationCoordinateErrors:
    def test_invalid_variation_axis_name((self)):
    def test_numpy_invalid_variation_type((self)):

class TestErrorMessageQuality:
    def test_error_includes_font_path((self)):
    def test_batch_error_includes_job_id((self)):
    def test_json_error_indicates_parse_issue((self)):
    def test_validation_error_indicates_reason((self)):

class TestContextManagerErrorHandling:
    def test_exception_in_context_manager((self)):
    def test_context_manager_cleanup_after_error((self)):

class TestEdgeCases:
    def test_very_large_dimensions((self)):
    def test_unicode_text_in_errors((self)):
    def test_multiple_jobs_some_failing((self)):

def test_process_jobs_missing_font((self)):

def test_streaming_session_missing_font((self)):

def test_render_to_numpy_missing_font((self)):

def test_corrupted_font_file((self, tmp_path)):

def test_empty_font_file((self, tmp_path)):

def test_invalid_json_syntax((self)):

def test_missing_version_field((self)):

def test_invalid_version((self)):

def test_empty_jobs_list((self)):

def test_streaming_invalid_json((self)):

def test_invalid_dimensions_zero_width((self)):

def test_invalid_dimensions_zero_height((self)):

def test_invalid_font_size_zero((self)):

def test_invalid_font_size_negative((self)):

def test_empty_text_content((self)):

def test_whitespace_only_text((self)):

def test_invalid_variation_axis_name((self)):

def test_numpy_invalid_variation_type((self)):

def test_error_includes_font_path((self)):

def test_batch_error_includes_job_id((self)):

def test_json_error_indicates_parse_issue((self)):

def test_validation_error_indicates_reason((self)):

def test_exception_in_context_manager((self)):

def test_context_manager_cleanup_after_error((self)):

def test_very_large_dimensions((self)):

def test_unicode_text_in_errors((self)):

def test_multiple_jobs_some_failing((self)):


# File: /Users/adam/Developer/vcs/github.fontlaborg/haforu/python/tests/test_numpy.py
# Language: python

import json
import pytest
import haforu
import haforu
import numpy as np
import haforu
import numpy as np
import haforu
import numpy as np
import haforu
import numpy as np
import haforu
import numpy as np
import haforu
import numpy as np
import haforu
import numpy as np
import haforu
import numpy as np
import haforu
import numpy as np
import haforu
import numpy as np
import haforu
import numpy as np
import base64

def test_render_to_numpy_import(()):

def test_render_to_numpy_basic(()):

def test_render_to_numpy_array_shape(()):

def test_render_to_numpy_dtype(()):

def test_render_to_numpy_with_variations(()):

def test_render_to_numpy_with_script_params(()):

def test_render_to_numpy_array_contiguous(()):

def test_render_to_numpy_value_range(()):

def test_render_to_numpy_context_manager(()):

def test_render_to_numpy_multiple_calls(()):

def test_render_to_numpy_parameter_validation(()):

def test_render_to_numpy_vs_base64_consistency(()):


# File: /Users/adam/Developer/vcs/github.fontlaborg/haforu/python/tests/test_streaming.py
# Language: python

import json
import pytest
import haforu
import haforu
import haforu
import haforu
import haforu
import haforu
import haforu
import haforu
import haforu
import haforu
import haforu
import haforu
import haforu
from pathlib import Path
import haforu
import haforu
import haforu
import haforu

def test_streaming_session_import(()):

def test_streaming_session_creation(()):

def test_streaming_session_custom_cache_size(()):

def test_streaming_session_cache_stats_and_resize(()):

def test_streaming_session_glyph_cache_reuses_results(()):

def test_streaming_session_can_disable_glyph_cache(()):

def test_streaming_session_close(()):

def test_streaming_session_context_manager(()):

def test_streaming_session_render_method_exists(()):

def test_streaming_session_render_invalid_json(()):

def test_streaming_session_warm_up_ping(()):

def test_streaming_session_render_single_job(()):

def test_streaming_session_multiple_renders(()):

def test_streaming_session_result_format(()):

def test_streaming_session_error_handling(()):

def test_streaming_session_metrics_format_returns_metrics_payload(()):

def test_haforu_module_is_available_probe(()):


<document index="17">
<source>run.sh</source>
<document_content>
#!/bin/bash
# this_file: run.sh

set -e

MODE="${1:-smoke}"

echo "Running haforu in '$MODE' mode..."
exec ./scripts/run.sh "$MODE"
</document_content>
</document>

<document index="18">
<source>scripts/batch_smoke.sh</source>
<document_content>
#!/usr/bin/env bash
# this_file: scripts/batch_smoke.sh

set -euo pipefail

ROOT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")/.." && pwd)"
cd "$ROOT_DIR"

JOBS_FILE="${JOBS_FILE:-$ROOT_DIR/scripts/jobs_smoke.jsonl}"
CACHE_SIZE="${CACHE_SIZE:-256}"
GLYPH_CACHE_SIZE="${GLYPH_CACHE_SIZE:-512}"
JOB_THREADS="${JOB_THREADS:-4}"

if [[ ! -r "$JOBS_FILE" ]]; then
  echo "Smoke jobs file not found: $JOBS_FILE" >&2
  exit 1
fi

BIN_PATH="${HAFORU_BIN:-$ROOT_DIR/target/release/haforu}"
if [[ ! -x "$BIN_PATH" ]]; then
  cargo build --release >/dev/null 2>&1
fi

if [[ ! -x "$BIN_PATH" ]]; then
  echo "haforu binary not found at $BIN_PATH" >&2
  exit 1
fi

OUTPUT_FILE="$(mktemp)"
trap 'rm -f "$OUTPUT_FILE"' EXIT

if ! "$BIN_PATH" batch \
  --max-fonts "$CACHE_SIZE" \
  --max-glyphs "$GLYPH_CACHE_SIZE" \
  --jobs "$JOB_THREADS" \
  < "$JOBS_FILE" | tee "$OUTPUT_FILE"; then
  echo "haforu batch run failed" >&2
  exit 1
fi

python3 <<'PY' "$OUTPUT_FILE"
import json
import pathlib
import sys

lines = [ln.strip() for ln in pathlib.Path(sys.argv[1]).read_text().splitlines() if ln.strip()]
if not lines:
    raise SystemExit("Smoke run produced no JSONL output")

expected = {
    "smoke-1": "success",
    "smoke-2": "success",
    "smoke-metrics": "success",
    "smoke-invalid": "error",
}

seen = {}
for raw in lines:
    try:
        payload = json.loads(raw)
    except json.JSONDecodeError as exc:
        raise SystemExit(f"Invalid JSONL line from haforu: {exc}: {raw!r}") from exc
    job_id = payload.get("id")
    status = payload.get("status")
    if job_id is None or status is None:
        raise SystemExit(f"Missing id/status in payload: {payload}")
    seen[job_id] = payload
    if job_id not in expected:
        raise SystemExit(f"Unexpected job id {job_id}; expected {sorted(expected)}")
    if status != expected[job_id]:
        raise SystemExit(
            f"Job {job_id} returned status {status}, expected {expected[job_id]}"
        )

invalid_error = seen["smoke-invalid"].get("error", "")
if "Font size" not in invalid_error:
    raise SystemExit(
        f"smoke-invalid should report font-size validation error, got: {invalid_error!r}"
    )

metrics_payload = seen["smoke-metrics"]
if "metrics" not in metrics_payload:
    raise SystemExit(f"smoke-metrics missing metrics payload: {metrics_payload}")
if "rendering" in metrics_payload:
    raise SystemExit("metrics format should not emit rendering field")
metrics = metrics_payload["metrics"]
for key in ("density", "beam"):
    value = metrics.get(key)
    if value is None:
        raise SystemExit(f"metrics payload missing {key}: {metrics}")
    if not isinstance(value, (int, float)) or not (0 <= value <= 1):
        raise SystemExit(f"{key} should be 0<=x<=1, got {value!r}")

print("âœ“ batch_smoke JSON contract verified")
PY
</document_content>
</document>

<document index="19">
<source>scripts/build.sh</source>
<document_content>
#!/usr/bin/env bash
# this_file: scripts/build.sh

set -euo pipefail

ROOT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")/.." && pwd)"
PROFILE="${HAFORU_PROFILE:-release}"
RUN_TESTS=1
RUN_SMOKE=1
SKIP_WHEELS=0
TARGETS="auto"

usage() {
    cat <<'EOF'
Usage: scripts/build.sh [options]

Options:
  --profile <name>     Cargo profile to build/test (default: release)
  --skip-tests         Skip cargo/uvx test suites
  --skip-smoke         Skip scripts/batch_smoke.sh
  --skip-wheels        Skip Python wheel builds
  --targets "<list>"   Wheel targets (auto|universal2|manylinux|windows|all)
  -h, --help           Show this help

Environment:
  ARTIFACT_DIR     Override target/artifacts output root
  HAFORU_PROFILE   Alias for --profile
EOF
}

while (($#)); do
    case "$1" in
        --profile) PROFILE="$2"; shift ;;
        --skip-tests) RUN_TESTS=0 ;;
        --skip-smoke) RUN_SMOKE=0 ;;
        --skip-wheels) SKIP_WHEELS=1 ;;
        --targets) TARGETS="$2"; shift ;;
        -h|--help)
            usage
            exit 0
            ;;
        *)
            printf 'Unknown option: %s\n\n' "$1" >&2
            usage
            exit 1
            ;;
    esac
    shift
done

cd "$ROOT_DIR"

if [[ -z "${CARGO_BUILD_JOBS:-}" ]]; then
    if command -v getconf >/dev/null 2>&1; then
        CARGO_BUILD_JOBS="$(getconf _NPROCESSORS_ONLN 2>/dev/null || echo 1)"
    else
        CARGO_BUILD_JOBS="${NUMBER_OF_PROCESSORS:-1}"
    fi
    [[ "$CARGO_BUILD_JOBS" -ge 1 ]] 2>/dev/null || CARGO_BUILD_JOBS=1
    export CARGO_BUILD_JOBS
fi

if [[ -z "${CARGO_SOURCE_CRATES_IO_REPLACE_WITH:-}" ]]; then
    export CARGO_SOURCE_CRATES_IO_REPLACE_WITH="crates-io"
fi

if [[ -z "${CARGO_SOURCE_VENDORED_SOURCES_DIRECTORY:-}" ]]; then
    export CARGO_SOURCE_VENDORED_SOURCES_DIRECTORY="$ROOT_DIR/target/vendor-empty"
    mkdir -p "$CARGO_SOURCE_VENDORED_SOURCES_DIRECTORY"
fi

ARTIFACT_ROOT="${ARTIFACT_DIR:-$ROOT_DIR/target/artifacts}"
RUN_STAMP="$(date +%Y%m%d-%H%M%S)"
RUN_DIR="$ARTIFACT_ROOT/$RUN_STAMP"
BIN_DIR="$RUN_DIR/bin"
WHEEL_DIR="$RUN_DIR/wheels"
LOG_DIR="$RUN_DIR/logs"
TIMINGS_FILE="$LOG_DIR/timings.txt"
mkdir -p "$BIN_DIR" "$WHEEL_DIR" "$LOG_DIR"
ln -sfn "$RUN_DIR" "$ARTIFACT_ROOT/latest"

log() {
    printf '\n[%s] %s\n' "$(date +%H:%M:%S)" "$*"
}

require_cmd() {
    if ! command -v "$1" >/dev/null 2>&1; then
        printf 'Missing required tool: %s\n' "$1" >&2
        exit 1
    fi
}

run_step() {
    local label="$1"
    shift
    log "$label"
    local start end
    start=$(date +%s)
    "$@"
    end=$(date +%s)
    printf '%s\t%ss\n' "$label" "$((end - start))" >> "$TIMINGS_FILE"
}

detect_platform() {
    local uname_out
    uname_out="$(uname -s)"
    case "$uname_out" in
        Darwin) PLATFORM="mac" ;;
        Linux) PLATFORM="linux" ;;
        MINGW*|MSYS*|CYGWIN*) PLATFORM="windows" ;;
        *) PLATFORM="unknown" ;;
    esac
    ARCH="$(uname -m)"
    BIN_NAME="haforu"
    [[ "$PLATFORM" == "windows" ]] && BIN_NAME="haforu.exe"
    BUILD_DIR_NAME=$([[ "$PROFILE" == "release" ]] && echo "release" || echo "$PROFILE")
    SOURCE_BIN="$ROOT_DIR/target/$BUILD_DIR_NAME/$BIN_NAME"
    HAFORU_BIN="$BIN_DIR/$BIN_NAME"
    export HAFORU_BIN
}

resolve_targets() {
    TARGET_SET=()
    if [[ "$TARGETS" == "auto" ]]; then
        case "$PLATFORM" in
            mac) TARGET_SET=("universal2") ;;
            linux) TARGET_SET=("manylinux") ;;
            windows) TARGET_SET=("windows") ;;
        esac
    elif [[ "$TARGETS" == "all" ]]; then
        TARGET_SET=("universal2" "manylinux" "windows")
    else
        read -r -a TARGET_SET <<<"$TARGETS"
    fi
}

build_cli() {
    local args=(build --locked --bin haforu)
    if [[ "$PROFILE" == "release" ]]; then
        args+=(--release)
    else
        args+=(--profile "$PROFILE")
    fi
    run_step "cargo ${args[*]}" cargo "${args[@]}"
    if [[ ! -f "$SOURCE_BIN" ]]; then
        printf 'Unable to locate built binary at %s\n' "$SOURCE_BIN" >&2
        exit 1
    fi
    cp "$SOURCE_BIN" "$HAFORU_BIN"
    chmod +x "$HAFORU_BIN"
    log "CLI ready at $HAFORU_BIN"
}

build_wheels() {
    [[ "$SKIP_WHEELS" -eq 1 ]] && return
    if [[ "${#TARGET_SET[@]}" -eq 0 ]]; then
        log "No wheel targets selected for $PLATFORM; skipping wheel build."
        return
    fi
    mkdir -p "$WHEEL_DIR"
    local rel_out="/io${WHEEL_DIR#$ROOT_DIR}"
    for target in "${TARGET_SET[@]}"; do
        case "$target" in
            universal2)
                run_step "maturin universal2" \
                    uvx maturin build --release --target universal2-apple-darwin \
                    --features python --out "$WHEEL_DIR"
                ;;
            manylinux)
                if command -v docker >/dev/null 2>&1; then
                    run_step "maturin manylinux (docker)" \
                        docker run --rm -v "$ROOT_DIR":/io ghcr.io/pyo3/maturin \
                        build --release --features python --compatibility manylinux_2_28 \
                        --out "$rel_out"
                else
                    run_step "maturin manylinux host" \
                        uvx maturin build --release --features python \
                        --compatibility manylinux_2_28 --out "$WHEEL_DIR"
                fi
                ;;
            windows)
                run_step "maturin windows" \
                    uvx maturin build --release --features python --out "$WHEEL_DIR"
                ;;
            *)
                printf 'Unknown wheel target: %s\n' "$target" >&2
                exit 1
                ;;
        esac
    done
    log "Wheels stored in $WHEEL_DIR"
}

run_rust_tests() {
    [[ "$RUN_TESTS" -eq 0 ]] && return
    local args=(test --locked --workspace)
    if [[ "$PROFILE" == "release" ]]; then
        args+=(--release)
    else
        args+=(--profile "$PROFILE")
    fi
    run_step "cargo ${args[*]}" cargo "${args[@]}"
}

run_python_tests() {
    [[ "$RUN_TESTS" -eq 0 ]] && return
    run_step "uvx hatch test" uvx hatch test
}

run_smoke() {
    [[ "$RUN_SMOKE" -eq 0 ]] && return
    export HAFORU_BIN
    run_step "scripts/batch_smoke.sh" bash "$ROOT_DIR/scripts/batch_smoke.sh"
}

write_summary() {
    local summary="$LOG_DIR/summary.txt"
    {
        printf "timestamp=%s\n" "$RUN_STAMP"
        printf "profile=%s\n" "$PROFILE"
        printf "platform=%s\n" "$PLATFORM"
        printf "arch=%s\n" "$ARCH"
        printf "cli=%s\n" "$HAFORU_BIN"
        printf "wheels=%s\n" "$WHEEL_DIR"
        printf "tests=%s\n" "$([[ "$RUN_TESTS" -eq 1 ]] && echo on || echo off)"
        printf "smoke=%s\n" "$([[ "$RUN_SMOKE" -eq 1 ]] && echo on || echo off)"
    } >"$summary"
    log "Summary written to $summary"
    log "Timings recorded in $TIMINGS_FILE"
}

main() {
    require_cmd cargo
    require_cmd uvx
    detect_platform
    resolve_targets
    log "Haforu build start (profile=$PROFILE, platform=$PLATFORM, arch=$ARCH)"
    build_cli
    build_wheels
    run_rust_tests
    run_python_tests
    run_smoke
    write_summary
}

main "$@"
</document_content>
</document>

<document index="20">
<source>scripts/jobs_smoke.jsonl</source>
<document_content>
{"id":"smoke-1","font":{"path":"testdata/fonts/Arial-Black.ttf","size":1000,"variations":{}},"text":{"content":"Haforu"},"rendering":{"format":"pgm","encoding":"base64","width":256,"height":128}}
{"id":"smoke-2","font":{"path":"testdata/fonts/Arial-Black.ttf","size":1000,"variations":{}},"text":{"content":"Integration"},"rendering":{"format":"pgm","encoding":"base64","width":256,"height":128}}
{"id":"smoke-metrics","font":{"path":"testdata/fonts/Arial-Black.ttf","size":640,"variations":{}},"text":{"content":"Metrics"},"rendering":{"format":"metrics","encoding":"json","width":128,"height":128}}
{"id":"smoke-invalid","font":{"path":"testdata/fonts/Arial-Black.ttf","size":0,"variations":{"wght":1400}},"text":{"content":"Invalid"},"rendering":{"format":"pgm","encoding":"base64","width":256,"height":128}}

... (Data file content truncated to first 5 lines)
</document_content>
</document>

<document index="21">
<source>scripts/profile-cli.sh</source>
<document_content>
#!/usr/bin/env bash
# this_file: scripts/profile-cli.sh
#
# Profile haforu CLI hot paths:
# - Argument parsing overhead
# - JSON batch parsing
# - JSONL streaming throughput
# - Job validation
# - End-to-end rendering

set -euo pipefail

HAFORU_BIN="${HAFORU_BIN:-./target/release/haforu}"
TESTDATA="./testdata/fonts/Arial-Black.ttf"

echo "=== Profiling haforu CLI hot paths ==="
echo "Binary: $HAFORU_BIN"
echo "Test font: $TESTDATA"
echo

# Check for hyperfine
if ! command -v hyperfine &> /dev/null; then
    echo "Note: hyperfine not found, using basic timing instead"
    echo "Install with: brew install hyperfine"
    USE_HYPERFINE=0
else
    USE_HYPERFINE=1
fi

# 1. Argument parsing overhead
echo "## 1. Argument Parsing Overhead"
echo "Measuring help/version commands (startup + arg parsing only):"
echo

if [ $USE_HYPERFINE -eq 1 ]; then
    hyperfine --warmup 3 \
        "$HAFORU_BIN --help" \
        "$HAFORU_BIN --version" \
        "$HAFORU_BIN diagnostics --format json"
else
    for cmd in "--help" "--version" "diagnostics --format json"; do
        echo "Timing: $HAFORU_BIN $cmd"
        time $HAFORU_BIN $cmd > /dev/null
    done
fi

echo

# 2. JSON batch parsing
echo "## 2. JSON Batch Parsing (hot path: serde_json parse)"
echo "Measuring batch mode with varying input sizes:"
echo

# Create test jobs with different sizes
create_batch_jobs() {
    local count=$1
    echo '{"version":"1.0","jobs":['
    for i in $(seq 1 $count); do
        cat <<EOF
{"id":"job-$i","font":{"path":"$TESTDATA","size":256,"variations":{}},"text":{"content":"A","script":"Latn"},"rendering":{"format":"metrics","encoding":"json","width":64,"height":64}}$([ $i -lt $count ] && echo ",")
EOF
    done
    echo ']}'
}

for count in 1 10 100; do
    echo "Batch with $count jobs:"
    create_batch_jobs $count > /tmp/batch_$count.json

    if [ $USE_HYPERFINE -eq 1 ]; then
        hyperfine --warmup 2 --runs 10 \
            "$HAFORU_BIN batch < /tmp/batch_$count.json"
    else
        echo "Timing: $HAFORU_BIN batch < /tmp/batch_$count.json"
        time $HAFORU_BIN batch < /tmp/batch_$count.json > /dev/null
    fi
    echo
done

# 3. JSONL streaming parsing
echo "## 3. JSONL Streaming (hot path: line-by-line JSON parse + dispatch)"
echo "Measuring stream mode with varying line counts:"
echo

# Create JSONL test data
create_jsonl_jobs() {
    local count=$1
    for i in $(seq 1 $count); do
        echo '{"id":"job-'$i'","font":{"path":"'$TESTDATA'","size":256,"variations":{}},"text":{"content":"A","script":"Latn"},"rendering":{"format":"metrics","encoding":"json","width":64,"height":64}}'
    done
}

for count in 10 100 1000; do
    echo "JSONL stream with $count lines:"
    create_jsonl_jobs $count > /tmp/stream_$count.jsonl

    if [ $USE_HYPERFINE -eq 1 ]; then
        hyperfine --warmup 2 --runs 10 \
            "$HAFORU_BIN stream < /tmp/stream_$count.jsonl"
    else
        echo "Timing: $HAFORU_BIN stream < /tmp/stream_$count.jsonl"
        time $HAFORU_BIN stream < /tmp/stream_$count.jsonl > /dev/null
    fi
    echo
done

# 4. End-to-end rendering (with vs without image encoding)
echo "## 4. End-to-End Rendering Performance"
echo "Comparing metrics-only vs full PGM rendering:"
echo

# Metrics only (fast path)
echo "Metrics-only format:"
if [ $USE_HYPERFINE -eq 1 ]; then
    hyperfine --warmup 5 --runs 50 \
        "$HAFORU_BIN render -f $TESTDATA -s 256 -t A --format metrics"
else
    echo "Timing: $HAFORU_BIN render -f $TESTDATA -s 256 -t A --format metrics"
    time for i in {1..50}; do $HAFORU_BIN render -f $TESTDATA -s 256 -t A --format metrics > /dev/null; done
fi

echo

# PGM rendering (full path)
echo "PGM rendering format:"
if [ $USE_HYPERFINE -eq 1 ]; then
    hyperfine --warmup 5 --runs 50 \
        "$HAFORU_BIN render -f $TESTDATA -s 256 -t A --format pgm -o /tmp/test.pgm"
else
    echo "Timing: $HAFORU_BIN render -f $TESTDATA -s 256 -t A --format pgm -o /tmp/test.pgm"
    time for i in {1..50}; do $HAFORU_BIN render -f $TESTDATA -s 256 -t A --format pgm -o /tmp/test.pgm; done
fi

echo

# Summary
echo "=== Profile Complete ==="
echo
echo "Hot paths profiled:"
echo "1. Argument parsing - baseline CLI startup overhead"
echo "2. JSON batch parsing - serde_json deserialize throughput"
echo "3. JSONL streaming - line-by-line parse + job dispatch"
echo "4. End-to-end rendering - metrics vs PGM output comparison"
echo
echo "Next steps:"
echo "- Review results above for any outliers"
echo "- Use flamegraph/perf for deeper profiling if needed"
echo "- Add regression tests for critical paths"
</document_content>
</document>

<document index="22">
<source>scripts/regression-test.sh</source>
<document_content>
#!/usr/bin/env bash
# this_file: scripts/regression-test.sh
#
# Performance regression tests for haforu CLI
# Runs key performance benchmarks and compares against baseline thresholds
# Exit code 0 = pass, 1 = regression detected

set -euo pipefail

HAFORU_BIN="${HAFORU_BIN:-./target/release/haforu}"
TESTDATA="./testdata/fonts/Arial-Black.ttf"
BASELINE_FILE="${BASELINE_FILE:-.baseline-perf.json}"

# Color output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[0;33m'
NC='\033[0m' # No Color

echo "=== Performance Regression Tests ==="
echo "Binary: $HAFORU_BIN"
echo "Baseline: $BASELINE_FILE"
echo

# Check if binary exists
if [ ! -f "$HAFORU_BIN" ]; then
    echo -e "${RED}ERROR: Binary not found at $HAFORU_BIN${NC}"
    echo "Run: cargo build --release"
    exit 1
fi

# Check for hyperfine
if ! command -v hyperfine &> /dev/null; then
    echo -e "${YELLOW}WARNING: hyperfine not found${NC}"
    echo "Install with: brew install hyperfine"
    echo "Skipping regression tests"
    exit 0
fi

# Performance thresholds (in milliseconds)
# Based on profiling results from 2025-11-14
# Note: bash -c wrapper adds ~5-7ms overhead
THRESHOLD_HELP=10          # --help should be <10ms
THRESHOLD_BATCH_1=15       # 1 job batch should be <15ms (includes bash -c overhead)
THRESHOLD_STREAM_100=15    # 100 line stream should be <15ms (includes bash -c overhead)
THRESHOLD_METRICS=10       # Single metrics render should be <10ms

FAILED=0

# Helper function to run benchmark and check threshold
check_perf() {
    local name=$1
    local threshold=$2
    shift 2
    local cmd="$@"

    echo "Testing: $name"
    echo "  Command: $cmd"
    echo "  Threshold: ${threshold}ms"

    # Run hyperfine and extract mean time
    result=$(hyperfine --warmup 3 --runs 10 --export-json /tmp/bench.json "$cmd" 2>&1)
    mean_ms=$(jq '.results[0].mean * 1000' /tmp/bench.json)

    # Compare (bash doesn't have floating point, so use bc)
    passed=$(echo "$mean_ms < $threshold" | bc -l)

    if [ "$passed" -eq 1 ]; then
        echo -e "  ${GREEN}âœ“ PASS${NC} (${mean_ms}ms < ${threshold}ms)"
    else
        echo -e "  ${RED}âœ— FAIL${NC} (${mean_ms}ms >= ${threshold}ms)"
        FAILED=1
    fi
    echo
}

# Test 1: Argument parsing (--help)
check_perf "Argument parsing (--help)" $THRESHOLD_HELP \
    "$HAFORU_BIN --help"

# Test 2: Batch processing (1 job)
echo '{"version":"1.0","jobs":[{"id":"test","font":{"path":"'$TESTDATA'","size":256,"variations":{}},"text":{"content":"A","script":"Latn"},"rendering":{"format":"metrics","encoding":"json","width":64,"height":64}}]}' > /tmp/batch_1.json
check_perf "Batch processing (1 job)" $THRESHOLD_BATCH_1 \
    "bash -c '$HAFORU_BIN batch < /tmp/batch_1.json'"

# Test 3: JSONL streaming (100 lines)
for i in $(seq 1 100); do
    echo '{"id":"job-'$i'","font":{"path":"'$TESTDATA'","size":256,"variations":{}},"text":{"content":"A","script":"Latn"},"rendering":{"format":"metrics","encoding":"json","width":64,"height":64}}'
done > /tmp/stream_100.jsonl
check_perf "JSONL streaming (100 lines)" $THRESHOLD_STREAM_100 \
    "bash -c '$HAFORU_BIN stream < /tmp/stream_100.jsonl'"

# Test 4: Single metrics render
check_perf "Metrics rendering (single glyph)" $THRESHOLD_METRICS \
    "$HAFORU_BIN render -f $TESTDATA -s 256 -t A --format metrics"

# Summary
echo "=== Regression Test Summary ==="
if [ $FAILED -eq 0 ]; then
    echo -e "${GREEN}âœ“ All tests passed!${NC}"
    exit 0
else
    echo -e "${RED}âœ— Performance regression detected!${NC}"
    echo
    echo "Some benchmarks exceeded their thresholds."
    echo "This may indicate a performance regression."
    echo
    echo "Next steps:"
    echo "1. Review recent changes for performance impact"
    echo "2. Run 'scripts/profile-cli.sh' for detailed profiling"
    echo "3. Use flamegraph/perf for deep analysis if needed"
    exit 1
fi
</document_content>
</document>

<document index="23">
<source>scripts/run.sh</source>
<document_content>
#!/usr/bin/env bash
# this_file: scripts/run.sh

set -euo pipefail

ROOT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")/.." && pwd)"
JOBS_FILE="${JOBS_FILE:-$ROOT_DIR/scripts/jobs_smoke.jsonl}"
HAFORU_BIN="${HAFORU_BIN:-$ROOT_DIR/target/release/haforu}"
PYTHON_BIN="${PYTHON_BIN:-python3}"
CONVERTER_PY="${CONVERTER_PY:-python3}"
MODE="${1:-smoke}"

RUN_LOG_DIR="$ROOT_DIR/target/run-log"
RUN_STAMP="$(date +%Y%m%d-%H%M%S)"
RUN_LOG="$RUN_LOG_DIR/$MODE-$RUN_STAMP.log"
TIMINGS_FILE="$RUN_LOG_DIR/$MODE-$RUN_STAMP.timings"
TMP_DIR="$(mktemp -d)"
trap 'rm -rf "$TMP_DIR"' EXIT
mkdir -p "$RUN_LOG_DIR"
touch "$RUN_LOG" "$TIMINGS_FILE"

log() {
    local line="[$(date +%H:%M:%S)] $*"
    printf '\n%s\n' "$line"
    printf '%s\n' "$line" >> "$RUN_LOG"
}

require_file() {
    if [[ ! -f "$1" ]]; then
        printf 'Missing file: %s\n' "$1" >&2
        exit 1
    fi
}

ensure_cli() {
    if [[ -x "$HAFORU_BIN" ]]; then
        return
    fi
    log "haforu binary not found at $HAFORU_BIN, building release binary"
    (cd "$ROOT_DIR" && cargo build --release >/dev/null)
    HAFORU_BIN="$ROOT_DIR/target/release/haforu"
    export HAFORU_BIN
}

convert_jobs() {
    local mode="$1"
    local dest="$2"
    "$CONVERTER_PY" - "$JOBS_FILE" "$mode" "$dest" <<'PY'
import json, sys
from pathlib import Path

src = Path(sys.argv[1])
mode = sys.argv[2]
dest = Path(sys.argv[3])
jobs = []
for line in src.read_text().splitlines():
    line = line.strip()
    if not line:
        continue
    job = json.loads(line)
    fmt = job.get("rendering", {}).get("format")
    if mode == "metrics" and fmt != "metrics":
        continue
    if mode == "nonmetrics" and fmt == "metrics":
        continue
    jobs.append(job)
dest.write_text(json.dumps({"version": "1.0", "jobs": jobs}))
PY
}

summarize_jobs() {
    local label="$1"
    local file="$2"
    "$CONVERTER_PY" - "$file" "$label" <<'PY'
import json, sys
from pathlib import Path

path = Path(sys.argv[1])
label = sys.argv[2]
print(f"{label} summaries:")
for line in path.read_text().splitlines():
    line = line.strip()
    if not line:
        continue
    job = json.loads(line)
    status = job.get("status")
    job_id = job.get("id")
    metrics = job.get("metrics")
    err = job.get("error")
    if metrics:
        metrics_text = f"density={metrics.get('density'):.3f}, beam={metrics.get('beam'):.3f}"
        print(f"  {job_id}: {status} ({metrics_text})")
    elif err:
        print(f"  {job_id}: {status} -> {err}")
    else:
        fmt = job.get("rendering", {}).get("format")
        print(f"  {job_id}: {status} ({fmt})")
PY
}

summarize_stream() {
    local file="$1"
    "$CONVERTER_PY" - "$file" <<'PY'
import json, sys
from pathlib import Path

path = Path(sys.argv[1])
print("Streaming summaries:")
for line in path.read_text().splitlines():
    line = line.strip()
    if not line:
        continue
    job = json.loads(line)
    job_id = job.get("id")
    status = job.get("status")
    err = job.get("error")
    if err:
        print(f"  {job_id}: {status} -> {err}")
    else:
        print(f"  {job_id}: {status}")
PY
}

run_cli() {
    local label="$1"
    local input="$2"
    local output="$3"
    shift 3
    log "$label"
    local start end
    start=$(date +%s)
    if [[ -n "$input" ]]; then
        "$HAFORU_BIN" "$@" < "$input" > "$output"
    else
        "$HAFORU_BIN" "$@" > "$output"
    fi
    end=$(date +%s)
    printf '%s\t%ss\n' "$label" "$((end - start))" >> "$TIMINGS_FILE"
}

batch_demo() {
    local batch_json="$TMP_DIR/batch.json"
    local output="$TMP_DIR/batch.out"
    convert_jobs all "$batch_json"
    run_cli "haforu batch (jobs_smoke)" "$batch_json" "$output" batch
    summarize_jobs "Batch" "$output" | tee -a "$RUN_LOG"
}

metrics_demo() {
    local metrics_json="$TMP_DIR/metrics.json"
    local output="$TMP_DIR/metrics.out"
    convert_jobs metrics "$metrics_json"
    run_cli "haforu batch (metrics only)" "$metrics_json" "$output" batch
    summarize_jobs "Metrics" "$output" | tee -a "$RUN_LOG"
}

stream_demo() {
    local output="$TMP_DIR/stream.out"
    run_cli "haforu stream (jobs_smoke)" "$JOBS_FILE" "$output" stream
    summarize_stream "$output" | tee -a "$RUN_LOG"
}

python_demo() {
    log "Python StreamingSession demo"
    if ! "$PYTHON_BIN" -c "import haforu" >/dev/null 2>&1; then
        log "haforu Python module not found for $PYTHON_BIN; skip demo (install the wheel first)."
        return
    fi
    local status
    "$PYTHON_BIN" - "$JOBS_FILE" <<'PY' | tee -a "$RUN_LOG"
import json, sys, haforu, pathlib

jobs = [json.loads(line) for line in pathlib.Path(sys.argv[1]).read_text().splitlines() if line.strip()]
first = jobs[0]
print(f"haforu {haforu.__version__}, available={haforu.is_available()}")
session = haforu.StreamingSession(max_fonts=8, max_glyphs=128)
session.warm_up()
result = json.loads(session.render(json.dumps(first)))
print(f"session render -> {result['id']} {result['status']}")
session.close()
PY
    status=${PIPESTATUS[0]}
    if [[ $status -ne 0 ]]; then
        exit $status
    fi
}

smoke_suite() {
    ensure_cli
    batch_demo
    metrics_demo
    stream_demo
}

main() {
    require_file "$JOBS_FILE"
    case "$MODE" in
        smoke)
            smoke_suite
            ;;
        batch)
            ensure_cli
            batch_demo
            ;;
        metrics)
            ensure_cli
            metrics_demo
            ;;
        stream)
            ensure_cli
            stream_demo
            ;;
        python)
            python_demo
            ;;
        all)
            smoke_suite
            python_demo
            ;;
        *)
            printf 'Usage: %s [smoke|batch|metrics|stream|python|all]\n' "$0"
            exit 1
            ;;
    esac
    log "Run artifacts: $RUN_LOG (timings: $TIMINGS_FILE)"
}

main
</document_content>
</document>

<document index="24">
<source>scripts/sync-version.sh</source>
<document_content>
#!/usr/bin/env bash
# this_file: scripts/sync-version.sh

set -euo pipefail

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
NC='\033[0m' # No Color

echo -e "${GREEN}===== Version Sync Script =====${NC}"
echo ""

# Get version from git tag or provide default
if git describe --tags --exact-match 2>/dev/null; then
    VERSION=$(git describe --tags --exact-match | sed 's/^v//')
    echo -e "${GREEN}Found git tag: v$VERSION${NC}"
else
    # Try to get from most recent tag
    if git describe --tags --abbrev=0 2>/dev/null; then
        LAST_TAG=$(git describe --tags --abbrev=0 | sed 's/^v//')
        # Count commits since last tag
        COMMITS_SINCE=$(git rev-list $(git describe --tags --abbrev=0)..HEAD --count)

        if [ "$COMMITS_SINCE" -gt 0 ]; then
            # Development version
            VERSION="${LAST_TAG}.dev${COMMITS_SINCE}"
            echo -e "${YELLOW}No exact tag, using development version: $VERSION${NC}"
        else
            VERSION="$LAST_TAG"
            echo -e "${GREEN}Using most recent tag: v$VERSION${NC}"
        fi
    else
        VERSION="0.0.0.dev"
        echo -e "${YELLOW}No tags found, using default: $VERSION${NC}"
    fi
fi

echo ""
echo "Syncing version: $VERSION"
echo ""

# Update Cargo.toml
if [ -f "Cargo.toml" ]; then
    echo "Updating Cargo.toml..."

    # Create backup
    cp Cargo.toml Cargo.toml.bak

    # Update version line
    if [[ "$OSTYPE" == "darwin"* ]]; then
        # macOS
        sed -i '' "s/^version = \".*\"/version = \"$VERSION\"/" Cargo.toml
    else
        # Linux
        sed -i "s/^version = \".*\"/version = \"$VERSION\"/" Cargo.toml
    fi

    echo -e "${GREEN}âœ“ Updated Cargo.toml${NC}"
else
    echo -e "${RED}âœ— Cargo.toml not found${NC}"
fi

# Check if pyproject.toml uses dynamic versioning
if [ -f "pyproject.toml" ]; then
    if grep -q "dynamic.*version" pyproject.toml; then
        echo "Python version is managed by hatch-vcs (dynamic)"
        echo -e "${GREEN}âœ“ pyproject.toml uses git-based versioning${NC}"
    else
        echo -e "${YELLOW}Warning: pyproject.toml doesn't use dynamic versioning${NC}"
        echo "Consider adding: dynamic = [\"version\"]"
    fi
fi

echo ""
echo "Version sync complete!"
echo ""
echo "Current versions:"
echo "  Git tag:     $(git describe --tags --abbrev=0 2>/dev/null || echo 'none')"
echo "  Cargo.toml:  $(grep '^version = ' Cargo.toml | head -1 | cut -d'"' -f2)"

if [ -f "python/haforu/__init__.py" ]; then
    if grep -q "__version__" python/haforu/__init__.py 2>/dev/null; then
        echo "  Python:      $(grep '__version__' python/haforu/__init__.py | cut -d'"' -f2 || echo 'dynamic')"
    else
        echo "  Python:      dynamic (from git tags via hatch-vcs)"
    fi
fi

echo ""
echo "To create a new release:"
echo "  1. git tag v$VERSION"
echo "  2. git push --tags"
echo "  3. GitHub Actions will build and publish automatically"
echo ""

# Cleanup backup
if [ -f "Cargo.toml.bak" ]; then
    rm Cargo.toml.bak
fi
</document_content>
</document>

<document index="25">
<source>scripts/test-cli-parity.sh</source>
<document_content>
#!/usr/bin/env bash
# this_file: scripts/test-cli-parity.sh
#
# Test Python Fire CLI parity with Rust CLI
# Verifies that both CLIs expose the same functionality

set -uo pipefail

RUST_CLI="${HAFORU_BIN:-./target/release/haforu}"
PYTHON_CLI="python -m haforu"
TESTDATA="./testdata/fonts/Arial-Black.ttf"

# Colors
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[0;33m'
NC='\033[0m'

echo "=== Testing CLI Parity: Rust vs Python Fire ==="
echo "Rust CLI: $RUST_CLI"
echo "Python CLI: $PYTHON_CLI"
echo

PASSED=0
FAILED=0

# Helper function to test command availability
test_command() {
    local cli=$1
    local cmd=$2
    local description=$3

    echo -n "Testing $description... "

    set +e
    if [[ "$cli" == *"python"* ]]; then
        $cli $cmd --help >/dev/null 2>&1
    else
        $cli $cmd --help >/dev/null 2>&1
    fi
    local exit_code=$?
    set -e

    if [[ $exit_code -eq 0 ]]; then
        echo -e "${GREEN}âœ“${NC}"
        PASSED=$((PASSED + 1))
        return 0
    else
        echo -e "${RED}âœ—${NC}"
        FAILED=$((FAILED + 1))
        return 1
    fi
}

# Test command availability
echo "## 1. Command Availability"
echo

# Rust CLI commands
rust_commands=(
    "batch:Batch processing"
    "stream:Streaming mode"
    "validate:Job validation"
    "version:Version display"
    "diagnostics:System diagnostics"
    "render:Single render"
)

# Python CLI commands (should match Rust)
python_commands=(
    "batch:Batch processing"
    "stream:Streaming mode"
    "validate:Job validation"
    "version:Version display"
    "diagnostics:System diagnostics"
    "render:Single render"
    "metrics:Metrics computation"
)

for cmd_desc in "${rust_commands[@]}"; do
    IFS=':' read -r cmd desc <<< "$cmd_desc"
    test_command "$RUST_CLI" "$cmd" "Rust: $desc"
done

echo

for cmd_desc in "${python_commands[@]}"; do
    IFS=':' read -r cmd desc <<< "$cmd_desc"
    test_command "$PYTHON_CLI" "$cmd" "Python: $desc"
done

echo

# Test functional equivalence
echo "## 2. Functional Equivalence Tests"
echo

# Test 2.1: Version command
echo -n "Testing version command output... "
rust_version=$($RUST_CLI version 2>&1 | head -1 || true)
python_version=$($PYTHON_CLI version 2>&1 | grep -v "INFO:" | head -1 || true)

if [[ -n "$rust_version" ]] && [[ -n "$python_version" ]]; then
    echo -e "${GREEN}âœ“${NC}"
    echo "  Rust:   $rust_version"
    echo "  Python: $python_version"
    PASSED=$((PASSED + 1))
else
    echo -e "${RED}âœ—${NC}"
    FAILED=$((FAILED + 1))
fi
echo

# Test 2.2: Diagnostics JSON output
echo -n "Testing diagnostics JSON output... "
rust_diag=$($RUST_CLI diagnostics --format json 2>&1 | grep -v "^$" || true)
python_diag=$($PYTHON_CLI diagnostics --format json 2>&1 | grep -v "INFO:" | grep -v "^$" || true)

if echo "$rust_diag" | jq . >/dev/null 2>&1 && echo "$python_diag" | jq . >/dev/null 2>&1; then
    echo -e "${GREEN}âœ“${NC}"
    PASSED=$((PASSED + 1))
else
    echo -e "${RED}âœ—${NC}"
    FAILED=$((FAILED + 1))
fi
echo

# Test 2.3: Validate command
echo -n "Testing validate command... "
cat > /tmp/test_job.json <<EOF
{
  "version": "1.0",
  "jobs": [{
    "id": "test",
    "font": {"path": "$TESTDATA", "size": 256, "variations": {}},
    "text": {"content": "A"},
    "rendering": {"format": "metrics", "encoding": "json", "width": 64, "height": 64}
  }]
}
EOF

rust_validate_exit=0
$RUST_CLI validate < /tmp/test_job.json >/dev/null 2>&1 || rust_validate_exit=$?

python_validate_exit=0
$PYTHON_CLI validate < /tmp/test_job.json 2>&1 | grep -v "INFO:" >/dev/null || python_validate_exit=$?

if [[ $rust_validate_exit -eq 0 ]] && [[ $python_validate_exit -eq 0 ]]; then
    echo -e "${GREEN}âœ“${NC}"
    PASSED=$((PASSED + 1))
else
    echo -e "${RED}âœ—${NC}"
    echo "  Rust exit: $rust_validate_exit"
    echo "  Python exit: $python_validate_exit"
    FAILED=$((FAILED + 1))
fi
echo

# Test 2.4: Batch processing
echo -n "Testing batch command... "
rust_batch_output=$($RUST_CLI batch < /tmp/test_job.json 2>/dev/null | grep -v "^$" || true)
python_batch_output=$($PYTHON_CLI batch < /tmp/test_job.json 2>&1 | grep -v "INFO:" | grep -v "^$" || true)

rust_batch_valid=0
python_batch_valid=0

if echo "$rust_batch_output" | jq . >/dev/null 2>&1; then
    rust_batch_valid=1
fi

if echo "$python_batch_output" | jq . >/dev/null 2>&1; then
    python_batch_valid=1
fi

if [[ $rust_batch_valid -eq 1 ]] && [[ $python_batch_valid -eq 1 ]]; then
    echo -e "${GREEN}âœ“${NC}"
    PASSED=$((PASSED + 1))
else
    echo -e "${RED}âœ—${NC}"
    echo "  Rust valid: $rust_batch_valid"
    echo "  Python valid: $python_batch_valid"
    FAILED=$((FAILED + 1))
fi
echo

# Test 2.5: Stream mode
echo -n "Testing stream command... "
echo '{"id":"test","font":{"path":"'$TESTDATA'","size":256,"variations":{}},"text":{"content":"A"},"rendering":{"format":"metrics","encoding":"json","width":64,"height":64}}' > /tmp/test_stream.jsonl

rust_stream_output=$($RUST_CLI stream < /tmp/test_stream.jsonl 2>/dev/null | grep -v "^$" || true)
python_stream_output=$($PYTHON_CLI stream < /tmp/test_stream.jsonl 2>&1 | grep -v "INFO:" | grep -v "^$" || true)

rust_stream_valid=0
python_stream_valid=0

if echo "$rust_stream_output" | jq . >/dev/null 2>&1; then
    rust_stream_valid=1
fi

if echo "$python_stream_output" | jq . >/dev/null 2>&1; then
    python_stream_valid=1
fi

if [[ $rust_stream_valid -eq 1 ]] && [[ $python_stream_valid -eq 1 ]]; then
    echo -e "${GREEN}âœ“${NC}"
    PASSED=$((PASSED + 1))
else
    echo -e "${RED}âœ—${NC}"
    echo "  Rust valid: $rust_stream_valid"
    echo "  Python valid: $python_stream_valid"
    FAILED=$((FAILED + 1))
fi
echo

# Test 2.6: Render command (metrics mode)
echo -n "Testing render command (metrics mode)... "
rust_render=$($RUST_CLI render -f $TESTDATA -s 256 -t A --format metrics 2>&1 | grep -v "^$" || true)
python_render=$($PYTHON_CLI render --font $TESTDATA --size 256 --text A --format metrics 2>&1 | grep -v "INFO:" | grep -v "^$" || true)

# Both should output density/beam metrics
if echo "$rust_render" | grep -q "density" && echo "$python_render" | grep -q "Density"; then
    echo -e "${GREEN}âœ“${NC}"
    PASSED=$((PASSED + 1))
else
    echo -e "${RED}âœ—${NC}"
    FAILED=$((FAILED + 1))
fi
echo

# Test 2.7: Cache knobs (batch mode)
echo -n "Testing cache knobs (--max-fonts, --max-glyphs)... "
rust_cache=$($RUST_CLI batch --max-fonts 128 --max-glyphs 1024 < /tmp/test_job.json 2>/dev/null || true)
python_cache=$($PYTHON_CLI batch --max_fonts 128 --max_glyphs 1024 < /tmp/test_job.json 2>&1 | grep -v "INFO:" || true)

# Both should succeed
if echo "$rust_cache" | jq . >/dev/null 2>&1 && echo "$python_cache" | jq . >/dev/null 2>&1; then
    echo -e "${GREEN}âœ“${NC}"
    PASSED=$((PASSED + 1))
else
    echo -e "${RED}âœ—${NC}"
    FAILED=$((FAILED + 1))
fi
echo

# Summary
echo "=== CLI Parity Test Summary ==="
echo -e "Passed: ${GREEN}$PASSED${NC}"
echo -e "Failed: ${RED}$FAILED${NC}"
echo

if [[ $FAILED -eq 0 ]]; then
    echo -e "${GREEN}âœ“ All parity tests passed!${NC}"
    echo
    echo "Python Fire CLI successfully mirrors Rust CLI functionality."
    echo "Both CLIs can be used interchangeably."
    exit 0
else
    echo -e "${RED}âœ— Some parity tests failed!${NC}"
    echo
    echo "Review the failures above and update the Python CLI to match Rust CLI."
    exit 1
fi
</document_content>
</document>

# File: /Users/adam/Developer/vcs/github.fontlaborg/haforu/smoke_test.rs
# Language: rust



# File: /Users/adam/Developer/vcs/github.fontlaborg/haforu/src/batch.rs
# Language: rust

mod tests;

struct JobSpec {
}

struct Job {
}

struct FontConfig {
}

struct TextConfig {
}

struct RenderingConfig {
}

struct JobResult {
}

struct RenderingOutput {
}

struct MetricsOutput {
}

struct TimingInfo {
}

struct MemoryInfo {
}

struct FontResult {
}


# File: /Users/adam/Developer/vcs/github.fontlaborg/haforu/src/bufpool.rs
# Language: rust

mod tests;

struct CanvasPool {
}

struct PooledBuffer {
}


# File: /Users/adam/Developer/vcs/github.fontlaborg/haforu/src/cache.rs
# Language: rust

mod tests;

struct GlyphCacheKey {
}

struct GlyphCacheStats {
}

struct GlyphCache {
}


# File: /Users/adam/Developer/vcs/github.fontlaborg/haforu/src/error.rs
# Language: rust

mod tests;


# File: /Users/adam/Developer/vcs/github.fontlaborg/haforu/src/fonts.rs
# Language: rust

mod tests;

struct FontLoader {
}

struct CacheStats {
}

struct FontInstance {
}

struct FontCacheKey {
}


# File: /Users/adam/Developer/vcs/github.fontlaborg/haforu/src/image_ops.rs
# Language: rust

mod tests;

struct AlignCompareResult {
}


# File: /Users/adam/Developer/vcs/github.fontlaborg/haforu/src/input.rs
# Language: rust

mod tests;


# File: /Users/adam/Developer/vcs/github.fontlaborg/haforu/src/lib.rs
# Language: rust

mod batch;

mod bufpool;

mod cache;

mod error;

mod fonts;

mod image_ops;

mod output;

mod render;

mod security;

mod shaping;

mod varsweep;

mod python;

mod tests;

struct ExecutionOptions {
}


# File: /Users/adam/Developer/vcs/github.fontlaborg/haforu/src/main.rs
# Language: rust

mod input;

mod tests;

struct Cli {
}

struct DiagnosticsReport {
}

struct BatchStatsReport {
}

struct StreamStatsReport {
}

struct StreamCounters {
}

struct BatchRunSummary {
}


# File: /Users/adam/Developer/vcs/github.fontlaborg/haforu/src/output.rs
# Language: rust

mod tests;

struct ImageOutput {
}


# File: /Users/adam/Developer/vcs/github.fontlaborg/haforu/src/python/batch.rs
# Language: rust

mod tests;

struct ProcessJobsIterator {
}


# File: /Users/adam/Developer/vcs/github.fontlaborg/haforu/src/python/errors.rs
# Language: rust

mod tests;

struct ErrorConverter {
}


# File: /Users/adam/Developer/vcs/github.fontlaborg/haforu/src/python/image_ops.rs
# Language: rust

struct AlignCompareResult {
}

struct ResizeResult {
}


# File: /Users/adam/Developer/vcs/github.fontlaborg/haforu/src/python/mod.rs
# Language: rust

mod batch;

mod errors;

mod image_ops;

mod streaming;

mod types;

mod tests;


# File: /Users/adam/Developer/vcs/github.fontlaborg/haforu/src/python/streaming.rs
# Language: rust

mod tests;

struct StreamingSession {
}


# File: /Users/adam/Developer/vcs/github.fontlaborg/haforu/src/python/types.rs
# Language: rust



# File: /Users/adam/Developer/vcs/github.fontlaborg/haforu/src/render.rs
# Language: rust

mod tests;

struct Image {
}

struct GlyphRasterizer {
}

struct ZenoPen {
}


# File: /Users/adam/Developer/vcs/github.fontlaborg/haforu/src/security.rs
# Language: rust

struct TimeoutGuard {
}


# File: /Users/adam/Developer/vcs/github.fontlaborg/haforu/src/shaping.rs
# Language: rust

mod tests;

struct ShapedText {
}

struct ShapedGlyph {
}

struct ShapeRequest {
}

struct TextShaper {
}


# File: /Users/adam/Developer/vcs/github.fontlaborg/haforu/src/varsweep.rs
# Language: rust

mod tests;

struct SweepPoint {
}

struct SweepConfig {
}


# File: /Users/adam/Developer/vcs/github.fontlaborg/haforu/tests/__init__.py
# Language: python



# File: /Users/adam/Developer/vcs/github.fontlaborg/haforu/tests/cli_stats.rs
# Language: rust



# File: /Users/adam/Developer/vcs/github.fontlaborg/haforu/tests/test_batch.py
# Language: python

from python.tests.test_batch import *


# File: /Users/adam/Developer/vcs/github.fontlaborg/haforu/tests/test_errors.py
# Language: python

from python.tests.test_errors import *


# File: /Users/adam/Developer/vcs/github.fontlaborg/haforu/tests/test_numpy.py
# Language: python

from python.tests.test_numpy import *


# File: /Users/adam/Developer/vcs/github.fontlaborg/haforu/tests/test_streaming.py
# Language: python

from python.tests.test_streaming import *


</documents>