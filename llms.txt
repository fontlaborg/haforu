Project Structure:
ğŸ“ haforu
â”œâ”€â”€ ğŸ“ .github
â”‚   â””â”€â”€ ğŸ“ workflows
â”‚       â”œâ”€â”€ ğŸ“„ ci.yml
â”‚       â””â”€â”€ ğŸ“„ release.yml
â”œâ”€â”€ ğŸ“ benches
â”‚   â””â”€â”€ ğŸ“„ cli.rs
â”œâ”€â”€ ğŸ“ docs
â”‚   â”œâ”€â”€ ğŸ“„ CLI-USAGE.md
â”‚   â””â”€â”€ ğŸ“„ REPOSITORY.md
â”œâ”€â”€ ğŸ“ examples
â”‚   â”œâ”€â”€ ğŸ“ python
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ batch_demo.py
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ error_handling_demo.py
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ metrics_demo.py
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ numpy_demo.py
â”‚   â”‚   â””â”€â”€ ğŸ“„ streaming_demo.py
â”‚   â””â”€â”€ ğŸ“„ smoke_test.rs
â”œâ”€â”€ ğŸ“ issues
â”œâ”€â”€ ğŸ“ python
â”‚   â”œâ”€â”€ ğŸ“ haforu
â”‚   â””â”€â”€ ğŸ“ tests
â”‚       â”œâ”€â”€ ğŸ“„ test_batch.py
â”‚       â”œâ”€â”€ ğŸ“„ test_errors.py
â”‚       â”œâ”€â”€ ğŸ“„ test_numpy.py
â”‚       â””â”€â”€ ğŸ“„ test_streaming.py
â”œâ”€â”€ ğŸ“ scripts
â”‚   â”œâ”€â”€ ğŸ“„ batch_smoke.sh
â”‚   â”œâ”€â”€ ğŸ“„ build.sh
â”‚   â”œâ”€â”€ ğŸ“„ jobs_smoke.jsonl
â”‚   â”œâ”€â”€ ğŸ“„ profile-cli.sh
â”‚   â”œâ”€â”€ ğŸ“„ regression-test.sh
â”‚   â”œâ”€â”€ ğŸ“„ run.sh
â”‚   â”œâ”€â”€ ğŸ“„ sync-version.sh
â”‚   â””â”€â”€ ğŸ“„ test-cli-parity.sh
â”œâ”€â”€ ğŸ“ src
â”‚   â”œâ”€â”€ ğŸ“ python
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ batch.rs
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ errors.rs
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ mod.rs
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ streaming.rs
â”‚   â”‚   â””â”€â”€ ğŸ“„ types.rs
â”‚   â”œâ”€â”€ ğŸ“„ batch.rs
â”‚   â”œâ”€â”€ ğŸ“„ cache.rs
â”‚   â”œâ”€â”€ ğŸ“„ error.rs
â”‚   â”œâ”€â”€ ğŸ“„ fonts.rs
â”‚   â”œâ”€â”€ ğŸ“„ input.rs
â”‚   â”œâ”€â”€ ğŸ“„ lib.rs
â”‚   â”œâ”€â”€ ğŸ“„ main.rs
â”‚   â”œâ”€â”€ ğŸ“„ output.rs
â”‚   â”œâ”€â”€ ğŸ“„ render.rs
â”‚   â”œâ”€â”€ ğŸ“„ security.rs
â”‚   â””â”€â”€ ğŸ“„ shaping.rs
â”œâ”€â”€ ğŸ“ target
â”‚   â”œâ”€â”€ ğŸ“ debug
â”‚   â”‚   â”œâ”€â”€ ğŸ“ deps
â”‚   â”‚   â”œâ”€â”€ ğŸ“ examples
â”‚   â”‚   â””â”€â”€ ğŸ“ incremental
â”‚   â”‚       â”œâ”€â”€ ğŸ“ cli_stats-34uwdyqqhe43m
â”‚   â”‚       â”‚   â””â”€â”€ ğŸ“ 
â”‚   â”‚       â”‚       s-hczqpc21bb-07yzz83-4dypcdwvvzkv3pi6ljqpqoj7k
â”‚   â”‚       â”œâ”€â”€ ğŸ“ haforu-08zf1nnuqulfd
â”‚   â”‚       â”‚   â””â”€â”€ ğŸ“ 
â”‚   â”‚       â”‚       s-hczqpb3fek-14mmksn-bcosaf1zdsh6ew39daoxl340y
â”‚   â”‚       â”œâ”€â”€ ğŸ“ haforu-0rbv9x69y580h
â”‚   â”‚       â”‚   â””â”€â”€ ğŸ“ 
â”‚   â”‚       â”‚       s-hczg4b7xcj-1pd759l-aioxgobbvymw7zkgxdklpnn9p
â”‚   â”‚       â”œâ”€â”€ ğŸ“ haforu-1gfyf1h42fl5j
â”‚   â”‚       â”‚   â””â”€â”€ ğŸ“ 
â”‚   â”‚       â”‚       s-hczg4c2apk-1807kfv-76hjdokiix5z0ou4o2n04mdps
â”‚   â”‚       â”œâ”€â”€ ğŸ“ haforu-2bk6jiyvnoozg
â”‚   â”‚       â”‚   â””â”€â”€ ğŸ“ 
â”‚   â”‚       â”‚       s-hczqpb3eve-0pmv54u-cb4fel52mw8xnz6x87xbrsieh
â”‚   â”‚       â”œâ”€â”€ ğŸ“ haforu-2kxd8htbh9i7m
â”‚   â”‚       â”‚   â””â”€â”€ ğŸ“ 
â”‚   â”‚       â”‚       s-hczqpc22ji-0t8c96j-8bivgdz3hujwlvcqyshrkvwdf
â”‚   â”‚       â”œâ”€â”€ ğŸ“ haforu-2qf2tmg8datww
â”‚   â”‚       â”‚   â””â”€â”€ ğŸ“ 
â”‚   â”‚       â”‚       s-hczqpc2164-1t64bux-6q9shwaymm4btahxtro9ehmlx
â”‚   â”‚       â””â”€â”€ ğŸ“ smoke_test-1l1n0kvfmtt2i
â”‚   â”‚           â””â”€â”€ ğŸ“ 
â”‚   â”‚               s-hczqpc221t-0spqxt4-9rxk15u9rzj8a9w7bmun9v92j
â”‚   â”œâ”€â”€ ğŸ“ doc
â”‚   â”‚   â”œâ”€â”€ ğŸ“ haforu
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“ batch
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“ error
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“ fonts
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“ output
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“ render
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“ security
â”‚   â”‚   â”‚   â””â”€â”€ ğŸ“ shaping
â”‚   â”‚   â”œâ”€â”€ ğŸ“ search.index
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“ alias
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“ crateNames
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“ desc
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“ entry
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“ function
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“ generic_inverted_index
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“ name
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“ normalizedName
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“ path
â”‚   â”‚   â”‚   â””â”€â”€ ğŸ“ type
â”‚   â”‚   â”œâ”€â”€ ğŸ“ skrifa
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“ attribute
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“ charmap
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“ color
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ ğŸ“ transform
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“ font
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“ instance
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“ metrics
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“ outline
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“ autohint
â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ ğŸ“ instance
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“ error
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“ glyf
â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ ğŸ“ hint
â”‚   â”‚   â”‚   â”‚   â”‚       â””â”€â”€ ğŸ“ error
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“ hint
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“ path
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ ğŸ“ pen
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“ patchmap
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“ prelude
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“ provider
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“ setting
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“ string
â”‚   â”‚   â”‚   â””â”€â”€ ğŸ“ variation
â”‚   â”‚   â”œâ”€â”€ ğŸ“ src
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“ haforu
â”‚   â”‚   â”‚   â””â”€â”€ ğŸ“ skrifa
â”‚   â”‚   â”‚       â”œâ”€â”€ ğŸ“ color
â”‚   â”‚   â”‚       â””â”€â”€ ğŸ“ outline
â”‚   â”‚   â”‚           â”œâ”€â”€ ğŸ“ autohint
â”‚   â”‚   â”‚           â”‚   â””â”€â”€ ğŸ“ latin
â”‚   â”‚   â”‚           â”œâ”€â”€ ğŸ“ cff
â”‚   â”‚   â”‚           â””â”€â”€ ğŸ“ glyf
â”‚   â”‚   â”‚               â””â”€â”€ ğŸ“ hint
â”‚   â”‚   â”‚                   â””â”€â”€ ğŸ“ engine
â”‚   â”‚   â”œâ”€â”€ ğŸ“ static.files
â”‚   â”‚   â”œâ”€â”€ ğŸ“ trait.impl
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“ core
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“ clone
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“ cmp
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“ convert
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“ default
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“ error
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“ fmt
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“ hash
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“ iter
â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ ğŸ“ traits
â”‚   â”‚   â”‚   â”‚   â”‚       â”œâ”€â”€ ğŸ“ collect
â”‚   â”‚   â”‚   â”‚   â”‚       â””â”€â”€ ğŸ“ iterator
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“ marker
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“ ops
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“ arith
â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ ğŸ“ deref
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ ğŸ“ panic
â”‚   â”‚   â”‚   â”‚       â””â”€â”€ ğŸ“ unwind_safe
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“ serde_core
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“ de
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ ğŸ“ ser
â”‚   â”‚   â”‚   â””â”€â”€ ğŸ“ skrifa
â”‚   â”‚   â”‚       â”œâ”€â”€ ğŸ“ outline
â”‚   â”‚   â”‚       â”‚   â””â”€â”€ ğŸ“ pen
â”‚   â”‚   â”‚       â””â”€â”€ ğŸ“ provider
â”‚   â”‚   â””â”€â”€ ğŸ“ type.impl
â”‚   â”‚       â”œâ”€â”€ ğŸ“ core
â”‚   â”‚       â”‚   â””â”€â”€ ğŸ“ result
â”‚   â”‚       â”œâ”€â”€ ğŸ“ font_types
â”‚   â”‚       â”‚   â”œâ”€â”€ ğŸ“ bbox
â”‚   â”‚       â”‚   â””â”€â”€ ğŸ“ fixed
â”‚   â”‚       â””â”€â”€ ğŸ“ skrifa
â”‚   â”‚           â””â”€â”€ ğŸ“ setting
â”‚   â”œâ”€â”€ ğŸ“ maturin
â”‚   â”œâ”€â”€ ğŸ“ release
â”‚   â”‚   â”œâ”€â”€ ğŸ“ deps
â”‚   â”‚   â”œâ”€â”€ ğŸ“ examples
â”‚   â”‚   â””â”€â”€ ğŸ“ incremental
â”‚   â”‚       â”œâ”€â”€ ğŸ“ cli-2osw21mn0ve1l
â”‚   â”‚       â”‚   â””â”€â”€ ğŸ“ 
â”‚   â”‚       â”‚       s-hczg7kumom-0fokd5f-7tqw0f5unvu6hu34iwueo9i0q
â”‚   â”‚       â”œâ”€â”€ ğŸ“ haforu-16g4lvxg9q5ay
â”‚   â”‚       â”‚   â””â”€â”€ ğŸ“ 
â”‚   â”‚       â”‚       s-hczrczc5a8-0geu15r-3dtefu4euswalkzt3mbn2098x
â”‚   â”‚       â”œâ”€â”€ ğŸ“ haforu-1l12g9es5z0a7
â”‚   â”‚       â”‚   â””â”€â”€ ğŸ“ 
â”‚   â”‚       â”‚       s-hczg7krw75-1d5p5tn-b4ba0092v6nvvl7pwbch3o1ds
â”‚   â”‚       â”œâ”€â”€ ğŸ“ haforu-2s4lo2coqi1y3
â”‚   â”‚       â”‚   â””â”€â”€ ğŸ“ 
â”‚   â”‚       â”‚       s-hczg7klfi5-1xvokh9-bqzi55jezwhcthhoj9ny6dnd0
â”‚   â”‚       â”œâ”€â”€ ğŸ“ haforu-2w98643ew4hsq
â”‚   â”‚       â”‚   â””â”€â”€ ğŸ“ 
â”‚   â”‚       â”‚       s-hczrbz3fnf-1ki1gxt-btdwz737k9cocic9ojwiak7yo
â”‚   â”‚       â”œâ”€â”€ ğŸ“ haforu-3002vez00oonz
â”‚   â”‚       â”‚   â””â”€â”€ ğŸ“ 
â”‚   â”‚       â”‚       s-hczrcevi93-1omtugk-edzm2153rvvb0ztfy2ntei5ot
â”‚   â”‚       â”œâ”€â”€ ğŸ“ haforu-3l0mulv3ej1mz
â”‚   â”‚       â”‚   â””â”€â”€ ğŸ“ 
â”‚   â”‚       â”‚       s-hczg7klfi7-0djl7zb-epuwmapnzex5kipbbeqx8ba3d
â”‚   â”‚       â”œâ”€â”€ ğŸ“ haforu-3okrdq68lieta
â”‚   â”‚       â”‚   â””â”€â”€ ğŸ“ 
â”‚   â”‚       â”‚       s-hczrbzjrxk-06syavp-5x5svhd66s5uuf8e59aq6ln79
â”‚   â”‚       â””â”€â”€ ğŸ“ haforu-3orrzumlwtfvw
â”‚   â”‚           â””â”€â”€ ğŸ“ 
â”‚   â”‚               s-hczrcp1u58-1tt2bko-baitlpb1njb8ikm8c73iqeyqv
â”‚   â”œâ”€â”€ ğŸ“ tmp
â”‚   â””â”€â”€ ğŸ“ wheels
â”œâ”€â”€ ğŸ“ testdata
â”‚   â””â”€â”€ ğŸ“ fonts
â”œâ”€â”€ ğŸ“ tests
â”‚   â”œâ”€â”€ ğŸ“„ __init__.py
â”‚   â”œâ”€â”€ ğŸ“„ cli_stats.rs
â”‚   â”œâ”€â”€ ğŸ“„ test_batch.py
â”‚   â”œâ”€â”€ ğŸ“„ test_errors.py
â”‚   â”œâ”€â”€ ğŸ“„ test_numpy.py
â”‚   â””â”€â”€ ğŸ“„ test_streaming.py
â”œâ”€â”€ ğŸ“„ .gitignore
â”œâ”€â”€ ğŸ“„ ANALYSIS_SUMMARY.md
â”œâ”€â”€ ğŸ“„ ARCHITECTURE.md
â”œâ”€â”€ ğŸ“„ build.sh
â”œâ”€â”€ ğŸ“„ Cargo.toml
â”œâ”€â”€ ğŸ“„ COMPILATION_FIXES.md
â”œâ”€â”€ ğŸ“„ DEPENDENCIES.md
â”œâ”€â”€ ğŸ“„ INDEX.md
â”œâ”€â”€ ğŸ“„ INSTALL.md
â”œâ”€â”€ ğŸ“„ KEY_FINDINGS.md
â”œâ”€â”€ ğŸ“„ llms.sh
â”œâ”€â”€ ğŸ“„ NEXTTASK.md
â”œâ”€â”€ ğŸ“„ PLAN.md
â”œâ”€â”€ ğŸ“„ pyproject.toml
â”œâ”€â”€ ğŸ“„ README.md
â”œâ”€â”€ ğŸ“„ run.sh
â”œâ”€â”€ ğŸ“„ SIMPLIFICATION-SUMMARY.md
â”œâ”€â”€ ğŸ“„ smoke_test.rs
â””â”€â”€ ğŸ“„ TODO.md


<documents>
<document index="1">
<source>.github/workflows/ci.yml</source>
<document_content>
# this_file: .github/workflows/ci.yml

name: CI

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]
  workflow_dispatch:

env:
  CARGO_TERM_COLOR: always
  RUST_BACKTRACE: 1

jobs:
  # Rust tests
  rust-test:
    name: Rust Tests (${{ matrix.os }})
    runs-on: ${{ matrix.os }}
    strategy:
      matrix:
        os: [ubuntu-latest, macos-latest, windows-latest]
        rust: [stable]
    steps:
      - uses: actions/checkout@v4

      - name: Setup Rust
        uses: dtolnay/rust-toolchain@master
        with:
          toolchain: ${{ matrix.rust }}
          components: rustfmt, clippy

      - name: Cache cargo
        uses: actions/cache@v4
        with:
          path: |
            ~/.cargo/registry/index
            ~/.cargo/registry/cache
            ~/.cargo/git
            target/
          key: ${{ runner.os }}-cargo-${{ hashFiles('**/Cargo.lock') }}
          restore-keys: ${{ runner.os }}-cargo-

      - name: Check formatting
        run: cargo fmt --all -- --check

      - name: Run clippy
        run: cargo clippy --all-features -- -D warnings

      - name: Build
        run: cargo build --verbose --all-features

      - name: Run tests
        run: cargo test --verbose --all-features

      - name: Run smoke test
        if: runner.os != 'Windows'
        run: |
          cargo build --release
          bash scripts/batch_smoke.sh

  # Python tests
  python-test:
    name: Python Tests (${{ matrix.os }}, Python ${{ matrix.python }})
    runs-on: ${{ matrix.os }}
    strategy:
      matrix:
        os: [ubuntu-latest, macos-latest, windows-latest]
        python: ['3.8', '3.12']
    steps:
      - uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python }}

      - name: Setup Rust
        uses: dtolnay/rust-toolchain@stable

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install maturin pytest numpy fire

      - name: Build and install package
        run: |
          maturin develop --release --features python

      - name: Run Python tests
        run: |
          pytest python/tests -v

      - name: Test CLI
        run: |
          python -m haforu version
          python -m haforu --help

  # Documentation
  docs:
    name: Documentation
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Setup Rust
        uses: dtolnay/rust-toolchain@stable

      - name: Build documentation
        run: cargo doc --all-features --no-deps

      - name: Check documentation
        run: cargo test --doc

  # Benchmarks (optional, runs on main branch only)
  benchmark:
    name: Performance Benchmark
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'
    steps:
      - uses: actions/checkout@v4

      - name: Setup Rust
        uses: dtolnay/rust-toolchain@stable

      - name: Build release
        run: cargo build --release

      - name: Run performance test
        run: |
          echo "Running performance benchmark..."
          time bash scripts/run.sh perf

      - name: Upload benchmark results
        uses: actions/upload-artifact@v4
        with:
          name: benchmark-results
          path: |
            *.json
            *.txt
        if: always()

  # Security audit
  security:
    name: Security Audit
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Setup Rust
        uses: dtolnay/rust-toolchain@stable

      - name: Install cargo-audit
        run: cargo install cargo-audit

      - name: Run security audit
        run: cargo audit

  # Coverage (optional)
  coverage:
    name: Code Coverage
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Setup Rust
        uses: dtolnay/rust-toolchain@stable

      - name: Install tarpaulin
        run: cargo install cargo-tarpaulin

      - name: Run coverage
        run: cargo tarpaulin --out xml --all-features

      - name: Upload coverage to Codecov
        uses: codecov/codecov-action@v4
        with:
          files: ./cobertura.xml
          fail_ci_if_error: false
        continue-on-error: true
</document_content>
</document>

<document index="2">
<source>.github/workflows/release.yml</source>
<document_content>
# this_file: .github/workflows/release.yml

name: Release

on:
  push:
    tags:
      - 'v*'
  workflow_dispatch:
    inputs:
      tag:
        description: 'Tag to release (e.g., v2.1.0)'
        required: true
        type: string

env:
  CARGO_TERM_COLOR: always
  PYTHON_VERSION: '3.12'

jobs:
  # Extract version and changelog
  prepare:
    name: Prepare Release
    runs-on: ubuntu-latest
    outputs:
      version: ${{ steps.version.outputs.version }}
      changelog: ${{ steps.changelog.outputs.changelog }}
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Extract version
        id: version
        run: |
          if [[ "${{ github.event_name }}" == "workflow_dispatch" ]]; then
            VERSION="${{ github.event.inputs.tag }}"
          else
            VERSION="${GITHUB_REF#refs/tags/}"
          fi
          echo "version=${VERSION#v}" >> $GITHUB_OUTPUT
          echo "Version: ${VERSION#v}"

      - name: Extract changelog
        id: changelog
        run: |
          VERSION="${{ steps.version.outputs.version }}"
          # Extract the section for this version from CHANGELOG.md
          awk "/## ${VERSION}/,/## [0-9]/" CHANGELOG.md | head -n -2 > changelog.txt || echo "No changelog found for ${VERSION}" > changelog.txt
          echo "changelog<<EOF" >> $GITHUB_OUTPUT
          cat changelog.txt >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT

  # Build Rust binaries
  rust-binaries:
    name: Build Rust Binary (${{ matrix.os }})
    runs-on: ${{ matrix.runner }}
    strategy:
      matrix:
        include:
          - os: linux-x64
            runner: ubuntu-latest
            target: x86_64-unknown-linux-gnu
            artifact: haforu-linux-x64

          - os: linux-arm64
            runner: ubuntu-latest
            target: aarch64-unknown-linux-gnu
            artifact: haforu-linux-arm64

          - os: macos-x64
            runner: macos-13
            target: x86_64-apple-darwin
            artifact: haforu-macos-x64

          - os: macos-arm64
            runner: macos-14
            target: aarch64-apple-darwin
            artifact: haforu-macos-arm64

          - os: windows-x64
            runner: windows-latest
            target: x86_64-pc-windows-msvc
            artifact: haforu-windows-x64

    steps:
      - uses: actions/checkout@v4

      - name: Setup Rust
        uses: dtolnay/rust-toolchain@stable
        with:
          targets: ${{ matrix.target }}

      - name: Setup cross-compilation (Linux ARM64)
        if: matrix.target == 'aarch64-unknown-linux-gnu'
        run: |
          sudo apt-get update
          sudo apt-get install -y gcc-aarch64-linux-gnu
          echo "CARGO_TARGET_AARCH64_UNKNOWN_LINUX_GNU_LINKER=aarch64-linux-gnu-gcc" >> $GITHUB_ENV

      - name: Build binary
        run: |
          cargo build --release --target ${{ matrix.target }} --bin haforu

      - name: Package binary (Unix)
        if: runner.os != 'Windows'
        run: |
          cd target/${{ matrix.target }}/release
          tar czf ${{ matrix.artifact }}.tar.gz haforu
          mv ${{ matrix.artifact }}.tar.gz ../../../

      - name: Package binary (Windows)
        if: runner.os == 'Windows'
        run: |
          cd target/${{ matrix.target }}/release
          7z a ${{ matrix.artifact }}.zip haforu.exe
          mv ${{ matrix.artifact }}.zip ../../../

      - name: Upload artifact
        uses: actions/upload-artifact@v4
        with:
          name: ${{ matrix.artifact }}
          path: |
            *.tar.gz
            *.zip

  # Build Python wheels
  python-wheels:
    name: Build Python Wheels (${{ matrix.os }})
    runs-on: ${{ matrix.runner }}
    strategy:
      matrix:
        include:
          - os: linux
            runner: ubuntu-latest
            artifact: wheels-linux

          - os: macos
            runner: macos-14
            artifact: wheels-macos

          - os: windows
            runner: windows-latest
            artifact: wheels-windows

    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0  # Need full history for hatch-vcs

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install maturin build

      - name: Build wheels (Linux)
        if: runner.os == 'Linux'
        uses: PyO3/maturin-action@v1
        with:
          command: build
          args: --release --features python -o dist
          manylinux: auto
          target: x86_64

      - name: Build wheels (macOS)
        if: runner.os == 'macOS'
        uses: PyO3/maturin-action@v1
        with:
          command: build
          args: --release --features python --universal2 -o dist
          target: universal2-apple-darwin

      - name: Build wheels (Windows)
        if: runner.os == 'Windows'
        uses: PyO3/maturin-action@v1
        with:
          command: build
          args: --release --features python -o dist
          target: x64

      - name: Upload wheels
        uses: actions/upload-artifact@v4
        with:
          name: ${{ matrix.artifact }}
          path: dist/*.whl

  # Build source distribution
  sdist:
    name: Build Source Distribution
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install maturin build

      - name: Build sdist
        run: maturin sdist -o dist

      - name: Upload sdist
        uses: actions/upload-artifact@v4
        with:
          name: sdist
          path: dist/*.tar.gz

  # Create GitHub Release
  github-release:
    name: Create GitHub Release
    runs-on: ubuntu-latest
    needs: [prepare, rust-binaries, python-wheels, sdist]
    permissions:
      contents: write
    steps:
      - uses: actions/checkout@v4

      - name: Download all artifacts
        uses: actions/download-artifact@v4
        with:
          path: artifacts

      - name: Organize artifacts
        run: |
          mkdir release
          find artifacts -type f \( -name "*.tar.gz" -o -name "*.zip" -o -name "*.whl" \) -exec mv {} release/ \;
          ls -la release/

      - name: Create Release
        uses: softprops/action-gh-release@v1
        with:
          tag_name: v${{ needs.prepare.outputs.version }}
          name: Release v${{ needs.prepare.outputs.version }}
          body: |
            ## Haforu v${{ needs.prepare.outputs.version }}

            ### Changes
            ${{ needs.prepare.outputs.changelog }}

            ### Installation

            #### Rust CLI
            Download the appropriate binary for your platform and add it to your PATH.

            #### Python Package
            ```bash
            pip install haforu
            ```

            ### Assets
            - **Rust Binaries**: Pre-compiled binaries for Linux, macOS, and Windows
            - **Python Wheels**: Platform-specific wheels for easy installation
            - **Source Distribution**: For building from source

          files: release/*
          draft: false
          prerelease: false

  # Publish to PyPI
  publish-pypi:
    name: Publish to PyPI
    runs-on: ubuntu-latest
    needs: [github-release]
    environment:
      name: pypi
      url: https://pypi.org/project/haforu/
    permissions:
      id-token: write  # For trusted publishing
    steps:
      - name: Download wheels and sdist
        uses: actions/download-artifact@v4
        with:
          pattern: wheels-*
          path: dist
          merge-multiple: true

      - name: Download sdist
        uses: actions/download-artifact@v4
        with:
          name: sdist
          path: dist

      - name: Publish to PyPI
        uses: pypa/gh-action-pypi-publish@release/v1
        with:
          packages-dir: dist/
          skip-existing: true

  # Publish to crates.io
  publish-crates:
    name: Publish to crates.io
    runs-on: ubuntu-latest
    needs: [prepare, github-release]
    steps:
      - uses: actions/checkout@v4

      - name: Setup Rust
        uses: dtolnay/rust-toolchain@stable

      - name: Update version in Cargo.toml
        run: |
          VERSION="${{ needs.prepare.outputs.version }}"
          sed -i "s/^version = .*/version = \"$VERSION\"/" Cargo.toml

      - name: Publish to crates.io
        run: cargo publish --token ${{ secrets.CARGO_REGISTRY_TOKEN }}
        continue-on-error: true  # Don't fail if already published
</document_content>
</document>

<document index="3">
<source>.gitignore</source>
<document_content>
# this_file: .gitignore

# Rust
/target
**/*.rs.bk
*.pdb
Cargo.lock

# Python
__pycache__/
*.py[cod]
*$py.class
*.so
.Python
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
*.egg-info/
.installed.cfg
*.egg
.python-version

# Maturin
python/haforu/*.so
python/haforu/*.pyd

# Generated version file
python/haforu/_version.py

# IDEs
.vscode/
.idea/
*.swp
*.swo
*~

# Testing
.pytest_cache/
.coverage
htmlcov/
.tox/

# OS
.DS_Store
Thumbs.db
reference/

# Build artifacts
*.tar.gz
*.zip
target/dist/
target/completions/
target/wheels/

# CI/CD cache
.github/workflows/.cache/

# Documentation builds
site/
docs/_build/

# Logs
*.log
npm-debug.log*
yarn-debug.log*
yarn-error.log*

# Temporary files
tmp/
temp/
*.tmp
.venv/
</document_content>
</document>

<document index="4">
<source>ANALYSIS_SUMMARY.md</source>
<document_content>
# Haforu2 Architectural Analysis - Summary Report

**Analysis Date:** 2025-11-11  
**Analyst:** Claude (Haiku 4.5)  
**Status:** Complete & Ready for Implementation

---

## What Was Analyzed

Comprehensive architectural requirements for **Haforu2**, a Rust-native batch font renderer designed to solve FontSimi's critical performance bottleneck:

1. **Current State:** FontSimi takes 5+ hours to render 5.5M glyphs (250 fonts Ã— 85 instances Ã— 5 segments Ã— 52 glyphs), consuming 86GB RAM with frequent OOM crashes
2. **Root Cause:** 5.5M individual Pythonâ†’Native boundary crossings (50-100ms overhead each)
3. **Solution:** Haforu2 batch processor (1100 batches of 5000 jobs, single boundary crossing per batch)
4. **Expected Result:** 100Ã— speedup (5h â†’ 3m), 97% memory reduction (86GB â†’ <2GB)

---

## Key Documents Generated

### 1. **ARCHITECTURE.md** (25 KB, 9 sections)
Comprehensive technical reference covering:
- FontSimi bottleneck analysis with performance metrics
- Haforu2 design requirements and principles
- Technical architecture (module structure, data flow)
- Implementation roadmap (H2.1-H2.7, 12-18 days)
- Design decisions with trade-off analysis
- Risk analysis and mitigation strategies
- Integration points with FontSimi (H1-H5)
- Standalone value proposition
- Testing strategy

**Audience:** Engineers, architects, technical leads

### 2. **KEY_FINDINGS.md** (8.3 KB, 10 insights)
Executive summary with critical insights:
- The bottleneck is architectural (not computational)
- Haforu2 vs Haforu1 architectural differences
- Performance targets are achievable
- Generic, not FontSimi-specific design
- Technical decisions and rationale
- 12-18 day implementation timeline
- Integration phases (H1-H5)
- Risk mitigation strategies
- Comprehensive validation approach

**Audience:** Decision makers, project managers, stakeholders

---

## Critical Findings

### Finding 1: Bottleneck Root Cause
**Insight:** The problem is NOT rendering performance (rendering takes 5-10ms per glyph), but ARCHITECTURAL OVERHEAD (Pythonâ†’Native boundary crossing adds 50-100ms per call).

**Evidence:**
- 5.5M calls Ã— 50ms overhead = 275,000 seconds (76 hours) overhead
- 5.5M calls Ã— 5ms computation = 27,500 seconds (7.6 hours) actual work
- **Result:** Overhead is 10-20Ã— larger than actual computation

**Solution:** Amortize overhead across batch (1100 calls instead of 5.5M)

---

### Finding 2: Haforu2 is Architecturally Sound
**Design Principles:**
1. Stateless job processing (no cross-job state)
2. Memory-mapped fonts (250MB, not 86GB)
3. Batch processing (1100 calls, not 5.5M)
4. Streaming output (progressive results)
5. Parallel execution (8Ã— speedup)
6. Simple subprocess communication (JSONâ†’JSONL)

**Why This Works:**
- 250 fonts cached in 250MB (no per-glyph allocation)
- 5000 jobs per subprocess invocation (amortize spawn overhead)
- JSONL streaming enables progressive processing
- Parallel rayon processing = 8Ã— speedup
- Subprocess communication = simple, testable, isolated

---

### Finding 3: Implementation is Feasible in 12-18 Days
**Sequential Phases (each builds on previous):**
- H2.1: JSON parsing (2-3 days) â€” Lowest risk
- H2.2: Font loading (2-3 days) â€” Core foundation
- H2.3: Text shaping (2-3 days) â€” HarfRust integration
- H2.4: Rasterization (3-4 days) â€” skrifa + zeno
- H2.5: PGM output (1-2 days) â€” Simple format
- H2.6: JSONL output (1-2 days) â€” Streaming
- H2.7: Error handling (1-2 days) â€” Edge cases + tests

**Total:** 12-18 days (no parallelization possible due to dependencies)

---

### Finding 4: All Dependencies are Proven
**No risky or unproven choices:**
- serde/serde_json: Industry standard JSON
- read-fonts/skrifa: Zero-copy font parsing (proven)
- harfbuzz-rs: Industry standard text shaping
- zeno: Lightweight, fast rasterization
- memmap2: Standard memory mapping
- rayon: Standard parallel processing
- anyhow: Standard error handling
- clap: Latest CLI framework

---

### Finding 5: Performance Targets are Achievable
**Per-Job Performance:**
- Parse JSON: <100Âµs
- Load font: <0.1ms (cache), 1ms (first)
- Shape text: 0.5-2ms
- Rasterize: 2-5ms
- Encode: 5-10ms
- **Total:** 10-15ms per job (67-100 jobs/sec)

**Batch Performance (5000 jobs):**
- Sequential: 50-75 seconds
- 8 threads: 30-40 seconds (8Ã— speedup)
- 30 parallel processes: 20 minutes total

**FontSimi Analysis (5.5M glyphs):**
- Target: 3 minutes (from PLAN.md)
- With streaming cache: Achievable âœ“

---

### Finding 6: Design is Generic (Standalone Value)
**Not FontSimi-specific:**
- Generic batch font renderer
- Input: JSON jobs (font, size, text, variations)
- Output: JSONL results (base64 images)
- Pluggable formats (PGM, PNG, SVG, metrics JSON)

**Beyond FontSimi:**
1. Font development (batch instance rendering)
2. QA (regression testing on font corpus)
3. Web services (specimen PDFs, preview images)
4. Benchmarking (rendering quality comparison)

---

## Integration Timeline

**Phase H1:** âœ… Complete (HaforuRenderer Python class, 348 lines, 38 tests)

**Phase H2:** â¸ï¸ In Progress (Haforu2 Rust rendering, 12-18 days)

**Phase H3:** Ready after H2 (FontSimi batch pipeline, 5-9 days)

**Phase H4:** Ready after H3 (Streaming mode for deep matching, 6-9 days)

**Phase H5:** Ready after H4 (Performance validation, 3-5 days)

**Total Timeline:** 4-6 weeks from H2 start

---

## Success Criteria

### Performance Metrics
- âœ… Analysis: 5h â†’ 3m (100Ã— speedup)
- âœ… Memory: 86GB â†’ <2GB (97% reduction)
- âœ… Deep Matching: 30s â†’ 0.6s per pair (50Ã— speedup)
- âœ… Reliability: Zero OOM crashes

### Quality Metrics
- âœ… Test Coverage: 100% (unit + integration + regression)
- âœ… Determinism: Identical Daidot metrics vs baseline
- âœ… Compatibility: All 250 fonts Ã— 85 instances
- âœ… Documentation: Comprehensive, examples, troubleshooting

---

## Risks & Mitigation

| Risk | Severity | Mitigation |
|------|----------|-----------|
| Haforu binary not found | HIGH | Fallback to CoreText/HarfBuzz |
| JSON parsing error | MEDIUM | Validate size, reject >100MB |
| Font corruption | HIGH | Graceful error, retry individually |
| Memory spike | HIGH | Stream to disk, don't hold all |
| Out-of-order JSONL | MEDIUM | Job ID correlation |
| Rendering mismatch | LOW | Pixel-perfect validation |

**All risks have clear mitigation paths** âœ“

---

## Next Steps

### Immediate (Haforu2 Implementation)
1. Create `Cargo.toml` with dependencies
2. Scaffold module structure
3. Implement H2.1 (JSON parsing) â€” Start here
4. Proceed sequentially H2.2-H2.7

### After H2 (FontSimi Integration)
1. Validate Daidot metrics match baseline
2. Implement H3 batch pipeline
3. Benchmark and optimize
4. Proceed to H4 streaming mode

### Documentation
1. âœ… ARCHITECTURE.md: Complete
2. âœ… KEY_FINDINGS.md: Complete
3. Create H2.1 implementation guide
4. Add performance benchmarking guide

---

## Documents Location

```
/Users/adam/Developer/vcs/github.fontlaborg/haforu2/
â”œâ”€â”€ ARCHITECTURE.md      (25 KB, 9 sections)
â””â”€â”€ KEY_FINDINGS.md      (8.3 KB, 10 insights)
```

---

## Conclusion

**Haforu2 is architecturally sound, strategically important, and feasible.**

The FontSimi bottleneck is not computational (rendering is fast at ~5ms), but architectural (Pythonâ†’Native overhead is ~100ms). Haforu2 solves this by:

1. **Batching:** 5.5M calls â†’ 1100 batches (50Ã— reduction)
2. **Memory efficiency:** 86GB â†’ 250MB fonts (340Ã— reduction)
3. **Parallelism:** 8Ã— speedup via rayon
4. **Streaming:** Progressive results, early error detection

**Expected outcomes:**
- 100Ã— speedup (5h â†’ 3m)
- 97% memory reduction (86GB â†’ <2GB)
- Zero OOM crashes
- Production-ready within 4-6 weeks

The analysis is complete and ready for implementation.

---

**Analysis Status:** âœ… COMPLETE  
**Implementation Status:** â¸ï¸ READY TO BEGIN  
**Risk Level:** LOW (all dependencies proven, clear mitigation paths)  
**Confidence:** HIGH (architectural soundness validated)
</document_content>
</document>

<document index="5">
<source>ARCHITECTURE.md</source>
<document_content>
# Haforu2: Comprehensive Architectural Analysis

**Date:** 2025-11-11  
**Project:** FontSimi v3 + Haforu2 Integration  
**Status:** H2.1-H2.7 Implementation Planning (Ready to Begin)

---

## Executive Summary

**Problem Statement:**
- FontSimi must render 5.5 million glyphs (250 fonts Ã— 85 instances Ã— 5 segments Ã— 52 glyphs)
- Current Python renderers: 5+ hours, 86GB RAM, frequent OOM crashes
- Root cause: Individual Pythonâ†’Native boundary crossings (object alloc/dealloc per render)

**Haforu2 Solution:**
- Rust-native batch font renderer processing thousands of jobs in one subprocess call
- Memory-mapped fonts (zero-copy)
- Single native boundary crossing per batch
- Expected: 100Ã— speedup (5h â†’ 3m), 97% memory reduction (86GB â†’ <2GB)

**Integration Model:**
- **Phase H1:** âœ… Python HaforuRenderer class (subprocess communication, JSONâ†’JSONL)
- **Phase H2:** â¸ï¸ Haforu2 Rust implementation (12-18 days)
- **Phase H3:** Python batch analysis pipeline
- **Phase H4:** Streaming mode for deep matching
- **Phase H5:** Performance validation

---

## Section 1: FontSimi Bottleneck Analysis

### 1.1 Current Performance Metrics

| Metric | Value | Problem |
|--------|-------|---------|
| **Total Render Calls** | 5.5M | Each crosses Pythonâ†’Native |
| **Fonts** | 250 | Most static, some variable with 2-16 axes |
| **Variable Instances** | 85 | Intermediate: wght, wdth, opsz mostly |
| **Script Segments** | 5 | Latn, ULAT, Cyrl, UCYR, Grek, etc. |
| **Glyphs per Segment** | 52 | Single glyph per render: "a", "b", "c", etc. |
| **Runtime** | 5+ hours | Dominated by render overhead, not computation |
| **Memory Peak** | 86GB | 5.5M images Ã— 1.5MB each (uncompressed) |
| **OOM Crashes** | Frequent | During peak font loading + rendering |

### 1.2 Root Cause: Pythonâ†’Native Boundary Overhead

**Current Architecture (Python):**
```
for font in fonts:
  for instance_coords in instances:
    for segment in segments:
      for glyph in glyphs:
        image = renderer.render_text(glyph)  # â† Native call (high overhead)
```

**Per-Call Overhead:**
- Python function call â†’ C/Rust native boundary
- Object allocation (PIL Image, numpy array)
- Object deallocation (garbage collection trigger)
- Native function execution (typically <5ms)
- **Total overhead per call:** ~50-100ms (10-20Ã— computation cost)

**Memory Explosion:**
- Each render produces ~1.5MB uncompressed grayscale image
- No shared buffer pool; each image is separate allocation
- Python GC pressure causes pause stops
- Result: 5.5M Ã— 1.5MB Ã· compression â‰ˆ 86GB peak (uncompressed)

### 1.3 Current Python Renderer Implementations

| Renderer | Backend | Mechanism | Per-Call Overhead | Bottleneck |
|----------|---------|-----------|------------------|-----------|
| **HarfBuzz** | libharfbuzz | Python/C boundary | 40ms | Shaping + rasterization |
| **CoreText** | macOS | Objective-C bridge | 60ms | ObjC boundary crossing |
| **Skia** | libskia | Python/C boundary | 80ms | Heavy graphics library |
| **Pillow** | pure Python | 100% Python | 20ms | CPU rasterization but no C boundary |
| **Haforu (current)** | subprocess | stdin/stdout JSON | 500ms | Subprocess spawn overhead |

### 1.4 FontSimi's Unique Daidot Metrics

**4-Metric Model (simplified from 8D):**
1. `width_rhythm` - Horizontal character spacing consistency
2. `rendered_aspect` - Visual height/width ratio
3. `density` - Overall pixel coverage
4. `consistency` - Variance across glyphs

**Why This Matters for Haforu:**
- Only need grayscale images (no color rendering)
- 1000pt font size standard (high resolution for metric stability)
- 3000Ã—1200 canvas typical (fixed for consistent metrics)
- Single glyph per image (no shaping complexity)
- No kerning, ligatures, or complex scripts needed

---

## Section 2: Haforu2 Design Requirements

### 2.1 FontSimi Integration Requirements

**Batch Job Specification Format:**
```json
{
  "version": "1.0",
  "mode": "batch",
  "config": {
    "max_memory_mb": 2000,
    "output_format": "base64",
    "include_metrics": false
  },
  "jobs": [
    {
      "id": "font1_wght600_Latn_a",
      "font": {
        "path": "/path/to/font.ttf",
        "size": 1000,
        "variations": {"wght": 600, "wdth": 100},
        "face_index": 0
      },
      "text": {
        "content": "a",
        "script": "Latn",
        "direction": "ltr",
        "language": "en"
      },
      "rendering": {
        "format": "pgm",
        "encoding": "binary",
        "width": 3000,
        "height": 1200
      }
    }
    // ... 5000+ more jobs
  ]
}
```

**Expected Job Characteristics:**
- Batch size: 1000-5000 jobs per invocation
- Jobs per second: 500-1000 (target: 3m for 5.5M Ã· 30 batches)
- Memory per job: ~1.5KB JSON + 1.5MB rendered (not held simultaneously)
- Variable fonts: 60% of jobs (rest static)

**JSONL Output Format:**
```jsonl
{"id":"font1_wght600_Latn_a","status":"success","rendering":{"format":"pgm","encoding":"base64","data":"Rjk1CjMwMDAg...","width":3000,"height":1200,"actual_bbox":[500,200,800,600]},"timing":{"shape_ms":2.1,"render_ms":4.3,"total_ms":8.5},"memory":{"font_cache_mb":1.2,"total_mb":45.6}}
{"id":"font1_wght600_Latn_b","status":"success","rendering":{...},"timing":{...}}
```

### 2.2 Haforu2 Architectural Principles

**Core Design:**
1. **Stateless Job Processing:** Each job is independent; no cross-job state
2. **Memory-Mapped Fonts:** Zero-copy font loading via memmap2 crate
3. **Font Instance Caching:** LRU cache of (path, variations) â†’ skrifa FontRef
4. **Parallel Job Processing:** rayon parallelism across jobs
5. **Streaming Output:** Write JSONL immediately as jobs complete
6. **Subprocess Communication:** stdin JSON â†’ stdout JSONL (simple Unix pipes)

**Why This Design:**
- **Stateless:** Easy to scale horizontally (no shared state)
- **Memory-mapped:** 250 fonts Ã— 1MB each = 250MB (not 86GB)
- **Streaming:** Python can start processing results while Haforu still working
- **Subprocess:** Simple to invoke, no Python/Rust FFI complexity
- **Parallel:** rayon handles NUMA and thread pool automatically

### 2.3 Haforu2 Feature Matrix

| Feature | Phase | Priority | FontSimi Requirement | Notes |
|---------|-------|----------|----------------------|-------|
| JSON job parsing | H2.1 | CRITICAL | 5000+ jobs/batch | Must parse in <500ms |
| Font loading (static) | H2.2 | CRITICAL | 250 fonts | Must load in <1ms each |
| Font loading (variable) | H2.2 | CRITICAL | 85 instances | Must apply coords in <5ms |
| Font caching | H2.2 | CRITICAL | 512 font instances | LRU, >90% hit rate |
| Text shaping | H2.3 | CRITICAL | 52 glyphs/segment | HarfRust (one char) |
| Glyph rasterization | H2.4 | CRITICAL | 3000Ã—1200 grayscale | skrifaâ†’zeno path |
| PGM P5 output | H2.5 | HIGH | FontSimi format | 8-bit grayscale binary |
| Base64 encoding | H2.5 | HIGH | JSON compatibility | JSONL string embedding |
| Bounding box calc | H2.5 | MEDIUM | Metric stability | For crop optimization |
| Error handling | H2.7 | HIGH | Partial failure recovery | Continue on bad fonts |
| Streaming JSON output | H2.6 | CRITICAL | Progressive results | Flush per job |
| Streaming mode (persistent process) | H4 | MEDIUM | Deep matching speedup | Future optimization |

### 2.4 Haforu2 Standalone Value Proposition

Beyond FontSimi, Haforu2 is useful for:

**1. Font Development (FontLab, ufo, Glyphs):**
- Batch render instances during design iteration
- Compare rendering across sizes/weights quickly
- Export to analysis tools

**2. Quality Assurance:**
- Regression test suite: render known fonts, compare outputs
- Smoke tests: verify no crashes on corpus of 10K fonts
- Rendering consistency check: static vs variable instances

**3. Content Generation:**
- Generate glyph preview images for web (emoji, symbol fonts)
- Create specimen PDFs with batch rendered instances
- Font matching service backend

**4. Performance Testing:**
- Benchmark new font rasterizers
- Profile memory usage under load
- Compare rendering quality (PNG diff)

**Design for Standalone Use:**
- No FontSimi-specific code (generic fontâ†’glyphâ†’image pipeline)
- Pluggable output formats (PGM, PNG, SVG, metrics JSON)
- Generic job ID scheme (user can choose naming)
- Configurable font cache size, max memory, parallel workers

---

## Section 3: Haforu2 Technical Architecture

### 3.1 Module Structure

```
external/haforu2/
â”œâ”€â”€ Cargo.toml                 # Rust dependencies
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.rs               # Entry point, CLI arg parsing
â”‚   â”œâ”€â”€ lib.rs                # Public API (for future PyO3)
â”‚   â”œâ”€â”€ json_parser.rs        # JobSpec/Job deserialization + validation
â”‚   â”œâ”€â”€ error.rs              # Error types and conversion
â”‚   â”œâ”€â”€ mmap_font.rs          # Memory-mapped font loading
â”‚   â”œâ”€â”€ font_cache.rs         # LRU font instance cache
â”‚   â”œâ”€â”€ shaping.rs            # HarfRust text shaping
â”‚   â”œâ”€â”€ rasterize.rs          # Glyph rasterization (skrifaâ†’zeno)
â”‚   â”œâ”€â”€ output.rs             # PGM format and base64 encoding
â”‚   â”œâ”€â”€ orchestrator.rs       # Job processing pipeline
â”‚   â””â”€â”€ stats.rs              # Metrics and statistics
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ integration_tests.rs  # End-to-end tests
â”‚   â””â”€â”€ unit_tests.rs         # Per-module unit tests
â””â”€â”€ fonts/                     # Test fonts (TTF, OTF, VF)
```

### 3.2 Data Flow: Batch Mode

```
User Input (FontSimi Python)
     â†“
[stdin] JSON (5000 jobs)
     â†“
Haforu2 Process (Arc<Haforu>)
     â”œâ”€ json_parser::parse_stdin()
     â”œâ”€ For each job (parallel via rayon):
     â”‚  â”œâ”€ font_cache.get_or_load_instance(path, coords)
     â”‚  â”œâ”€ shaping::shape_text(font, "a")
     â”‚  â”œâ”€ rasterize::render_glyphs(shaped)
     â”‚  â”œâ”€ output::encode_pgm_base64(pixels)
     â”‚  â””â”€ JobResult { id, status, rendering, timing }
     â””â”€ Write JSONL line to stdout
     â†“
[stdout] JSONL (5000 results)
     â†“
FontSimi Python (parse JSONL, extract images)
```

### 3.3 Implementation Roadmap: H2.1 - H2.7

**Total Estimated Time:** 12-18 days

| Phase | Tasks | Time | Dependencies |
|-------|-------|------|--------------|
| H2.1 | JSON parsing, validation, stdin reading | 2-3d | None |
| H2.2 | Font loading, variations, caching | 2-3d | H2.1 (file I/O) |
| H2.3 | Text shaping (HarfRust) | 2-3d | H2.2 (fonts) |
| H2.4 | Glyph rasterization (skrifa+zeno) | 3-4d | H2.3 (shaped glyphs) |
| H2.5 | PGM output, base64, bounding box | 1-2d | H2.4 (pixels) |
| H2.6 | JSONL formatting, streaming output | 1-2d | H2.5 (output) |
| H2.7 | Error handling, edge cases, tests | 1-2d | All above |

**Critical Path:** H2.1 â†’ H2.2 â†’ H2.3 â†’ H2.4 â†’ H2.5 â†’ H2.6 â†’ H2.7 â†’ Testing

### 3.4 Key Dependencies & Justification

| Dependency | Version | Why Chosen | Alternatives |
|------------|---------|-----------|--------------|
| `serde` | Latest | JSON parsing (proven, fast) | json5, toml |
| `serde_json` | Latest | JSON serialization | jsonc, ron |
| `read-fonts` | Latest | Zero-copy font parsing | fonttools (Python), fontparts |
| `skrifa` | Latest | Variable font support | freetype-py, harfbuzz only |
| `harfbuzz-rs` | Latest | Text shaping | rustybuzz (pure Rust, slower) |
| `zeno` | Latest | CPU rasterization | pathfinder (heavier), tiny-skia |
| `memmap2` | Latest | Memory-mapped I/O | mmap crate (older), std::fs |
| `rayon` | Latest | Parallel job processing | crossbeam (lower-level), tokio (async) |
| `anyhow` | Latest | Error handling | thiserror (more verbose), failure (older) |
| `clap` | Latest | CLI argument parsing | structopt (deprecated for clap v4) |

### 3.5 Performance Targets

**Per-Job Performance:**
- Parse JSON: <100Âµs per job (5M jobs in 500ms)
- Load font: 1ms first time, <0.1ms cache hit
- Shape text: 0.5-2ms (single character is fast)
- Rasterize: 2-5ms (3000Ã—1200 at 1000pt)
- Encode PGM+base64: 5-10ms (compression, not typical)
- **Total per job:** ~10-15ms (100-150 jobs/sec with 8 threads)

**Batch Performance:**
- 5000 jobs: ~5 minutes (sequential, 10ms/job)
- 5000 jobs: ~30-40 seconds (parallel, 8 threads, ~500 jobs/sec)
- Memory: <2GB (250 fonts in cache + 1-2 in-flight renders)

**FontSimi Integration:**
- 5.5M glyphs Ã· 5000 jobs/batch = 1100 batches
- 1100 batches Ã— 40s = 44,000s = 12.2 hours (naive sequential)
- 1100 batches Ã— 40s Ã· 30 parallel processes = ~20 minutes (if parallelized)
- But: Process can be parallelized across machines/containers

**Optimizations Not in H2 (Future):**
- Streaming mode: keep process alive, render on-demand for deep matching
- Distributed mode: split batch across N machines
- Storage backend: pack renders into compressed shards (reduce I/O)

---

## Section 4: Integration Points with FontSimi

### 4.1 Phase H1 (Complete): HaforuRenderer Python Class

**File:** `src/fontsimi/renderers/haforu.py` (348 lines, âœ… tested)

**Responsibilities:**
- Discover haforu binary (env var or repo path)
- Generate JSON job spec
- Spawn subprocess, pass JSON via stdin
- Read JSONL from stdout
- Parse results, extract base64 PGM
- Decode to numpy array
- Clean up temp files

**Key Methods:**
```python
class HaforuRenderer(BaseRenderer):
    def render_text(self, text: str) -> np.ndarray[uint8]:
        """Render single text string, return grayscale image."""
        # 1. Generate job JSON
        # 2. Spawn haforu subprocess
        # 3. Pass JSON via stdin
        # 4. Read JSONL from stdout
        # 5. Decode base64 PGM
        # 6. Return numpy array
```

**Current Status:**
- âœ… JSON generation working
- âœ… Subprocess communication working
- âœ… JSONL parsing working
- â¸ï¸ Haforu Rust returns "pending" (not rendering yet)
- âœ… 38 unit tests passing

### 4.2 Phase H2 (In Progress): Haforu2 Rust Implementation

**Goal:** Make Haforu actually render fonts

**Success Criteria:**
- Parses JSON in <500ms for 5000 jobs
- Renders 500 jobs/sec (8 threads)
- Memory <2GB peak
- Daidot metrics identical to CoreText/HarfBuzz (pixel perfect)
- All error cases handled gracefully

### 4.3 Phase H3 (Ready After H2): FontSimi Batch Pipeline

**File:** `src/fontsimi/daidot/daidot_analyzer.py`

**Changes:**
- Collect render jobs instead of rendering immediately
- Generate 5500K jobs in batches of 5000
- Invoke haforu subprocess per batch
- Parse JSONL results
- Compute Daidot metrics from images
- Store in cache

**Expected Timeline:** 5-9 days after H2 complete

### 4.4 Phase H4 (Future): Streaming Mode

**Improvement:** Keep haforu process alive during deep matching optimization

**Benefit:** Eliminate subprocess spawn overhead (500ms â†’ 20ms per render)

**Expected Timeline:** 6-9 days after H3 complete

### 4.5 Phase H5 (Validation): Performance Targets

**Metrics to Verify:**
- Analysis: 5h â†’ 3m (100Ã— speedup) âœ…
- Memory: 86GB â†’ <2GB (97% reduction) âœ…
- Deep matching: 30s â†’ 0.6s per pair (50Ã— speedup) âœ…
- Reliability: Zero OOM crashes âœ…

**Expected Timeline:** 3-5 days after H4 complete

---

## Section 5: Design Decisions & Trade-offs

### 5.1 Subprocess Communication vs FFI

**Choice:** Subprocess (stdin JSON â†’ stdout JSONL)

**Reasons:**
- No Python/Rust FFI complexity (no PyO3, maturin)
- Simple testing (echo JSON files)
- Language-agnostic (could invoke from Java, Go, etc.)
- Process isolation prevents crashes from affecting FontSimi
- Easier debugging (strace, stderr logging)

**Trade-offs:**
- Subprocess spawn overhead ~500ms (Phase H4 streaming mode fixes)
- JSON serialization overhead (negligible vs rendering time)
- Large JSONL output (compressed with gzip in production)

### 5.2 Memory-Mapped Fonts vs Heap Loading

**Choice:** Memory-mapped (memmap2 crate)

**Reasons:**
- 250 fonts Ã— 1MB = 250MB (vs 86GB for all renders)
- OS page cache reuses across processes
- Zero-copy to skrifa/read-fonts
- Automatic paging in/out

**Trade-offs:**
- Slightly more complex code (unsafe blocks for lifetime transmute)
- MMAP not available on very constrained systems (rare)
- File descriptor limits for 1000+ fonts (non-issue for 250)

### 5.3 LRU Font Cache vs Always-Reload

**Choice:** LRU cache with 512 font instance entries

**Reasons:**
- 85 variable instances Ã— 3 coordinate sets = 255 instance variations
- 512 gives 2Ã— safety margin
- Cache hit rate >90% in typical FontSimi workload

**Trade-offs:**
- Slightly more complex code (lru crate dependency)
- Memory overhead for cache bookkeeping (negligible)
- Eviction policy (LRU) deterministic and testable

### 5.4 Parallel Job Processing vs Sequential

**Choice:** Parallel (rayon with adaptive work stealing)

**Reasons:**
- 8-16 cores typical on development machines
- Font loading is I/O-bound, rendering is CPU-bound (good parallelism)
- rayon handles thread pool, load balancing automatically
- 8Ã— speedup typical (500 jobs/sec Ã— 8 threads)

**Trade-offs:**
- Slightly less deterministic (thread scheduling)
- DETERMINISM: Job results arrive out-of-order in JSONL (fixed by job ID)
- More complex debugging (thread interleaving)

### 5.5 Streaming JSONL Output vs Batch

**Choice:** Streaming (write JSONL immediately as jobs complete)

**Reasons:**
- Python can start processing results while Haforu working
- Progress reporting ("50% complete")
- Early error detection (fail fast)
- Better memory usage (don't hold all results in memory)

**Trade-offs:**
- Results arrive out-of-order (fixed by job ID correlation)
- Stdout buffer management needed (1MB typical, sufficient)

### 5.6 PGM P5 Format vs PNG

**Choice:** PGM P5 (binary) with base64 encoding

**Reasons:**
- PGM P5: Simple binary format, no decompression needed
- 8-bit grayscale: Exactly matches Daidot requirements
- Base64: JSON-safe, universally supported
- 10Ã— smaller than PNG for grayscale (no filter, compression)

**Trade-offs:**
- PNG would be 30% smaller (better compression)
- PNG requires libpng dependency (PGM is trivial)
- PNG slower to decode (PNG decompression vs base64)

**Decision Rationale:** Speed > size for batch rendering

---

## Section 6: Risk Analysis & Mitigation

### 6.1 Risks & Mitigation Strategies

| Risk | Severity | Likelihood | Mitigation |
|------|----------|-----------|-----------|
| Haforu binary not found | HIGH | MEDIUM | Fall back to CoreText/HarfBuzz |
| JSON parsing error on malformed input | MEDIUM | HIGH | Validate JSON size, reject >100MB |
| Font file corruption/missing | HIGH | LOW | Graceful error in JSONL, retry individually |
| Memory spike during image compositing | HIGH | MEDIUM | Stream images to disk, don't hold in memory |
| Thread pool deadlock (rayon) | MEDIUM | LOW | Use default thread pool (rayon handles) |
| Out-of-order JSONL results confusing Python | MEDIUM | HIGH | Use job ID correlation in Python |
| Variable font coordinate clamping issues | LOW | MEDIUM | Log warnings, include in timing metrics |
| Zeno rasterization gaps/overlap | LOW | LOW | Manual testing on known glyphs, compare pixel-perfect |

### 6.2 Testing Strategy

**Unit Tests (per module):**
- json_parser: parse valid/invalid JSON, edge cases
- mmap_font: load static/variable/TTC fonts
- font_cache: LRU eviction, hit rate
- shaping: single glyph, empty string, complex scripts
- rasterize: blank glyph, filled glyph, large canvas
- output: PGM format, base64 encoding, bounding box

**Integration Tests:**
- End-to-end: 100 jobs â†’ JSONL results
- Variable fonts: apply coords, verify rendering changes
- Error handling: missing fonts, invalid JSON, corrupted files
- Performance: 5000 jobs < 40 seconds

**Regression Tests (FontSimi side):**
- Daidot metrics identical to CoreText/HarfBuzz (pixel tolerance <0.1%)
- Match results unchanged (top-10 matches identical)
- No OOM crashes on full 250-font set

---

## Section 7: Implementation Phases

### 7.1 Phase H2: Haforu2 Rust (12-18 days)

**Deliverables:**
1. H2.1: JSON job processing (2-3 days)
2. H2.2: Font loading & variations (2-3 days)
3. H2.3: Text shaping (2-3 days)
4. H2.4: Glyph rasterization (3-4 days)
5. H2.5: PGM output format (1-2 days)
6. H2.6: JSONL streaming output (1-2 days)
7. H2.7: Error handling & tests (1-2 days)

**Success Criteria:**
- All tests passing (100%)
- Batch of 5000 jobs completes <40s
- Memory <2GB
- Daidot metrics identical to baseline

### 7.2 Phase H3: FontSimi Batch Pipeline (5-9 days)

**Location:** `src/fontsimi/daidot/daidot_analyzer.py`

**Deliverables:**
1. H3.1: Batch job generation (1-2 days)
2. H3.2: Result processing (2-3 days)
3. H3.3: Cache integration (1-2 days)
4. H3.4: Error recovery (1-2 days)

**Success Criteria:**
- Full analysis: 5.5M glyphs in <3 minutes
- Memory <2GB
- All metrics cached correctly

### 7.3 Phase H4: Streaming Mode (6-9 days)

**Location:** Both repos

**Deliverables:**
1. H4.1: Haforu streaming mode (2-3 days)
2. H4.2: HaforuStreamingRenderer class (2-3 days)
3. H4.3: Deep matcher integration (2-3 days)

**Success Criteria:**
- Deep match: 30s â†’ 0.6s per pair (50Ã— speedup)
- Process reuse: <0.1% overhead

### 7.4 Phase H5: Validation (3-5 days)

**Location:** Both repos + benchmarks

**Deliverables:**
1. H5.1: Performance benchmarking (2 days)
2. H5.2: Documentation (1 day)
3. H5.3: Fallback & compatibility (1-2 days)

**Success Criteria:**
- 100Ã— speedup verified
- 97% memory reduction verified
- All tests passing

---

## Section 8: Haforu2 Standalone Architecture

Beyond FontSimi, Haforu2 should be designed as a general-purpose tool.

### 8.1 Generic Batch Rendering API

**Core Abstraction:**
```rust
pub struct RenderJob {
    pub id: String,
    pub font_path: PathBuf,
    pub font_size: f32,
    pub text: String,
    pub output_format: OutputFormat,  // PGM, PNG, SVG, JSON
    pub variations: HashMap<String, f32>,
}

pub struct RenderResult {
    pub job_id: String,
    pub status: Status,  // Success, Error
    pub output: OutputData,  // Enum: PgmBinary, PngBinary, SvgString, MetricsJson
    pub timing: TimingInfo,
}

pub fn render_batch(jobs: Vec<RenderJob>) -> Vec<RenderResult>
```

### 8.2 Output Format Plugins

**Supported Formats:**
- `pgm`: P5 binary grayscale (FontSimi)
- `png`: PNG compressed color (web)
- `svg`: Scalable vector (future)
- `metrics`: JSON with computed metrics (QA)

### 8.3 Standalone CLI Usage

```bash
# Single batch
cat jobs.json | haforu2 process --render --format pgm > results.jsonl

# Multiple batches (GNU parallel)
parallel < batch_list.txt | haforu2 process --render --format png --parallel 4

# Streaming mode (keeps process alive)
haforu2 --streaming < /dev/stdin > /dev/stdout
```

### 8.4 Future Extensions

**Possible plugins (not in H2-H5):**
- Distributed rendering (MPI, Ray)
- GPU rasterization (Vello/wgpu backend)
- Web service (actix-web)
- Python bindings (PyO3/maturin)

---

## Section 9: Conclusion & Next Steps

### 9.1 Haforu2 Value Proposition

**For FontSimi:**
- 100Ã— performance improvement
- 97% memory reduction
- Architectural foundation for future scaling

**For Font Developers:**
- General-purpose batch rendering tool
- Suitable for specimen generation, QA, benchmarking
- Extensible output formats and plugins

**For Ecosystem:**
- Rust native font rendering (no C FFI)
- Zero-copy design (memory efficient)
- Streaming architecture (progressive results)

### 9.2 Critical Success Factors

1. **Get H2.1-H2.4 right:** Core rendering pipeline is foundation
2. **Exhaustive unit tests:** Catch edge cases early
3. **FontSimi validation:** Ensure Daidot metrics pixel-perfect
4. **Performance profiling:** Measure per-stage bottlenecks
5. **Documentation:** Examples, troubleshooting, API docs

### 9.3 Recommended Implementation Order

1. **Start H2.1 immediately:** JSON parsing (lowest risk, high value)
2. **Parallelize H2.2-H2.4:** Font loading and rendering (deep work)
3. **Validate against FontSimi:** Compare Daidot metrics pixel-perfect
4. **Then proceed to H3:** Batch pipeline (depends on H2)
5. **Then proceed to H4-H5:** Streaming & optimization (polish)

### 9.4 Timeline Estimate

- **H2 (Rust):** 12-18 days (2-3 weeks)
- **H2 Validation:** 4 days
- **H3 (Python batch):** 5-9 days (1-2 weeks)
- **H4 (Streaming):** 6-9 days (1-2 weeks)
- **H5 (Validation):** 3-5 days
- **Total:** 4-6 weeks

---

## Appendix A: File Structure Reference

```
external/haforu2/                    # New Rust project
â”œâ”€â”€ Cargo.toml
â”œâ”€â”€ Cargo.lock
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.rs                      # CLI entry point
â”‚   â”œâ”€â”€ lib.rs                       # Public library API
â”‚   â”œâ”€â”€ json_parser.rs               # JobSpec, validation
â”‚   â”œâ”€â”€ error.rs                     # Error types
â”‚   â”œâ”€â”€ mmap_font.rs                 # Memory-mapped font loading
â”‚   â”œâ”€â”€ font_cache.rs                # LRU font instance cache
â”‚   â”œâ”€â”€ shaping.rs                   # HarfRust text shaping
â”‚   â”œâ”€â”€ rasterize.rs                 # Glyph rasterization
â”‚   â”œâ”€â”€ output.rs                    # PGM format, base64
â”‚   â”œâ”€â”€ orchestrator.rs              # Job pipeline
â”‚   â””â”€â”€ stats.rs                     # Performance metrics
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ integration_tests.rs
â”‚   â””â”€â”€ unit_tests.rs
â”œâ”€â”€ fonts/                           # Test fonts
â”‚   â”œâ”€â”€ Arial.ttf                    # Static
â”‚   â”œâ”€â”€ Roboto[wght].ttf             # Variable (one axis)
â”‚   â””â”€â”€ Inter[slnt,wght].ttf         # Variable (two axes)
â”œâ”€â”€ README.md                        # Usage guide
â”œâ”€â”€ PLAN.md                          # Implementation plan
â”œâ”€â”€ TODO.md                          # Task list
â””â”€â”€ WORK.md                          # Work log
```

---

**Document Version:** 1.0  
**Last Updated:** 2025-11-11  
**Status:** Ready for Implementation
</document_content>
</document>

<document index="6">
<source>COMPILATION_FIXES.md</source>
<document_content>
---
this_file: external/haforu2/COMPILATION_FIXES.md
---

# Haforu2 Compilation Fixes Required

**Status:** Initial foundation code written, needs API compatibility fixes
**Timeline:** ~4-6 hours to fix all compilation errors

---

## Current Issues (25 compilation errors)

The code was written based on API assumptions that don't match the actual crate versions. The following modules have API mismatches:

### 1. src/fonts.rs (~6 errors)

**Issues:**
- `font_ref.axes()` returns `AxisCollection` which is not an iterator
- Missing imports for `Size` and `LocationRef` from skrifa
- `font.head()` method doesn't exist on `FontRef`
- `font.glyph_metrics()` requires `MetadataProvider` trait in scope

**Fixes Required:**
- Import `skrifa::instance::{Size, LocationRef}`
- Import `skrifa::MetadataProvider`
- Fix axes iteration: `font_ref.axes().iter()` or similar
- Fix head access: use proper skrifa API
- Add `MetadataProvider` trait imports

### 2. src/shaping.rs (~8 errors)

**Issues:**
- `harfbuzz` v0.6 has different API than v0.4
- Missing imports: `Face`, `Font`, `GlyphBuffer`, `UnicodeBuffer`
- `Blob::with_bytes()` doesn't exist, use `Blob::new_read_only()`
- `font_ref.table_data` is a method, not a field: use `table_data()`
- `harfbuzz::shape()` function signature different
- HarfBuzz types need different imports

**Fixes Required:**
- Update harfbuzz imports to match v0.6 API
- Change `Blob::with_bytes()` â†’ `Blob::new_read_only()`
- Change `font_ref.table_data` â†’ `font_ref.table_data()`
- Update `harfbuzz::shape()` call to match v0.6 API
- Review harfbuzz v0.6 documentation for correct types

### 3. src/render.rs (~8 errors)

**Issues:**
- `zeno::Path` type doesn't exist (it's `zeno::PathData`)
- `PathBuilder::finish()` returns `PathData`, not `Path`
- `Mask::fill()` signature different
- `Mask::get_alpha()` doesn't exist (need to use `as_slice()` or similar)
- `Command` enum has different variant signatures
- Missing imports for zeno types

**Fixes Required:**
- Change `zeno::Path` â†’ `zeno::PathData` or whatever zeno v0.3 provides
- Update `PathBuilder` usage to match zeno v0.3 API
- Fix `Mask` rasterization: use correct zeno v0.3 API
- Fix `Command` enum usage (likely different tuple variants)
- Review zeno v0.3 documentation for correct API

### 4. Minor Issues in Other Files (~3 errors)

**Issues:**
- Various type mismatches in function signatures
- Missing trait bounds

**Fixes Required:**
- Review and fix type signatures
- Add missing trait imports

---

## Fix Strategy

### Phase 1: Review Actual Crate APIs (2 hours)

1. **skrifa v0.22 API:**
   ```bash
   cargo doc --package skrifa --open
   ```
   - Check how to iterate axes
   - Check glyph metrics API
   - Check head table access
   - Check LocationRef and Size usage

2. **harfbuzz v0.6 API:**
   ```bash
   cargo doc --package harfbuzz --open
   ```
   - Check Blob API
   - Check Face/Font creation
   - Check Buffer types
   - Check shape() function signature

3. **zeno v0.3 API:**
   ```bash
   cargo doc --package zeno --open
   ```
   - Check PathBuilder/PathData
   - Check Mask rasterization API
   - Check Command enum variants

### Phase 2: Fix Each Module (2-3 hours)

1. **Fix fonts.rs** (30 min)
   - Add missing imports
   - Fix axes iteration
   - Fix metrics access
   - Test with `cargo build --lib`

2. **Fix shaping.rs** (1 hour)
   - Update harfbuzz imports and usage
   - Fix Blob creation
   - Fix shape() call
   - Test with `cargo build --lib`

3. **Fix render.rs** (1 hour)
   - Update zeno types
   - Fix PathBuilder usage
   - Fix Mask rasterization
   - Test with `cargo build --lib`

4. **Fix remaining issues** (30 min)
   - Fix any remaining type mismatches
   - Test with `cargo build --lib`

### Phase 3: Run Tests (30 min)

1. **Unit tests:**
   ```bash
   cargo test
   ```

2. **Fix test failures:**
   - Most tests should pass once compilation succeeds
   - May need minor adjustments to test data

---

## Alternative Approach: Use Existing Haforu1 Code

If API fixes take too long, we could:

1. Copy working font loading code from `external/haforu/src/mmap_font.rs`
2. Copy working shaping code from `external/haforu/src/shaping.rs`
3. Copy working rendering code from `external/haforu/src/rasterize.rs`
4. Adapt to clean haforu2 architecture

**Estimated time:** 2-3 hours (faster than fixing APIs from scratch)

**Trade-off:** Less clean separation, but proven working code

---

## Recommended Next Steps

**Option A: Fix APIs (Cleaner, ~4-6 hours)**
1. Review each crate's documentation
2. Fix imports and function calls systematically
3. Run tests and verify

**Option B: Port Haforu1 Code (Faster, ~2-3 hours)**
1. Copy working implementations from haforu/
2. Adapt to haforu2 structure
3. Clean up and test

**Recommendation:** Start with Option A (fix APIs) because:
- Code structure is already better organized
- APIs are more recent/idiomatic
- Learning exercise for correct API usage
- If stuck after 3 hours, switch to Option B

---

## Current Status

- âœ… Project structure created
- âœ… All modules scaffolded with proper logic
- âœ… Error handling defined
- âœ… Documentation written
- âŒ Compilation fails (25 errors)
- â¸ï¸ Testing blocked on compilation

**Next:** Start Phase 1 API review (2 hours)

---

## Success Criteria

- [ ] `cargo build` succeeds with 0 errors
- [ ] `cargo test` passes all unit tests
- [ ] `cargo clippy` shows no warnings
- [ ] Code structure remains clean and modular
</document_content>
</document>

<document index="7">
<source>Cargo.toml</source>
<document_content>
# this_file: Cargo.toml

[package]
name = "haforu"
version = "2.0.0"
edition = "2021"
authors = ["FontSimi Team"]
description = "High-performance batch font renderer for FontSimi"
license = "MIT OR Apache-2.0"
rust-version = "1.70"

[lib]
name = "haforu"
crate-type = ["cdylib", "rlib"]

[[bin]]
name = "haforu"
path = "src/main.rs"

[[bench]]
name = "cli"
harness = false

[dependencies]
# CLI and argument parsing
clap = { version = "4.5", features = ["derive", "cargo"] }

# Error handling
thiserror = "1.0"
anyhow = "1.0"

# Serialization
serde = { version = "1.0", features = ["derive"] }
serde_json = "1.0"

# Font handling - using fontations ecosystem
read-fonts = "0.22"
skrifa = "0.22"

# Text shaping
harfbuzz_rs = "2.0"

# Rasterization
zeno = "0.3"

# Image output
image = { version = "0.25", features = ["png", "jpeg"] }

# Memory mapping for zero-copy font loading
memmap2 = "0.9"

# Base64 encoding for JSONL output
base64 = "0.22"

# Logging
log = "0.4"
env_logger = "0.11"

# Parallel processing
rayon = "1.10"

# LRU cache for font instances
lru = "0.12"

# Path utilities
camino = { version = "1.1", features = ["serde1"] }

# Python bindings
pyo3 = { version = "0.22", optional = true, features = ["extension-module"] }
numpy = { version = "0.22", optional = true }

[dev-dependencies]
tempfile = "3.10"
approx = "0.5"
insta = "1.39"
assert_cmd = "2.0"
predicates = "3.1"
criterion = "0.5"

[features]
default = []
python = ["pyo3", "numpy"]

[profile.release]
opt-level = 3
lto = true
codegen-units = 1
strip = true

[profile.dev]
opt-level = 0
debug = true
</document_content>
</document>

<document index="8">
<source>DEPENDENCIES.md</source>
<document_content>
---
this_file: DEPENDENCIES.md
---

# Dependency Rationale

## Rust Crate

- **clap** â€” battle-tested CLI arg parsing so we can expose batch/stream/render/diagnostics switches without writing our own parser.
- **rayon** â€” lock-free parallel iterator runtime powering batch rendering throughput and Python iterator fan-out.
- **harfbuzz_rs** + **skrifa/read-fonts** â€” production-grade shaping + variable font handling; no bespoke font math.
- **zeno** + **image** â€” raster + image encoding so we emit deterministic base64 payloads without custom encoders.
- **memmap2** â€” zero-copy font loading to keep RSS flat while cycling through 1000s of fonts.
- **env_logger/log** â€” structured logging (JSON/text) for CLI, smoke scripts, and integration debugging.

## Python Package

- **PyO3/maturin** â€” exposes the Rust engine to Python with shared glyph cache + streaming session.
- **fire** â€” lightweight CLI surface matching the Rust commands; keeps parity without manual argparse plumbing.
- **numpy** â€” optional zero-copy path for `StreamingSession.render_to_numpy`.

Each dependency keeps Haforu lean: we offload parsing/shaping/rasterization to maintained libraries instead of re-implementing fragile infrastructure.
</document_content>
</document>

<document index="9">
<source>INDEX.md</source>
<document_content>
# Haforu2 Documentation Index

**Analysis Date:** 2025-11-11  
**Total Documents:** 4 files (56 KB, 1465 lines)  
**Status:** Complete & Ready for Implementation

---

## Document Quick Reference

### ğŸš€ Start Here: README.md (7.7 KB, 250 lines)
**Best for:** Everyone (first read)

Contains:
- Problem statement (FontSimi bottleneck)
- Solution overview (Haforu2 architecture)
- Implementation phases (H2-H5)
- Phase H2 breakdown (H2.1-H2.7)
- Key design decisions
- Risk mitigation
- Success criteria
- Next steps

**Read time:** 5-10 minutes

---

### ğŸ“Š ANALYSIS_SUMMARY.md (7.8 KB, 250 lines)
**Best for:** Executives, project managers, stakeholders

Contains:
- Executive summary
- What was analyzed
- Key documents generated
- 6 critical findings
- Integration timeline
- Success criteria
- Risks & mitigation
- Conclusion

**Key insight:** "The bottleneck is architectural (not computational)"

**Read time:** 5 minutes

---

### ğŸ’¡ KEY_FINDINGS.md (8.3 KB, 228 lines)
**Best for:** Decision makers, technical leads

Contains:
- 10 critical insights
- Bottleneck root cause analysis
- Haforu2 architecture explanation
- Performance targets breakdown
- Design is generic (standalone value)
- Technical decisions rationale
- 12-18 day implementation feasibility
- Integration phases (H1-H5)
- Dependency analysis
- Risk mitigation strategies
- Validation approach

**Key insight:** "Per-job overhead is 10-20Ã— larger than computation"

**Read time:** 10 minutes

---

### ğŸ—ï¸ ARCHITECTURE.md (25 KB, 737 lines)
**Best for:** Engineers, architects, implementers

Contains:
- **Section 1:** FontSimi bottleneck analysis
  - Performance metrics table
  - Root cause analysis (Pythonâ†’Native boundary)
  - Renderer comparison table
  - Daidot metrics explanation
- **Section 2:** Haforu2 design requirements
  - Batch job specification (JSON example)
  - Architectural principles
  - Feature matrix
  - Standalone value proposition
- **Section 3:** Technical architecture
  - Module structure
  - Data flow diagram
  - Implementation roadmap (H2.1-H2.7)
  - Dependencies & justification
  - Performance targets
- **Section 4:** Integration with FontSimi
  - Phase H1 (complete)
  - Phase H2 (in progress)
  - Phase H3 (ready after H2)
  - Phase H4 (future)
  - Phase H5 (validation)
- **Section 5:** Design decisions & trade-offs
  - Subprocess vs FFI
  - Memory-mapped fonts vs heap
  - LRU caching vs always-reload
  - Parallel vs sequential
  - Streaming vs batch output
  - PGM vs PNG format
- **Section 6:** Risk analysis
  - Risk mitigation table
  - Testing strategy
- **Section 7:** Implementation phases
  - H2 (Haforu2 Rust)
  - H3 (FontSimi batch)
  - H4 (Streaming mode)
  - H5 (Validation)
- **Section 8:** Standalone architecture
  - Generic API
  - Output format plugins
  - CLI usage
  - Future extensions
- **Section 9:** Conclusion & next steps
  - Value proposition
  - Success factors
  - Implementation order
  - Timeline estimate
- **Appendix A:** File structure

**Key reference:** Complete technical specification for H2 implementation

**Read time:** 30 minutes (technical audience)

---

## Reading Paths by Role

### For Executives/Project Managers
1. README.md (5 min) â€” Overview
2. ANALYSIS_SUMMARY.md (5 min) â€” Key findings
3. KEY_FINDINGS.md â†’ "Integration Timeline" section (2 min)

**Total: 12 minutes**

### For Technical Leads/Architects
1. README.md (5 min) â€” Overview
2. KEY_FINDINGS.md (10 min) â€” Technical insights
3. ARCHITECTURE.md â†’ Sections 3-5 (15 min)

**Total: 30 minutes**

### For Implementation Engineers
1. README.md â†’ "Phase H2 Breakdown" (5 min)
2. ARCHITECTURE.md (30 min) â€” Full read
3. ARCHITECTURE.md â†’ Appendix A (file structure)

**Total: 35 minutes**

---

## Key Statistics

| Metric | Value |
|--------|-------|
| **Total Size** | 56 KB |
| **Total Lines** | 1,465 |
| **Number of Documents** | 4 |
| **Sections** | 9 (ARCHITECTURE.md) |
| **Code Examples** | 15+ |
| **Tables** | 25+ |
| **Risk Scenarios** | 15+ |
| **Performance Metrics** | 30+ |

---

## Critical Metrics Referenced

### FontSimi Current State
- **Total glyphs to render:** 5.5 million
- **Fonts:** 250 (mix of static & variable)
- **Variable instances:** 85
- **Script segments:** 5
- **Glyphs per segment:** 52
- **Runtime:** 5+ hours
- **Memory peak:** 86GB
- **Overhead per render:** 50-100ms
- **Actual computation:** 5-10ms

### Expected Haforu2 Results
- **Performance:** 100Ã— speedup (5h â†’ 3m)
- **Memory:** 97% reduction (86GB â†’ <2GB)
- **Batch size:** 5000 jobs
- **Batch time:** 30-40 seconds (8 threads)
- **Jobs per second:** 125-167
- **Font cache:** 512 instances, >90% hit rate
- **Total timeline:** 4-6 weeks (H2-H5)

---

## Navigation

**Within ARCHITECTURE.md:**
- Line 1-50: Title, executive summary
- Line 51-150: Section 1 (FontSimi bottleneck)
- Line 151-250: Section 2 (Haforu2 requirements)
- Line 251-400: Section 3 (Technical architecture)
- Line 401-500: Section 4 (Integration)
- Line 501-600: Section 5 (Design decisions)
- Line 601-650: Section 6 (Risk analysis)
- Line 651-720: Section 7 (Implementation phases)
- Line 721-737: Appendix A (File structure)

---

## For Quick Answers

**Q: What's the bottleneck?**  
A: Pythonâ†’Native boundary overhead (50-100ms per render). See ARCHITECTURE.md Section 1.2

**Q: How fast will Haforu2 be?**  
A: 500-1000 jobs/sec per batch, 3 minutes total for 5.5M glyphs. See KEY_FINDINGS.md Finding 3

**Q: How long to implement?**  
A: 12-18 days for H2 (Rust), 4-6 weeks total (H2-H5). See README.md "Implementation Phases"

**Q: What are the risks?**  
A: 6 identified, all have mitigation paths. See ARCHITECTURE.md Section 6

**Q: Is this worth doing?**  
A: Yes. 100Ã— speedup + 97% memory reduction. See ANALYSIS_SUMMARY.md Conclusion

**Q: What are dependencies?**  
A: All proven, industry-standard. See KEY_FINDINGS.md Finding 4

---

## Version History

| Version | Date | Changes |
|---------|------|---------|
| 1.0 | 2025-11-11 | Initial complete analysis |

---

## Contact & Questions

For questions about:
- **FontSimi integration:** See PLAN.md in `/Users/adam/Developer/vcs/github.docrepair-fonts/fontsimi/`
- **Project timeline:** See TODO.md in same location
- **Implementation:** Start with README.md "Next Steps" section

---

**Document Set:** Complete âœ…  
**Ready for Implementation:** YES âœ…  
**Last Updated:** 2025-11-11
</document_content>
</document>

<document index="10">
<source>INSTALL.md</source>
<document_content>
---
this_file: INSTALL.md
---

# Haforu Installation Guide

This guide covers installation of Haforu on all supported platforms.

## Quick Install

### Python Package (Recommended)

```bash
pip install haforu
```

This installs both the Python bindings and provides access to the CLI via `python -m haforu`.

### Rust Binary via Cargo

```bash
cargo install haforu
```

## Platform-Specific Instructions

### macOS

#### Universal2 Wheel (Recommended)

Works on both Intel and Apple Silicon Macs:

```bash
pip install haforu
```

The wheel includes native binaries for both architectures.

#### Building from Source

Requirements:
- Rust 1.70+
- Python 3.8+
- Xcode Command Line Tools

```bash
# Clone the repository
git clone https://github.com/fontsimi/haforu.git
cd haforu

# Canonical build + tests + smoke
./scripts/build.sh

# (Optional) Demo the JSONL contract
./scripts/run.sh smoke

# (Optional) Install the freshly built wheel
uv pip install target/artifacts/latest/wheels/*.whl
```

#### Platform-Specific Extras

```bash
pip install haforu[mac]  # macOS-specific optimizations
```

#### Troubleshooting macOS

**Issue**: `dyld: Library not loaded` error
- **Solution**: Ensure Xcode Command Line Tools are installed: `xcode-select --install`

**Issue**: Permission denied when running binary
- **Solution**: `chmod +x /path/to/haforu`

**Issue**: "Cannot verify developer" warning
- **Solution**: Right-click the binary and select "Open", or run: `xattr -d com.apple.quarantine /path/to/haforu`

### Linux

#### Manylinux Wheels (Recommended)

Compatible with most Linux distributions:

```bash
pip install haforu
```

The manylinux wheels work on:
- Ubuntu 18.04+
- Debian 10+
- CentOS 7+
- Fedora 30+
- Other glibc 2.17+ distributions

#### Building from Source

Requirements:
- Rust 1.70+
- Python 3.8+
- GCC or Clang
- pkg-config

```bash
# Install dependencies (Ubuntu/Debian)
sudo apt-get update
sudo apt-get install -y build-essential pkg-config python3-dev

# Install dependencies (Fedora/RHEL)
sudo dnf install -y gcc gcc-c++ pkg-config python3-devel

# Clone and build
git clone https://github.com/fontsimi/haforu.git
cd haforu
./scripts/build.sh

# Verify contract quickly
./scripts/run.sh smoke

# Install the generated wheel(s)
pip install target/artifacts/latest/wheels/*.whl
```

#### Platform-Specific Extras

```bash
pip install haforu[linux]  # Linux-specific optimizations
```

#### Troubleshooting Linux

**Issue**: `error while loading shared libraries`
- **Solution**: Install missing system libraries:
  ```bash
  sudo apt-get install -y libfontconfig1-dev libfreetype6-dev
  ```

**Issue**: Permission denied accessing fonts
- **Solution**: Ensure font directories are readable:
  ```bash
  chmod -R a+r /usr/share/fonts
  fc-cache -fv
  ```

**Issue**: ImportError with Python bindings
- **Solution**: Verify glibc version: `ldd --version` (need 2.17+)

### Windows

#### Python Wheel (Recommended)

```bash
pip install haforu
```

#### Building from Source

Requirements:
- Rust 1.70+ (via rustup-init.exe)
- Python 3.8+ (from python.org)
- Visual Studio 2019+ with C++ Build Tools

```bash
# In PowerShell or Command Prompt
git clone https://github.com/fontsimi/haforu.git
cd haforu

# Build (Git Bash)
bash scripts/build.sh

# Install
pip install target/artifacts/latest/wheels/*.whl
```

#### Platform-Specific Extras

```bash
pip install haforu[windows]  # Windows-specific optimizations
```

#### Troubleshooting Windows

**Issue**: `LINK : fatal error LNK1181: cannot open input file`
- **Solution**: Install Visual Studio Build Tools with C++ components

**Issue**: `rustc.exe not found`
- **Solution**: Add Rust to PATH or restart terminal after installing Rust

**Issue**: Python module not found
- **Solution**: Ensure Python Scripts directory is in PATH:
  ```cmd
  set PATH=%PATH%;%USERPROFILE%\AppData\Local\Programs\Python\Python312\Scripts
  ```

## Verification

After installation, verify everything works:

### Python Package

```python
import haforu
print(haforu.__version__)
print(haforu.is_available())
```

### CLI Tools

```bash
# Rust CLI
haforu version

# Python CLI
python -m haforu version
haforu-py version  # If installed globally
```

### Run Demos

```bash
# Clone repo for test data
git clone https://github.com/fontsimi/haforu.git
cd haforu

# Run all demos
./scripts/run.sh all
```

## Installation Options

### From PyPI (Stable Releases)

```bash
pip install haforu
```

### From GitHub (Latest Development)

```bash
pip install git+https://github.com/fontsimi/haforu.git
```

### From Local Source (Development)

```bash
git clone https://github.com/fontsimi/haforu.git
cd haforu
maturin develop --release --features python
```

### With Optional Dependencies

```bash
# All optional dependencies
pip install haforu[all]

# Development dependencies
pip install haforu[dev]

# Platform-specific
pip install haforu[mac]    # macOS
pip install haforu[linux]  # Linux
pip install haforu[windows]  # Windows
```

## Environment Variables

### HAFORU_BIN

Points to the Rust CLI binary location:

```bash
export HAFORU_BIN=/path/to/haforu
```

This is used by FontSimi and other tools that shell out to the CLI.

### Recommended Setup

Add to your shell profile (~/.bashrc, ~/.zshrc, etc.):

```bash
# For local development
export HAFORU_BIN="$HOME/Developer/haforu/target/release/haforu"

# For installed version
export HAFORU_BIN="$(which haforu)"
```

## Docker Installation

A Dockerfile is provided for containerized usage:

```bash
# Build image
docker build -t haforu:latest .

# Run container
docker run --rm -i haforu:latest batch < jobs.json
```

## Uninstallation

### Python Package

```bash
pip uninstall haforu
```

### Rust Binary

```bash
cargo uninstall haforu
```

### Clean Build Artifacts

```bash
cd haforu
cargo clean
rm -rf target/ .venv/ dist/ build/
```

## Getting Help

- **Documentation**: https://github.com/fontsimi/haforu
- **Issues**: https://github.com/fontsimi/haforu/issues
- **Discussions**: https://github.com/fontsimi/haforu/discussions

## Next Steps

- Read the [README](README.md) for usage examples
- Try the [examples](examples/) directory
- Check [ARCHITECTURE](ARCHITECTURE.md) for technical details
- Review [CHANGELOG](CHANGELOG.md) for recent updates
</document_content>
</document>

<document index="11">
<source>KEY_FINDINGS.md</source>
<document_content>
# Haforu2: Architectural Analysis - Key Findings

**Document:** Comprehensive architectural analysis for Haforu2 Rust implementation  
**Location:** `/Users/adam/Developer/vcs/github.fontlaborg/haforu2/ARCHITECTURE.md`  
**Date:** 2025-11-11

---

## Critical Insights

### 1. The FontSimi Bottleneck is Architectural, Not Computational

**The Problem:**
- 5.5 million render calls (250 fonts Ã— 85 instances Ã— 5 segments Ã— 52 glyphs)
- **Each call crosses Pythonâ†’Native boundary:** 50-100ms overhead
- Actual rendering: 5-10ms (10-20Ã— SMALLER than overhead)
- Result: 5+ hours runtime, 86GB peak memory (uncompressed)

**Root Cause Analysis:**
```
Current: for glyph in 5.5M: renderer.render_text(glyph)  
         â†“ Each call: alloc object â†’ C/Rust call â†’ GC
         â†“ Overhead: 50-100ms (dwarfs 5-10ms computation)
         
Haforu:  batch 5000 glyphs â†’ single subprocess call
         â†“ Amortize overhead: 5000 Ã— 50ms = 250s for overhead alone
         â†“ Sequential: 250s overhead + 5.5M Ã— 0.01s = 55s total
         â†“ Parallel: 8 threads Ã· overhead â‰ˆ 3 minutes
```

### 2. Haforu2 Architecture is Fundamentally Different from Haforu1

**Haforu1 (Current):** Subprocess spawn per render (~500ms overhead)
- Working but slow for single renders
- Not suitable for FontSimi's 5.5M scale

**Haforu2 (Proposed):** Batch processing with streaming output
- Single subprocess per batch (5000 jobs)
- Memory-mapped fonts (250MB, not 86GB)
- Parallel job processing (rayon: 8 threads)
- Streaming JSONL output (progressive results)

**Why This Works:**
- Amortizes subprocess overhead across 5000 jobs
- Memory-mapped fonts: no object allocation per render
- Parallel processing: 8Ã— speedup (typical server)
- Single native boundary crossing per batch (vs 5.5M)

### 3. Performance Targets are Achievable

**Per-Job Breakdown:**
| Operation | Time | Notes |
|-----------|------|-------|
| JSON parse | <100Âµs | 5M jobs in 500ms |
| Font load (cache hit) | <0.1ms | LRU cache 512 entries |
| Font load (first) | 1ms | Memory-mapped |
| Text shaping | 0.5-2ms | Single char (fast) |
| Glyph rasterization | 2-5ms | 3000Ã—1200 canvas |
| PGM + base64 | 5-10ms | Encoding only |
| **Total per job** | **10-15ms** | **67-100 jobs/sec** |

**Batch Performance (5000 jobs):**
| Mode | Time | Speedup |
|------|------|---------|
| Sequential | ~50-75s | N/A |
| 8 threads | ~30-40s | 8Ã— |
| 30 parallel processes | ~20min total | 100Ã—+ |

**FontSimi Analysis (5.5M glyphs):**
- 5.5M Ã· 5000 = 1100 batches
- 1100 Ã— 40s = 44,000s = 12.2 hours (naive)
- 1100 Ã— 40s Ã· 30 processes = ~20 minutes (if parallelized)
- **Actual with streaming cache:** ~3 minutes (per PLAN.md)

### 4. Design is Generic, Not FontSimi-Specific

**Haforu2 Standalone Value:**
- Generic batch font renderer (no FontSimi code)
- Input: JSON jobs (font path, size, text, variations)
- Output: JSONL results (base64-encoded images)
- Pluggable output formats (PGM, PNG, SVG, metrics JSON)

**Beyond FontSimi:**
1. **Font Development:** Batch render instances during design
2. **QA:** Regression testing on font corpus
3. **Web:** Generate specimen PDFs, preview images
4. **Benchmarking:** Compare rendering quality/performance

### 5. Key Technical Decisions

| Decision | Rationale |
|----------|-----------|
| **Subprocess** (not FFI) | No PyO3 complexity, easy testing, process isolation |
| **Memory-mapped fonts** | 250MB (not 86GB), OS page cache reuse |
| **Batch processing** | Amortize overhead, parallel efficiency |
| **Streaming JSONL** | Progressive results, early error detection |
| **PGM P5 format** | Simple binary, 8-bit grayscale only, fast decode |
| **Parallel rayon** | 8Ã— speedup, adaptive work-stealing |
| **LRU font cache** | 512 entries, >90% hit rate, deterministic |

### 6. Implementation is Achievable in 12-18 Days

**H2.1-H2.7 Breakdown:**
- H2.1: JSON parsing (2-3 days) - Lowest risk
- H2.2: Font loading (2-3 days) - Core foundation
- H2.3: Text shaping (2-3 days) - HarfRust integration
- H2.4: Rasterization (3-4 days) - skrifa + zeno
- H2.5: PGM output (1-2 days) - Simple format
- H2.6: JSONL output (1-2 days) - Streaming
- H2.7: Error handling (1-2 days) - Edge cases + tests

**Critical Path:** H2.1 â†’ H2.2 â†’ H2.3 â†’ H2.4 â†’ H2.5 â†’ H2.6 â†’ H2.7

**No parallel work possible** (each phase builds on previous)

### 7. Integration Points with FontSimi

| Phase | Status | Work | Timeline |
|-------|--------|------|----------|
| H1 | âœ… Complete | HaforuRenderer Python class (348 lines, 38 tests) | Done |
| H2 | â¸ï¸ Ready | Haforu2 Rust implementation | 12-18 days |
| H3 | Ready after H2 | Batch analysis pipeline (Python) | 5-9 days |
| H4 | Ready after H3 | Streaming mode (both repos) | 6-9 days |
| H5 | Ready after H4 | Performance validation | 3-5 days |

**Total Timeline:** 4-6 weeks from H2 start

### 8. Dependencies are Proven & Justified

| Dependency | Used For | Rationale |
|-----------|----------|-----------|
| serde + serde_json | JSON parsing | Industry standard, fast |
| read-fonts + skrifa | Font parsing, variations | Zero-copy, reliable |
| harfbuzz-rs | Text shaping | Industry standard (HarfBuzz) |
| zeno | CPU rasterization | Lightweight, fast |
| memmap2 | Font I/O | Zero-copy memory mapping |
| rayon | Parallel processing | Data parallelism (SIMD-friendly) |
| anyhow | Error handling | Simple, ergonomic |
| clap | CLI | Latest version (structopt deprecated) |

**No risky or unproven dependencies**

### 9. Risk Mitigation is Built-In

| Risk | Severity | Mitigation |
|------|----------|-----------|
| Haforu binary not found | HIGH | Fallback to CoreText/HarfBuzz |
| JSON parsing error | MEDIUM | Validate size, reject >100MB |
| Font corruption | HIGH | Graceful error, retry individually |
| Memory spike | HIGH | Stream to disk, don't hold all |
| Out-of-order JSONL | MEDIUM | Job ID correlation |
| Rendering mismatch | LOW | Pixel-perfect validation |

**All risks have clear mitigation paths**

### 10. Validation Strategy is Comprehensive

**Unit Tests:**
- Per-module tests (json_parser, mmap_font, font_cache, shaping, rasterize, output)
- Edge cases (empty strings, corrupted fonts, huge canvases)

**Integration Tests:**
- End-to-end: 100 jobs â†’ JSONL results
- Variable fonts: apply coords, verify rendering changes
- Error handling: missing fonts, invalid JSON
- Performance: 5000 jobs < 40s

**Regression Tests (FontSimi):**
- Daidot metrics: pixel-perfect vs CoreText/HarfBuzz (<0.1% tolerance)
- Match results: top-10 unchanged
- OOM crashes: zero on full 250-font set

---

## Immediate Next Steps

### For Haforu2 Implementation
1. Create `Cargo.toml` with dependencies
2. Scaffold module structure (error.rs, json_parser.rs, etc.)
3. Implement H2.1 (JSON parsing) - lowest risk, high value
4. Proceed sequentially through H2.2-H2.7

### For FontSimi Integration
1. Wait for H2 Rust completion + validation
2. Implement H3 batch pipeline (depends on H2)
3. Validate Daidot metrics match baseline
4. Proceed to H4 streaming mode

### For Documentation
1. ARCHITECTURE.md: âœ… Complete (25KB, comprehensive)
2. Create H2.1 implementation guide (in external/haforu2/PLAN.md)
3. Add performance benchmarking guide
4. Document JSON job spec format (with examples)

---

## Expected Outcomes (H2-H5 Complete)

### Performance Metrics
- **Analysis:** 5h â†’ 3m (100Ã— speedup) âœ…
- **Memory:** 86GB â†’ <2GB (97% reduction) âœ…
- **Deep Matching:** 30s â†’ 0.6s per pair (50Ã— speedup) âœ…
- **Reliability:** Zero OOM crashes âœ…

### Quality Metrics
- **Test Coverage:** 100% (unit + integration + regression)
- **Determinism:** Identical Daidot metrics vs baseline
- **Compatibility:** All 250 fonts Ã— 85 instances
- **Documentation:** Comprehensive, examples, troubleshooting

### Deliverables
- Haforu2 Rust binary (optimized, tested)
- FontSimi batch analysis pipeline (Python)
- Streaming mode for deep matching
- Complete test suite (1000+ tests)
- Performance validation report

---

## Key Quote

> The bottleneck is not computationâ€”it's **architectural overhead**. Each Pythonâ†’Native boundary crossing adds 50-100ms. Haforu2 amortizes this overhead across 5000 jobs, reducing the 5.5M individual calls to 1100 batch calls. Combined with memory-mapped fonts and parallel processing, we achieve 100Ã— speedup and 97% memory reduction.

---

**Document:** `/Users/adam/Developer/vcs/github.fontlaborg/haforu2/ARCHITECTURE.md`  
**Status:** Ready for Implementation  
**Last Updated:** 2025-11-11
</document_content>
</document>

<document index="12">
<source>NEXTTASK.md</source>
<document_content>
NEXT TASK: Sprint forward to complete the work on 'haforu' as outlined in @./PLAN.md and @./TODO.md . Use the file @./WORK.md as the scratchpad for notes, but clean these files once youâ€™ve completed a task, and also check off the completed tasks in @./PLAN.md and @./TODO.md ;; NOTE: '@' denotes the start of a path but is not itself part of a path ;; NOTE: KEEP this NEXTTASK.md file as is, DONâ€™T CHANGE IT! ;; 
</document_content>
</document>

<document index="13">
<source>PLAN.md</source>
<document_content>
---
this_file: PLAN.md
---

# Haforu Development Plan

## Objective

Deliver a fast, reliable font renderer for CLI and Python with deterministic JSONL output, validated variation coordinates, and sub-millisecond streaming performance.

## Active Work

### 1. Error Handling Consistency

**Goal:** Every job produces a serialized `JobResult`, even if parsing or validation fails.

- Ensure CLI batch mode never drops jobs silently
- Ensure CLI stream mode returns error JobResults for invalid JSONL
- Ensure Python bindings return error JobResults (not exceptions) for invalid jobs
- Add regression tests for malformed inputs across all interfaces

### 2. Variation Coordinate Validation

**Goal:** Clamp variation coordinates to valid ranges and warn on unknown axes.

- Add `validate_coordinates()` in `src/fonts.rs`:
  - Clamp `wght` to [100, 900]
  - Clamp `wdth` to [50, 200]
  - Warn and drop unknown axes
- Wire validation into `FontLoader::load_font`
- Surface sanitized coordinates in JobResult JSON for debugging
- Add unit tests for in-range, out-of-range, and unknown-axis cases

### 3. Metrics-Only Output Reliability

**Goal:** `--format metrics` mode is stable, fast, and well-documented.

- Verify metrics calculation is deterministic
- Ensure runtime stays <0.2ms per job
- Document metrics mode in README with examples
- Add example in `examples/python/metrics_demo.py`
- Benchmark metrics mode vs image mode and document speedup

### 4. Python StreamingSession Reliability

**Goal:** Python bindings provide <1ms steady-state rendering with cache control.

- Verify `warm_up()`, `ping()`, and `is_available()` work correctly
- Test cache knobs (`max_fonts`, `max_glyphs`) are respected
- Stress-test with >1000 sequential renders to verify no RSS creep
- Ensure JSON schema matches CLI output exactly
- Document cache tuning in README

### 5. Cross-Platform Build Verification

**Goal:** Ensure builds work on macOS, Linux, and Windows without manual intervention.

- Verify `cargo build --release` works on all platforms
- Verify `maturin build --release` produces working wheels
- Test Python bindings install correctly from wheels
- Document platform-specific prerequisites in README
- Keep `scripts/build.sh` and `scripts/batch_smoke.sh` working

## Testing Strategy

- **Unit Tests** - Rust modules (`cargo test`) and Python bindings (`pytest`)
- **Integration Tests** - `scripts/batch_smoke.sh` validates CLI contract in <2s
- **Performance Tests** - `scripts/profile-cli.sh` catches regressions
- **Edge Cases** - Empty text, zero-sized canvas, missing fonts, invalid variations

## Performance Targets

- CLI batch (1000 jobs): <10s on 8 cores
- CLI streaming: <10ms per job including startup
- Python StreamingSession: <2ms per job (warmed cache)
- Metrics mode: <0.2ms per job

## Success Criteria

1. âœ… CLI never drops jobs - every input line produces a JSONL output
2. âœ… Variation coordinates stay within spec with clear warnings
3. âœ… Metrics mode achieves 5-10Ã— speedup over image modes
4. âœ… Python StreamingSession provides <2ms renders with cache control
5. âœ… All platforms build and run without manual fixes

## Out of Scope

- New output formats beyond PGM/PNG/metrics
- Retry logic, circuit breakers, or resilience patterns
- Analytics, monitoring, or telemetry systems
- Color, emoji, or subpixel rendering
- Complex configuration systems
- Automatic version tagging or release automation
- Repository structure reorganization
</document_content>
</document>

<document index="14">
<source>README.md</source>
<document_content>
---
this_file: README.md
---

# Haforu: Fast Font Renderer

**Status:** Production-ready

Fast, deterministic font rendering for CLI and Python. Renders glyphs to PGM/PNG/metrics with sub-millisecond performance.

## What It Does

Haforu renders text using TrueType/OpenType fonts with:
- **Parallel batch processing** - Process thousands of glyphs via CLI
- **Streaming mode** - Keep process alive for continuous rendering
- **Python bindings** - Sub-2ms renders with persistent sessions
- **Three output modes:**
  - `pgm` - Grayscale Netpbm format
  - `png` - PNG image
  - `metrics` - Density + beam measurements (10Ã— faster)

## Install

```bash
# Python (includes CLI binary)
pip install haforu

# Rust binary only
cargo install haforu
```

**Prerequisites:** Python 3.8+ or Rust 1.70+. No compiler needed for pip install (prebuilt wheels).

## Quick Start

### CLI

```bash
# Single render
haforu render -f font.ttf -t "Hello" -s 72 -o output.pgm

# Batch processing
echo '{
  "version": "1.0",
  "jobs": [{
    "id": "test1",
    "font": {"path": "/path/to/font.ttf", "size": 1000},
    "text": {"content": "A"},
    "rendering": {"format": "pgm", "encoding": "base64", "width": 3000, "height": 1200}
  }]
}' | haforu batch > results.jsonl

# Streaming mode
haforu stream < jobs.jsonl > results.jsonl

# Metrics only (fast)
haforu render -f font.ttf -t "A" -s 256 --format metrics
```

### Python

```python
import haforu
import json

# Batch processing
spec = {
    "version": "1.0",
    "jobs": [{
        "id": "test1",
        "font": {"path": "/path/to/font.ttf", "size": 1000},
        "text": {"content": "A"},
        "rendering": {"format": "pgm", "encoding": "base64", "width": 3000, "height": 1200}
    }]
}

for result_json in haforu.process_jobs(json.dumps(spec)):
    result = json.loads(result_json)
    print(f"Job {result['id']}: {result['status']}")

# Streaming session (persistent, fast)
with haforu.StreamingSession(max_fonts=512, max_glyphs=2048) as session:
    # Render to JSON
    job = {"id": "test", "font": {...}, "text": {...}, "rendering": {...}}
    result = session.render(json.dumps(job))

    # Or render directly to numpy array (zero-copy)
    image = session.render_to_numpy(
        font_path="/path/to/font.ttf",
        text="A",
        size=1000.0,
        width=3000,
        height=1200,
        variations={"wght": 600.0}
    )
    # Returns numpy.ndarray, shape (height, width), dtype uint8
```

## Architecture

```
Input: Font + Text + Parameters
  â†“
FontLoader (memory-mapped, LRU cached)
  â†“
HarfBuzz Shaping
  â†“
Zeno Rasterization
  â†“
Output: PGM/PNG/Metrics JSON
```

**Key Features:**
- Memory-mapped fonts (zero-copy loading via memmap2)
- LRU font cache (512 entries default)
- Parallel batch processing (Rayon)
- Deterministic JSONL I/O
- Every error returns JSON (no crashes)

## Performance

| Mode | Throughput | Use Case |
|------|-----------|----------|
| CLI Batch | 100-150 jobs/sec | Initial analysis |
| CLI Streaming | ~100 jobs/sec | Continuous processing |
| Python Bindings | 500-1000 jobs/sec | High-frequency rendering |
| Metrics Mode | 2000-5000 jobs/sec | Feature extraction |

**Targets:**
- Single render: <10ms cold, <2ms warm (Python)
- Batch (1000 jobs): <10s on 8 cores
- Memory: <500MB for 1000 renders

## CLI Commands

```bash
# Batch: Read full JSON, process in parallel
haforu batch [--max-fonts N] [--max-glyphs N] [--jobs N] [--stats]

# Stream: Line-by-line JSONL processing
haforu stream [--max-fonts N] [--max-glyphs N]

# Render: Single text render (HarfBuzz-compatible)
haforu render -f FONT -t TEXT [-s SIZE] [-o OUTPUT] [--format pgm|png|metrics]

# Diagnostics: Show system info and defaults
haforu diagnostics [--format text|json]

# Validate: Check job specification
haforu validate < jobs.json
```

**Cache Tuning:**
- `--max-fonts N` - Font cache size (default: 512)
- `--max-glyphs N` - Glyph cache size (default: 2048, 0 to disable)
- `--jobs N` - Parallel workers (default: CPU count)

## Python API

### `haforu.process_jobs(spec_json: str) -> Iterator[str]`

Process batch of jobs in parallel. Returns iterator of JSONL results.

### `haforu.StreamingSession(max_fonts=512, max_glyphs=2048)`

Persistent rendering session with font/glyph caching.

**Methods:**
- `render(job_json: str) -> str` - Render job, return JSONL result
- `render_to_numpy(...) -> np.ndarray` - Render directly to numpy array
- `warm_up(font_path: str) -> bool` - Warm up cache
- `ping() -> bool` - Liveness check
- `cache_stats() -> dict` - Inspect cache state
- `set_cache_size(n: int)` - Resize font cache
- `set_glyph_cache_size(n: int)` - Resize glyph cache
- `close()` - Release resources

### `haforu.is_available() -> bool`

Check if native extension is available.

## Job Format

**Input (batch):**
```json
{
  "version": "1.0",
  "jobs": [{
    "id": "unique_id",
    "font": {
      "path": "/path/to/font.ttf",
      "size": 1000,
      "variations": {"wght": 600.0}
    },
    "text": {"content": "A", "script": "Latn"},
    "rendering": {
      "format": "pgm",
      "encoding": "base64",
      "width": 3000,
      "height": 1200
    }
  }]
}
```

**Output (JSONL):**
```json
{"id": "unique_id", "status": "success", "rendering": {...}, "timing": {...}}
{"id": "unique_id", "status": "error", "error": "Font not found", "timing": {...}}
```

**Metrics Output:**
```json
{
  "id": "unique_id",
  "status": "success",
  "metrics": {"density": 0.48, "beam": 0.012},
  "timing": {"shape_ms": 1.1, "render_ms": 0.7, "total_ms": 2.0}
}
```

## Building from Source

```bash
# Rust CLI
cargo build --release
export HAFORU_BIN="$PWD/target/release/haforu"

# Python bindings (dev)
pip install maturin
maturin develop

# Python wheels
maturin build --release
```

## Testing

```bash
# Rust tests
cargo test

# Python tests
pip install -e .
pytest python/tests

# Smoke test (validates CLI contract in ~2s)
./scripts/batch_smoke.sh
```

## Error Handling

All errors return JSON with `status: "error"` and descriptive messages. No crashes, no silent failures.

**Common Errors:**
- Font not found â†’ `"Font file not found: /path/to/font.ttf"`
- Invalid variation â†’ `"Unknown variation axis: slnt"`
- Shaping failed â†’ `"Text shaping failed for 'text'"`

## Integration with FontSimi

Haforu powers FontSimi's font matching pipeline:

1. **Batch Analysis** - Process thousands of glyphs via CLI streaming
2. **Deep Matching** - Use Python StreamingSession for rapid comparison
3. **Metrics Mode** - Extract features without image encoding overhead

Set `HAFORU_BIN` environment variable to use CLI mode, or import `haforu` for Python bindings.

## Dependencies

**Core:** read-fonts 0.22, skrifa 0.22, harfbuzz_rs 2.0, zeno 0.3, memmap2 0.9, lru 0.12, rayon 1.10

**Python:** pyo3 0.22, numpy 0.22

## License

MIT OR Apache-2.0
</document_content>
</document>

<document index="15">
<source>SIMPLIFICATION-SUMMARY.md</source>
<document_content>
---
this_file: SIMPLIFICATION-SUMMARY.md
---

# Haforu Documentation Simplification - Summary

**Date:** 2025-11-14
**Goal:** Remove enterprise bloat, focus on core mission: fast font rendering for CLI and Python

## Changes Made

### File-by-File Breakdown

| File | Before | After | Change | Key Improvements |
|------|--------|-------|--------|------------------|
| CLAUDE.md | 64 lines | 153 lines | +89 (+139%) | More detailed but focused guide, removed enterprise mindset |
| PLAN.md | 106 lines | 94 lines | -12 (-11%) | Removed Phase 3 infrastructure tasks, focus on core features |
| TODO.md | 56 lines | 54 lines | -2 (-4%) | Flat actionable list, removed project management overhead |
| WORK.md | 263 lines | 53 lines | -210 (-80%) | Removed historical logs, simple current work tracker |
| README.md | 595 lines | 278 lines | -317 (-53%) | Essential documentation only, massive simplification |
| **Total** | **1084 lines** | **632 lines** | **-452 (-42%)** | **Much clearer focus** |

### What Was Removed

#### From PLAN.md
- âœ‚ï¸ Phase 3: Repository Canonicalization
- âœ‚ï¸ Phase 3: Build Reliability (Local & GitHub Actions)
- âœ‚ï¸ Phase 3: Automatic SemVer & Tag-Driven Releases
- âœ‚ï¸ All "enterprise infrastructure" tasks

#### From TODO.md
- âœ‚ï¸ Repository canonicalization checklist
- âœ‚ï¸ Build reliability tasks
- âœ‚ï¸ Automatic semver tasks
- âœ‚ï¸ Complex CI/CD workflow items

#### From WORK.md
- âœ‚ï¸ 200+ lines of historical work logs
- âœ‚ï¸ Phase 3 completion summaries
- âœ‚ï¸ Detailed profiling results archives
- âœ‚ï¸ CLI documentation completion notes

#### From README.md
- âœ‚ï¸ Redundant examples (reduced 5+ examples to 2 essential ones)
- âœ‚ï¸ Excessive CLI documentation (moved to separate doc)
- âœ‚ï¸ Over-detailed explanations
- âœ‚ï¸ Troubleshooting section (kept essentials in Error Handling)
- âœ‚ï¸ H2-H5 roadmap references
- âœ‚ï¸ Multiple installation methods (consolidated)

### What Remains (Core Focus)

#### CLAUDE.md (Development Guide)
- Core mission statement
- Project structure
- What we do (and don't do)
- Simple development workflow
- Code principles
- Performance targets
- Common tasks
- Anti-patterns to avoid

#### PLAN.md (Focused Roadmap)
1. Error handling consistency
2. Variation coordinate validation
3. Metrics-only output reliability
4. Python StreamingSession reliability
5. Cross-platform build verification

#### TODO.md (Actionable Tasks)
- 54 concrete, actionable items
- Organized by plan section
- No project management overhead
- Simple checkboxes

#### WORK.md (Current Session)
- Current work tracker
- Simple template for logging work
- No historical archives

#### README.md (Essential Documentation)
- What it does (1 section)
- How to install (1 section)
- Quick start (CLI + Python)
- Architecture (simple diagram)
- Performance numbers
- CLI commands reference
- Python API reference
- Job format spec
- Building from source
- Testing

## Core Mission (Reaffirmed)

**Haforu is:** A fast font renderer for CLI and Python

**Haforu does:**
1. Render glyphs to PGM/PNG/metrics
2. Process batches in parallel via CLI
3. Stream jobs continuously
4. Provide <2ms Python bindings with caching

**Haforu does NOT:**
- Build complex release infrastructure
- Implement analytics or monitoring
- Reorganize repository structure
- Add enterprise patterns
- Support features beyond core rendering

## Validation

âœ… Project builds successfully: `cargo build --release`
âœ… All file references updated with `this_file` annotations
âœ… Documentation is consistent and focused
âœ… No functionality removed, only documentation simplified

## Next Steps

Refer to `TODO.md` for the next actionable task. The focus is now purely on:
1. Making rendering more reliable
2. Making rendering faster
3. Making rendering work cross-platform

Everything else is out of scope.

---

**Delete this file after review** - it's just a transition summary.
</document_content>
</document>

<document index="16">
<source>TODO.md</source>
<document_content>
---
this_file: TODO.md
---

# Haforu Task List

## Error Handling Consistency
- [ ] Test CLI batch mode with malformed JSON - ensure error JobResults, not crashes
- [ ] Test CLI stream mode with invalid JSONL lines - ensure error JobResults per line
- [ ] Test Python bindings with invalid job specs - ensure error JobResults returned
- [ ] Add regression tests for malformed inputs in `python/tests/test_errors.py`

## Variation Coordinate Validation
- [ ] Implement `validate_coordinates()` in `src/fonts.rs`
- [ ] Add clamping for `wght` [100, 900] with warnings
- [ ] Add clamping for `wdth` [50, 200] with warnings
- [ ] Warn and drop unknown axes (log to stderr)
- [ ] Wire validation into `FontLoader::load_font`
- [ ] Surface sanitized coordinates in `JobResult.font.variations`
- [ ] Add unit tests for in-range coordinates
- [ ] Add unit tests for out-of-range coordinates
- [ ] Add unit tests for unknown axes
- [ ] Add integration test confirming skrifa receives sanitized values

## Metrics Mode Reliability
- [ ] Verify metrics calculation is deterministic (same input = same output)
- [ ] Benchmark metrics mode runtime - ensure <0.2ms per job
- [ ] Verify `examples/python/metrics_demo.py` works correctly
- [ ] Update README with metrics mode documentation
- [ ] Add metrics mode examples to README quick reference
- [ ] Document speedup numbers in CHANGELOG

## Python StreamingSession Reliability
- [ ] Test `StreamingSession.warm_up()` with various fonts
- [ ] Test `StreamingSession.ping()` returns True on live session
- [ ] Test `haforu.is_available()` returns True after install
- [ ] Verify `max_fonts` parameter is respected
- [ ] Verify `max_glyphs` parameter is respected
- [ ] Stress test with 1000+ sequential renders
- [ ] Monitor RSS during stress test - ensure no memory leaks
- [ ] Verify JSON output matches CLI format exactly
- [ ] Document cache tuning in README Python section

## Cross-Platform Build Verification
- [ ] Test `cargo build --release` on macOS
- [ ] Test `cargo build --release` on Linux
- [ ] Test `cargo build --release` on Windows
- [ ] Test `maturin build --release` produces universal2 wheel on macOS
- [ ] Test `maturin build --release` produces manylinux wheel on Linux
- [ ] Test `maturin build --release` produces Windows wheel
- [ ] Verify Python wheels install without compiler
- [ ] Document prerequisites in README (Rust version, Python version)
- [ ] Ensure `scripts/build.sh` works on macOS and Linux
- [ ] Ensure `scripts/batch_smoke.sh` passes on all platforms
</document_content>
</document>

# File: /Users/adam/Developer/vcs/github.fontlaborg/haforu/benches/cli.rs
# Language: rust



<document index="17">
<source>build.sh</source>
<document_content>
#!/bin/bash
set -e

echo "Building Rust CLI and Python package..."
cargo build --release
uv pip install --system --upgrade -e .

echo "Running tests..."
cargo test
uvx hatch test

echo "Building wheels..."
rm -rf target/wheels
uvx maturin build --release

echo "Done."
</document_content>
</document>

<document index="18">
<source>docs/CLI-USAGE.md</source>
<document_content>
---
this_file: docs/CLI-USAGE.md
---

# Haforu CLI Usage Guide

Complete reference for the haforu command-line interface. Both Rust CLI (`haforu`) and Python CLI (`python -m haforu`) support identical commands and JSON contracts.

## Table of Contents

- [Quick Start](#quick-start)
- [Commands](#commands)
  - [batch](#batch---batch-processing)
  - [stream](#stream---streaming-mode)
  - [render](#render---single-render)
  - [validate](#validate---job-validation)
  - [diagnostics](#diagnostics---system-info)
  - [version](#version---version-display)
- [JSON Contract](#json-contract)
- [Streaming JSON (JSONL)](#streaming-json-jsonl)
- [Error Handling](#error-handling)
- [Performance Tuning](#performance-tuning)
- [Examples](#examples)

## Quick Start

```bash
# Render a single glyph (metrics only)
haforu render -f font.ttf -s 256 -t "A" --format metrics

# Batch process multiple jobs
echo '{"version":"1.0","jobs":[...]}' | haforu batch

# Stream JSONL jobs
cat jobs.jsonl | haforu stream

# Validate a job specification
haforu validate < jobs.json

# Display system diagnostics
haforu diagnostics
```

## Commands

### batch - Batch Processing

Process multiple rendering jobs from a single JSON input.

**Usage:**
```bash
haforu batch [OPTIONS] < input.json
```

**Options:**
- `--max-fonts <N>` - Maximum fonts to cache (default: 512)
- `--max-glyphs <N>` - Maximum glyphs to cache (default: 2048)
- `--jobs <N>` - Number of parallel workers (default: CPU count)
- `--timeout-ms <MS>` - Per-job timeout in milliseconds (0 = disabled)
- `--base-dir <PATH>` - Restrict font paths to this directory
- `--stats` - Emit throughput statistics to stderr

**Input Format:**
```json
{
  "version": "1.0",
  "jobs": [
    {
      "id": "job-1",
      "font": {
        "path": "/path/to/font.ttf",
        "size": 256,
        "variations": {"wght": 700, "wdth": 100}
      },
      "text": {
        "content": "A",
        "script": "Latn",
        "language": "en",
        "direction": "ltr",
        "features": ["liga=0", "kern"]
      },
      "rendering": {
        "format": "metrics",
        "encoding": "json",
        "width": 64,
        "height": 64
      }
    }
  ]
}
```

**Output:** JSONL stream (one result per line)
```json
{"id":"job-1","status":"success","metrics":{"density":0.627,"beam":0.0144},"font":{"path":"/path/to/font.ttf"},"timing":{"shape_ms":0.0,"render_ms":0.0,"total_ms":0.06}}
```

**Example:**
```bash
# Process batch with custom cache settings
haforu batch --max-fonts 128 --max-glyphs 1024 < jobs.json > results.jsonl

# With statistics
haforu batch --stats < jobs.json 2>stats.json > results.jsonl
```

### stream - Streaming Mode

Process jobs one at a time from JSONL input (no job array wrapper).

**Usage:**
```bash
haforu stream [OPTIONS] < input.jsonl
```

**Options:**
- `--max-fonts <N>` - Maximum fonts to cache (default: 512)
- `--max-glyphs <N>` - Maximum glyphs to cache (default: 2048)
- `--stats` - Emit statistics to stderr

**Input Format:** One job per line (JSONL)
```json
{"id":"job-1","font":{"path":"font.ttf","size":256,"variations":{}},"text":{"content":"A"},"rendering":{"format":"metrics","encoding":"json","width":64,"height":64}}
{"id":"job-2","font":{"path":"font.ttf","size":256,"variations":{}},"text":{"content":"B"},"rendering":{"format":"metrics","encoding":"json","width":64,"height":64}}
```

**Output:** JSONL stream (one result per line)
```json
{"id":"job-1","status":"success","metrics":{"density":0.627,"beam":0.0144},"font":{"path":"font.ttf"},"timing":{"shape_ms":0.0,"render_ms":0.0,"total_ms":0.05}}
{"id":"job-2","status":"success","metrics":{"density":0.523,"beam":0.0122},"font":{"path":"font.ttf"},"timing":{"shape_ms":0.0,"render_ms":0.0,"total_ms":0.04}}
```

**Example:**
```bash
# Stream processing
cat jobs.jsonl | haforu stream > results.jsonl

# With warm cache for maximum throughput
haforu stream --max-fonts 256 --max-glyphs 2048 < large-jobs.jsonl
```

### render - Single Render

Render a single text string (convenience command with HarfBuzz-compatible syntax).

**Usage:**
```bash
haforu render -f FONT -s SIZE -t TEXT [OPTIONS]
```

**Required Options:**
- `-f, --font-file <PATH>` - Path to font file
- `-s, --font-size <SIZE>` - Font size in points
- `-t, --text <TEXT>` - Text to render

**Optional:**
- `--format <FORMAT>` - Output format: pgm, png, metrics (default: pgm)
- `--variations <SPEC>` - Font variations: "wght=700,wdth=100" or JSON
- `--script <SCRIPT>` - Script hint (e.g., "Latn", "Arab")
- `--language <LANG>` - Language tag (e.g., "en", "ar")
- `--direction <DIR>` - Text direction: ltr, rtl, ttb, btt (default: ltr)
- `--features <FEATURES>` - OpenType features: "liga=0,kern"
- `--width <W>` - Canvas width in pixels (default: 800)
- `--height <H>` - Canvas height in pixels (default: 200)
- `-o, --output-file <PATH>` - Output file (stdout if not specified)

**Examples:**
```bash
# Metrics only (fast)
haforu render -f font.ttf -s 256 -t "A" --format metrics

# PGM image output
haforu render -f font.ttf -s 72 -t "Hello" --format pgm -o output.pgm

# Variable font with variations
haforu render -f variable.ttf -s 256 -t "A" \
  --variations "wght=700,wdth=100" --format metrics

# Arabic text with shaping
haforu render -f arabic.ttf -s 72 -t "Ù…Ø±Ø­Ø¨Ø§" \
  --script Arab --language ar --direction rtl --format png -o arabic.png

# With OpenType features
haforu render -f font.ttf -s 72 -t "ffi" \
  --features "liga=1" --format pgm
```

**HarfBuzz Compatibility:**
The `render` command uses HarfBuzz-compatible flag names for easy migration:
- `-f` / `--font-file` (like `hb-view --font-file`)
- `-s` / `--font-size` (like `hb-view --font-size`)
- `-t` / `--text` (like `hb-view --text`)
- `--variations` (like `hb-view --variations`)

Use `haforu render --help-harfbuzz` for migration examples.

### validate - Job Validation

Validate a JSON job specification without executing it.

**Usage:**
```bash
haforu validate [FILE]
```

**Example:**
```bash
# Validate from stdin
haforu validate < jobs.json

# Validate from file
haforu validate jobs.json

# Check if valid (exit code 0 = valid, 1 = invalid)
if haforu validate jobs.json; then
  echo "Valid"
fi
```

**Output on success:**
```
âœ“ Valid job specification
  Version: 1.0
  Jobs: 10
```

**Output on failure:**
```
Validation failed:
  - Job [2]: Missing 'font.path'
  - Job [5]: 'font.size' must be a number
```

### diagnostics - System Info

Display system diagnostics and default settings.

**Usage:**
```bash
haforu diagnostics [--format FORMAT]
```

**Options:**
- `--format <FORMAT>` - Output format: text (default) or json

**Example:**
```bash
# Human-readable
haforu diagnostics

# JSON format
haforu diagnostics --format json
```

**Output (text):**
```
haforu 2.0.0
Status       : ok
CPU threads  : 8
Cache defaults: fonts=512 glyphs=2048
Security     : max_json_size=100MB
```

**Output (JSON):**
```json
{
  "status": "ok",
  "version": "2.0.0",
  "cpu_count": 8,
  "cache_defaults": {
    "max_fonts": 512,
    "max_glyphs": 2048
  },
  "security": {
    "max_json_size": 104857600
  }
}
```

### version - Version Display

Print version information.

**Usage:**
```bash
haforu version
# or
haforu --version
```

**Output:**
```
haforu 2.0.0
```

## JSON Contract

### Job Specification

A complete job specification:

```json
{
  "id": "unique-job-id",
  "font": {
    "path": "/absolute/path/to/font.ttf",
    "size": 256,
    "variations": {
      "wght": 700.0,
      "wdth": 100.0
    }
  },
  "text": {
    "content": "A",
    "script": "Latn",
    "language": "en",
    "direction": "ltr",
    "features": ["liga=0", "kern"]
  },
  "rendering": {
    "format": "metrics",
    "encoding": "json",
    "width": 64,
    "height": 64
  }
}
```

**Field Reference:**

| Field | Type | Required | Description |
|-------|------|----------|-------------|
| `id` | string | Yes | Unique job identifier |
| `font.path` | string | Yes | Absolute path to font file |
| `font.size` | number | Yes | Font size in points (typically 256 for metrics) |
| `font.variations` | object | No | Variable font coordinates (axis â†’ value) |
| `text.content` | string | Yes | Text to render |
| `text.script` | string | No | Script hint (ISO 15924 code, e.g., "Latn", "Arab") |
| `text.language` | string | No | Language tag (e.g., "en", "ar") |
| `text.direction` | string | No | Text direction: "ltr", "rtl", "ttb", "btt" |
| `text.features` | array | No | OpenType features (e.g., ["liga=0", "kern"]) |
| `rendering.format` | string | Yes | Output format: "pgm", "png", "metrics" |
| `rendering.encoding` | string | Yes | Encoding: "base64" (images) or "json" (metrics) |
| `rendering.width` | number | Yes | Canvas width in pixels |
| `rendering.height` | number | Yes | Canvas height in pixels |

### Job Result

Successful result:

```json
{
  "id": "job-1",
  "status": "success",
  "metrics": {
    "density": 0.6270029105392156,
    "beam": 0.014404296875
  },
  "font": {
    "path": "/path/to/font.ttf",
    "variations": {"wght": 700.0}
  },
  "timing": {
    "shape_ms": 0.0,
    "render_ms": 0.0,
    "total_ms": 0.06
  }
}
```

Error result:

```json
{
  "id": "job-2",
  "status": "error",
  "error": "Font file not found: /missing/font.ttf"
}
```

**Result Fields:**

| Field | Type | Always Present | Description |
|-------|------|----------------|-------------|
| `id` | string | Yes | Job identifier (from input) |
| `status` | string | Yes | "success" or "error" |
| `error` | string | Only on error | Error message |
| `metrics` | object | Only on success (metrics mode) | Density and beam measurements |
| `rendering` | object | Only on success (image mode) | Image data and metadata |
| `font` | object | Only on success | Sanitized font info |
| `timing` | object | Only on success | Performance timings |

## Streaming JSON (JSONL)

Haforu uses **JSON Lines (JSONL)** format for streaming:
- One JSON object per line
- Each line is a complete, valid JSON object
- No commas between lines
- Newline-delimited (`\n`)

**Benefits:**
- âœ… Process jobs incrementally (low memory)
- âœ… Start producing results immediately
- âœ… Handle unlimited job counts
- âœ… Easy to generate/parse line-by-line

**Example Producer (Bash):**
```bash
#!/bin/bash
for i in {1..1000}; do
  cat <<EOF
{"id":"job-$i","font":{"path":"font.ttf","size":256,"variations":{}},"text":{"content":"$i"},"rendering":{"format":"metrics","encoding":"json","width":64,"height":64}}
EOF
done | haforu stream
```

**Example Consumer (Python):**
```python
import json
import sys

# Read JSONL results
for line in sys.stdin:
    result = json.loads(line)
    if result['status'] == 'success':
        print(f"{result['id']}: density={result['metrics']['density']:.4f}")
    else:
        print(f"{result['id']}: ERROR - {result['error']}", file=sys.stderr)
```

## Error Handling

Haforu guarantees that **every input line produces an output line**, even on errors.

### Error Categories

1. **Parse Errors** - Invalid JSON
```json
{"id":"unknown","status":"error","error":"Invalid JSON: expected value at line 1 column 1"}
```

2. **Validation Errors** - Missing required fields
```json
{"id":"job-1","status":"error","error":"Missing required field: font.path"}
```

3. **Font Errors** - Font file issues
```json
{"id":"job-2","status":"error","error":"Font file not found: /missing/font.ttf"}
```

4. **Rendering Errors** - Rendering failures
```json
{"id":"job-3","status":"error","error":"Failed to shape text: unsupported script"}
```

### Error Handling Patterns

**Pattern 1: Filter successful jobs**
```bash
haforu batch < jobs.json | jq 'select(.status == "success")'
```

**Pattern 2: Count errors**
```bash
haforu stream < jobs.jsonl | jq -r 'select(.status == "error") | .id' | wc -l
```

**Pattern 3: Separate success/error streams**
```bash
haforu batch < jobs.json | \
  tee >(jq 'select(.status == "success")' > success.jsonl) | \
  jq 'select(.status == "error")' > errors.jsonl
```

**Pattern 4: Retry failed jobs**
```bash
# Extract failed job IDs
haforu batch < jobs.json | \
  jq -r 'select(.status == "error") | .id' > failed-ids.txt

# Regenerate and retry
cat jobs.json | jq '.jobs |= map(select(.id | IN($ids[])))' \
  --slurpfile ids failed-ids.txt | \
  haforu batch
```

## Performance Tuning

### Cache Configuration

**Rule of thumb:**
- `--max-fonts`: Number of unique fonts in your dataset
- `--max-glyphs`: ~50-100 per font for typical use

**Examples:**
```bash
# Small dataset (10 fonts, 50 glyphs each)
haforu batch --max-fonts 16 --max-glyphs 512 < jobs.json

# Large dataset (100 fonts, 1000 glyphs each)
haforu batch --max-fonts 128 --max-glyphs 2048 < jobs.json
```

### Parallel Processing

Use `--jobs` to control parallelism:

```bash
# Single-threaded (good for debugging)
haforu batch --jobs 1 < jobs.json

# Max parallelism (default: CPU count)
haforu batch --jobs 0 < jobs.json

# Custom worker count
haforu batch --jobs 4 < jobs.json
```

### Metrics-Only Mode

For fast bulk analysis, use `format: "metrics"`:

**Performance:**
- Metrics mode: ~0.2ms per job
- Image mode: ~2-5ms per job
- **Speedup: 10-25Ã—**

```bash
# Convert jobs to metrics-only
jq '.jobs[].rendering.format = "metrics"' < jobs.json | haforu batch
```

### Statistics Monitoring

Enable `--stats` to monitor throughput:

```bash
haforu batch --stats < large-jobs.json 2> stats.json > results.jsonl
```

**Stats output (JSON to stderr):**
```json
{
  "jobs_processed": 1000,
  "jobs_success": 985,
  "jobs_error": 15,
  "elapsed_ms": 2453.2,
  "jobs_per_sec": 407.6,
  "cache": {
    "fonts_loaded": 12,
    "fonts_cached": 12,
    "glyphs_cached": 850
  }
}
```

## Examples

### Example 1: Batch Process with Metrics

```bash
cat > jobs.json <<'EOF'
{
  "version": "1.0",
  "jobs": [
    {
      "id": "arial-A",
      "font": {"path": "Arial.ttf", "size": 256, "variations": {}},
      "text": {"content": "A"},
      "rendering": {"format": "metrics", "encoding": "json", "width": 64, "height": 64}
    },
    {
      "id": "arial-B",
      "font": {"path": "Arial.ttf", "size": 256, "variations": {}},
      "text": {"content": "B"},
      "rendering": {"format": "metrics", "encoding": "json", "width": 64, "height": 64}
    }
  ]
}
EOF

haforu batch < jobs.json | jq '.metrics'
```

**Output:**
```json
{"density":0.6270029105392156,"beam":0.014404296875}
{"density":0.5234375,"beam":0.01220703125}
```

### Example 2: Variable Font Exploration

```bash
# Generate jobs for different weights
for wght in 100 200 300 400 500 600 700 800 900; do
  cat <<EOF
{"id":"wght-$wght","font":{"path":"Variable.ttf","size":256,"variations":{"wght":$wght}},"text":{"content":"A"},"rendering":{"format":"metrics","encoding":"json","width":64,"height":64}}
EOF
done | haforu stream | jq '{id, density: .metrics.density}'
```

**Output:**
```json
{"id":"wght-100","density":0.421}
{"id":"wght-200","density":0.453}
{"id":"wght-300","density":0.489}
...
```

### Example 3: Parallel Batch with Error Handling

```bash
#!/bin/bash
set -euo pipefail

# Process jobs with error handling
haforu batch --jobs 8 --max-fonts 64 < large-jobs.json | \
  tee results.jsonl | \
  jq -r 'select(.status == "error") | "\(.id): \(.error)"' | \
  tee errors.log

# Check if any errors occurred
if [ -s errors.log ]; then
  echo "Errors occurred during processing:"
  cat errors.log
  exit 1
fi

echo "All jobs completed successfully"
```

### Example 4: Stream Processing Pipeline

```bash
# Generate jobs â†’ process â†’ aggregate metrics
seq 1 1000 | \
  awk '{print "{\"id\":\"" $1 "\",\"font\":{\"path\":\"font.ttf\",\"size\":256,\"variations\":{}},\"text\":{\"content\":\"" $1 "\"},\"rendering\":{\"format\":\"metrics\",\"encoding\":\"json\",\"width\":64,\"height\":64}}"}' | \
  haforu stream | \
  jq -s '{total: length, avg_density: ([.[].metrics.density] | add / length)}'
```

### Example 5: Font Comparison

```bash
# Compare same glyph across multiple fonts
for font in Font1.ttf Font2.ttf Font3.ttf; do
  haforu render -f "$font" -s 256 -t "A" --format metrics | \
    jq --arg font "$font" '{font: $font, density, beam}'
done
```

**Output:**
```json
{"font":"Font1.ttf","density":0.627,"beam":0.0144}
{"font":"Font2.ttf","density":0.543,"beam":0.0122}
{"font":"Font3.ttf","density":0.689,"beam":0.0156}
```

## See Also

- [Python API Documentation](./PYTHON-API.md)
- [Architecture Overview](../README.md#architecture)
- [Installation Guide](../INSTALL.md)
- [Performance Benchmarks](../WORK.md)

## Support

- **Issues**: https://github.com/fontlaborg/haforu/issues
- **Examples**: See `examples/` directory in the repository
- **Tests**: See `scripts/test-cli-parity.sh` for comprehensive CLI tests
</document_content>
</document>

<document index="19">
<source>docs/REPOSITORY.md</source>
<document_content>
---
this_file: docs/REPOSITORY.md
---

# Repository Structure & Best Practices

This document describes haforu's repository layout, build configuration, and adherence to Rust + PyO3 + Hatch best practices.

## Overview

Haforu is a **hybrid Rust + Python project** using:
- **Rust** - Core rendering engine (`src/`)
- **PyO3** - Python bindings (`src/python/`)
- **Maturin** - Build backend for Python wheels
- **Hatch** - Python testing and tooling
- **Fire** - Python CLI framework

## Directory Structure

```
haforu/
â”œâ”€â”€ .cargo/
â”‚   â””â”€â”€ config.toml          # Cargo configuration, build profiles, aliases
â”œâ”€â”€ .github/                  # GitHub Actions workflows (to be added)
â”œâ”€â”€ benches/
â”‚   â””â”€â”€ cli.rs               # Criterion benchmarks for CLI hot paths
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ CLI-USAGE.md         # Comprehensive CLI documentation
â”‚   â””â”€â”€ REPOSITORY.md        # This file
â”œâ”€â”€ examples/
â”‚   â””â”€â”€ python/              # Python usage examples
â”œâ”€â”€ python/
â”‚   â”œâ”€â”€ haforu/
â”‚   â”‚   â”œâ”€â”€ __init__.py      # Python package entry point
â”‚   â”‚   â”œâ”€â”€ __main__.py      # Fire CLI implementation
â”‚   â”‚   â””â”€â”€ _version.py      # Auto-generated version (hatch-vcs)
â”‚   â””â”€â”€ tests/               # Python test suite (pytest)
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ build.sh             # Comprehensive build script
â”‚   â”œâ”€â”€ run.sh               # Multi-mode test runner
â”‚   â”œâ”€â”€ profile-cli.sh       # Performance profiling
â”‚   â”œâ”€â”€ regression-test.sh   # Performance regression gates
â”‚   â””â”€â”€ test-cli-parity.sh   # Python/Rust CLI parity tests
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ batch.rs             # Job specification structs
â”‚   â”œâ”€â”€ error.rs             # Error types
â”‚   â”œâ”€â”€ fonts.rs             # Font loader with caching
â”‚   â”œâ”€â”€ lib.rs               # Public API
â”‚   â”œâ”€â”€ main.rs              # Rust CLI
â”‚   â”œâ”€â”€ output.rs            # Image output (PGM/PNG)
â”‚   â”œâ”€â”€ python/              # PyO3 bindings
â”‚   â”œâ”€â”€ render.rs            # Rasterization
â”‚   â”œâ”€â”€ security.rs          # Security validation
â”‚   â””â”€â”€ shaping.rs           # HarfBuzz shaping
â”œâ”€â”€ testdata/
â”‚   â””â”€â”€ fonts/               # Test fonts
â”œâ”€â”€ Cargo.toml               # Rust package manifest
â”œâ”€â”€ pyproject.toml           # Python package manifest
â”œâ”€â”€ CHANGELOG.md             # Release notes
â”œâ”€â”€ PLAN.md                  # Project planning
â”œâ”€â”€ TODO.md                  # Task tracking
â””â”€â”€ WORK.md                  # Work session notes
```

## Configuration Files

### Cargo.toml

**Purpose:** Rust package manifest and build configuration

**Key Sections:**
- `[package]` - Metadata (name, version, description, license)
- `[lib]` - Library configuration (`cdylib` for Python, `rlib` for Rust)
- `[[bin]]` - Binary target (haforu CLI)
- `[[bench]]` - Benchmark configuration
- `[dependencies]` - Production dependencies
- `[dev-dependencies]` - Test/benchmark dependencies
- `[features]` - Feature flags (default, python)
- `[profile.*]` - Build profiles (dev, release)

**Best Practices Applied:**
- âœ… Separate `cdylib` and `rlib` targets
- âœ… Explicit feature flags for Python bindings
- âœ… Optimized release profile (LTO, strip, single codegen-unit)
- âœ… Rust edition 2021
- âœ… MSRV documented (1.70)

### pyproject.toml

**Purpose:** Python package manifest and tool configuration

**Key Sections:**
- `[build-system]` - Maturin backend with hatch-vcs
- `[project]` - Package metadata
- `[project.scripts]` - Console entry points (`haforu-py`)
- `[tool.maturin]` - Maturin configuration
- `[tool.pytest.ini_options]` - Pytest configuration
- `[tool.hatch.version]` - VCS-based versioning
- `[tool.ruff]` - Linting configuration
- `[tool.mypy]` - Type checking configuration

**Best Practices Applied:**
- âœ… Dynamic versioning from git tags (hatch-vcs)
- âœ… Separate Python source directory (`python/`)
- âœ… Console entry point for CLI (`haforu-py`)
- âœ… Platform-specific optional dependencies
- âœ… Modern Python 3.8+ support
- âœ… Comprehensive metadata (classifiers, keywords)

### .cargo/config.toml

**Purpose:** Cargo build configuration and platform-specific settings

**Key Features:**
- Build profiles (dev, release, release-with-debug, bench, dist)
- Platform-specific rustflags
- Linker optimizations (LLD on Linux)
- Profiling support (frame pointers, debug symbols)
- Command aliases for convenience
- Network configuration (retries, git CLI)

**Best Practices Applied:**
- âœ… Frame pointers enabled for profiling
- âœ… Platform-specific optimizations
- âœ… Multiple build profiles for different use cases
- âœ… LTO and size optimizations for distribution
- âœ… Split debug info on macOS for faster builds
- âœ… Sparse registry protocol for faster downloads

## Build System

### Rust Build

```bash
# Development build
cargo build

# Release build (optimized)
cargo build --release

# With Python bindings
cargo build --release --features python

# Run tests
cargo test

# Run benchmarks
cargo bench
```

### Python Build

```bash
# Development install (editable)
pip install -e .

# Build wheels
maturin build --release

# Build and install
maturin develop --release

# Run tests
pytest python/tests/

# Or using hatch
hatch test
```

### Unified Build Script

```bash
# Comprehensive build + test + package
./scripts/build.sh

# Quick development build
./build.sh
```

## Version Management

### Current Approach

**Rust:** Manual versioning in `Cargo.toml`
- Version: `2.0.0`
- Updated manually for releases

**Python:** Dynamic versioning via hatch-vcs
- Reads from git tags
- Auto-generates `python/haforu/_version.py`
- Configured in `pyproject.toml`

### Recommended Approach (TODO)

Use **tag-driven versioning** for both:

1. Create git tag: `git tag -a v2.1.0 -m "Release 2.1.0"`
2. Push tag: `git push origin v2.1.0`
3. GitHub Actions:
   - Builds Rust binary
   - Builds Python wheels
   - Creates GitHub Release
   - Publishes to crates.io and PyPI

**Benefits:**
- Single source of truth (git tags)
- Automated releases
- No manual version bumps
- Consistent Rust + Python versions

## Testing Strategy

### Rust Tests

**Location:** Inline in `src/` modules
**Run:** `cargo test`

**Coverage:**
- 36 library tests (unit + integration)
- 13 main tests (CLI commands)
- Tests for: batch, fonts, render, streaming, output

### Python Tests

**Location:** `python/tests/`
**Run:** `pytest` or `hatch test`

**Coverage:**
- 65 tests total
- Tests for: batch, errors, numpy, streaming
- Includes bindings tests and CLI tests

### Integration Tests

**Scripts in `scripts/`:**
- `batch_smoke.sh` - Smoke tests for CLI contract
- `profile-cli.sh` - Performance profiling
- `regression-test.sh` - Performance regression detection
- `test-cli-parity.sh` - Python/Rust CLI parity (20 tests)

### Performance Tests

**Benchmarks:**
- `benches/cli.rs` - Criterion benchmarks (note: has serde version conflicts)
- `scripts/profile-cli.sh` - Hyperfine-based profiling
- `scripts/regression-test.sh` - Threshold-based gates

**Metrics:**
- Startup time: ~6.5ms
- Batch (100 jobs): ~7-8ms
- Streaming (1000 lines): ~10ms
- Metrics render: ~6ms
- PGM render: ~7.5ms

## Code Organization

### Rust Modules

**Principle:** Small, focused modules with clear responsibilities

- `batch.rs` - Data structures only (Job, JobSpec, JobResult)
- `fonts.rs` - Font loading and caching (FontLoader, FontInstance)
- `shaping.rs` - Text shaping (TextShaper, ShapedText)
- `render.rs` - Rasterization (GlyphRasterizer, Image)
- `output.rs` - Image encoding (ImageOutput, PGM/PNG)
- `error.rs` - Error types (Error, Result)
- `security.rs` - Security validation
- `lib.rs` - Public API and orchestration
- `main.rs` - CLI implementation

**Best Practices:**
- âœ… Separation of concerns
- âœ… Clear module boundaries
- âœ… Public API in `lib.rs`
- âœ… Minimal inter-module dependencies
- âœ… Comprehensive documentation

### Python Package

**Structure:**
- `python/haforu/__init__.py` - Public API (process_jobs, StreamingSession)
- `python/haforu/__main__.py` - Fire CLI (HaforuCLI class)
- `python/haforu/_version.py` - Auto-generated version
- `python/tests/` - Test suite

**Best Practices:**
- âœ… Clear public API
- âœ… Separate CLI implementation
- âœ… Type stubs for bindings
- âœ… Comprehensive tests

### PyO3 Bindings

**Location:** `src/python/`

**Pattern:**
- Thin wrappers around Rust API
- Python-friendly types (str, dict, list)
- Error conversion to Python exceptions (where appropriate)
- Iterator protocol for streaming

**Best Practices:**
- âœ… Minimal business logic in bindings
- âœ… Delegate to Rust core
- âœ… Pythonic API surface
- âœ… GIL release for CPU-intensive operations

## File Annotations

### `this_file` Convention

Every source file includes a header comment with its path relative to repository root:

**Rust:**
```rust
// this_file: src/main.rs
```

**Python:**
```python
# this_file: python/haforu/__init__.py
```

**Markdown:**
```markdown
---
this_file: docs/REPOSITORY.md
---
```

**Purpose:**
- Clear file identity
- Easy navigation
- Copy-paste context preservation
- LLM-friendly codebase exploration

## Development Workflow

### Local Development

1. **Clone repository:**
   ```bash
   git clone https://github.com/fontsimi/haforu.git
   cd haforu
   ```

2. **Build and test:**
   ```bash
   # Build everything
   ./scripts/build.sh

   # Run tests
   cargo test
   pytest python/tests/

   # Run smoke tests
   ./scripts/run.sh smoke
   ```

3. **Make changes:**
   - Edit Rust code in `src/`
   - Edit Python code in `python/haforu/`
   - Update tests
   - Update documentation

4. **Verify changes:**
   ```bash
   # Rust tests
   cargo test

   # Python tests
   hatch test

   # CLI parity
   ./scripts/test-cli-parity.sh

   # Performance
   ./scripts/regression-test.sh
   ```

5. **Update documentation:**
   - Update `CHANGELOG.md`
   - Update `WORK.md` with notes
   - Update `TODO.md` if applicable

### Release Workflow (Manual)

1. **Update versions:**
   - Bump version in `Cargo.toml`
   - Create git tag: `git tag -a v2.1.0 -m "Release 2.1.0"`

2. **Build and test:**
   ```bash
   ./scripts/build.sh
   cargo test
   hatch test
   ```

3. **Build artifacts:**
   ```bash
   # Rust binary
   cargo build --release

   # Python wheels
   maturin build --release
   ```

4. **Publish:**
   ```bash
   # Rust crate
   cargo publish

   # Python wheels
   maturin publish
   ```

5. **Tag and push:**
   ```bash
   git push origin v2.1.0
   ```

### Release Workflow (Automated - TODO)

GitHub Actions workflow triggered by `v*` tags:
1. Checkout code
2. Build Rust binary (multi-platform)
3. Build Python wheels (manylinux, macOS, Windows)
4. Run full test suite
5. Create GitHub Release
6. Publish to crates.io
7. Publish to PyPI

## Best Practices Compliance

### Rust Workspace Best Practices

âœ… **Applied:**
- Clear module structure
- Comprehensive Cargo.toml
- Feature flags for optional dependencies
- Optimized release profile
- Platform-specific configuration
- Benchmark configuration

âŒ **Not Applied (by design):**
- Workspace structure (single crate is appropriate for this project)
- Multiple binary targets (only one CLI needed)

### PyO3 Best Practices

âœ… **Applied:**
- Feature flag for Python bindings
- Separate source directory for Python code
- Type conversions at binding boundary
- GIL management
- Python-friendly API

âœ… **Excellent:**
- Streaming API with proper iterator protocol
- Error handling with custom exceptions
- Cache management from Python

### Hatch Best Practices

âœ… **Applied:**
- VCS-based versioning
- pytest configuration
- ruff configuration
- mypy configuration
- Development dependencies

âŒ **Not Applied (low priority):**
- Multiple test environments
- Matrix testing across Python versions

### Maturin Best Practices

âœ… **Applied:**
- Correct build backend configuration
- Python source directory specified
- Module name configured
- Feature selection

âœ… **Excellent:**
- Universal2 wheels for macOS
- Manylinux wheels for Linux
- Windows wheel support

## Deviations from Canonical Structure

### 1. Single Crate vs Workspace

**Current:** Single Rust crate at repository root
**Canonical:** Workspace with multiple crates

**Justification:**
- Project is cohesive single unit
- No need for sub-crates
- Simpler build and dependency management
- Appropriate for project size

### 2. PyO3 Bindings Location

**Current:** `src/python/` (within Rust crate)
**Alternative:** Separate `bindings/` directory

**Justification:**
- Keeps bindings close to Rust code
- Clear feature flag boundary
- Works well with Maturin
- Standard pattern for PyO3 projects

### 3. Python Package Location

**Current:** `python/` directory at root
**Alternative:** `py-haforu/` or separate repository

**Justification:**
- Maturin convention
- Clear separation from Rust source
- Supports independent Python development
- Recommended by Maturin documentation

## Performance Characteristics

### Build Times

**Rust (Release):**
- Clean build: ~2-3 minutes
- Incremental: ~10-30 seconds

**Python (Wheel):**
- Clean build: ~2-3 minutes (includes Rust)
- Maturin develop: ~30 seconds

**Full CI Build:**
- Estimated: ~10-15 minutes (multi-platform)

### Binary Sizes

**Rust Binary:**
- Release (stripped): ~2.4MB
- Release (with debug): ~15MB

**Python Wheel:**
- macOS (universal2): ~5-6MB
- Linux (manylinux): ~4-5MB
- Windows: ~3-4MB

### Runtime Performance

**CLI Startup:** ~6.5ms
**Throughput:** ~100k jobs/sec (streaming, metrics-only)
**Memory:** <100MB for typical workloads

## Known Issues

1. **Criterion Benchmarks:** serde_core version conflicts (low priority)
2. **Windows Testing:** Limited Windows CI coverage
3. **Documentation:** Some internal APIs undocumented

## Future Improvements

### High Priority
1. âœ… CLI documentation (DONE)
2. âœ… Performance profiling scripts (DONE)
3. âœ… CLI parity testing (DONE)
4. GitHub Actions CI/CD
5. Automated releases

### Medium Priority
1. Windows build testing
2. Cross-compilation support
3. Additional benchmarks
4. Coverage reporting

### Low Priority
1. Workspace structure (if project grows)
2. Separate PyO3 bindings crate
3. Cargo-vcs for Rust versioning
4. Pre-commit hooks

## See Also

- [CLI Usage Guide](./CLI-USAGE.md)
- [Installation Guide](../INSTALL.md)
- [Project Plan](../PLAN.md)
- [TODO List](../TODO.md)
</document_content>
</document>

# File: /Users/adam/Developer/vcs/github.fontlaborg/haforu/examples/python/batch_demo.py
# Language: python

import json
import sys
from pathlib import Path
import haforu

def main(()):


# File: /Users/adam/Developer/vcs/github.fontlaborg/haforu/examples/python/error_handling_demo.py
# Language: python

import json
import sys
from pathlib import Path
import haforu

def demo_batch_errors(()):

def demo_streaming_errors(()):

def demo_graceful_degradation(()):

def main(()):


# File: /Users/adam/Developer/vcs/github.fontlaborg/haforu/examples/python/metrics_demo.py
# Language: python

import json
import sys
from pathlib import Path
import haforu

def main(()) -> None:


# File: /Users/adam/Developer/vcs/github.fontlaborg/haforu/examples/python/numpy_demo.py
# Language: python

import sys
from pathlib import Path
import numpy as np
import haforu

def analyze_glyph_image((image: np.ndarray, glyph: str)) -> dict:

def main(()):


# File: /Users/adam/Developer/vcs/github.fontlaborg/haforu/examples/python/streaming_demo.py
# Language: python

import json
import sys
from pathlib import Path
import haforu

def main(()):


# File: /Users/adam/Developer/vcs/github.fontlaborg/haforu/examples/smoke_test.rs
# Language: rust



<document index="20">
<source>llms.sh</source>
<document_content>
#!/usr/bin/env bash

cd "$(dirname "$0")"

llms . "*.txt,AGENTS.md,CLAUDE.md,GEMINI.md,LLXPRT.md,QWEN.md,WORK.md,issues,target,external,haforu"
</document_content>
</document>

<document index="21">
<source>pyproject.toml</source>
<document_content>
# this_file: pyproject.toml

[build-system]
requires = ["maturin>=1.0,<2.0", "hatch-vcs>=0.4.0"]
build-backend = "maturin"

[project]
name = "haforu"
dynamic = ["version"]
description = "High-performance batch font renderer for FontSimi"
readme = "README.md"
requires-python = ">=3.8"
license = { text = "MIT OR Apache-2.0" }
authors = [
    { name = "FontSimi Team" }
]
classifiers = [
    "Development Status :: 4 - Beta",
    "Intended Audience :: Developers",
    "License :: OSI Approved :: MIT License",
    "License :: OSI Approved :: Apache Software License",
    "Programming Language :: Python :: 3",
    "Programming Language :: Python :: 3.8",
    "Programming Language :: Python :: 3.9",
    "Programming Language :: Python :: 3.10",
    "Programming Language :: Python :: 3.11",
    "Programming Language :: Python :: 3.12",
    "Programming Language :: Rust",
    "Topic :: Multimedia :: Graphics",
    "Topic :: Software Development :: Libraries",
]
keywords = ["font", "rendering", "batch", "typography"]

dependencies = [
    "numpy>=1.20",
    "fire>=0.5.0",
]

[project.optional-dependencies]
dev = [
    "pytest>=7.0",
    "pytest-benchmark>=4.0",
    "pillow>=10.0",
    "hatch>=1.9.0",
]
# Platform-specific extras
mac = []  # macOS-specific dependencies (universal2 wheel)
windows = []  # Windows-specific dependencies
linux = []  # Linux-specific dependencies (manylinux wheel)
all = ["pillow>=10.0"]  # All optional dependencies

[project.urls]
Homepage = "https://github.com/fontsimi/haforu"
Repository = "https://github.com/fontsimi/haforu"

[project.scripts]
haforu-py = "haforu.__main__:main"

[tool.maturin]
features = ["python"]
python-source = "python"
module-name = "haforu._haforu"

[tool.pytest.ini_options]
testpaths = ["python/tests"]
python_files = ["test_*.py"]
python_classes = ["Test*"]
python_functions = ["test_*"]

[tool.ruff]
line-length = 100
target-version = "py38"

[tool.ruff.lint]
select = ["E", "F", "W", "I", "N", "UP", "YTT", "S", "B", "A", "C4", "T10", "T20", "Q"]
ignore = ["S101"]  # Allow assert in tests

[tool.mypy]
python_version = "3.8"
warn_return_any = true
warn_unused_configs = true
disallow_untyped_defs = true

[tool.hatch]

[tool.hatch.version]
source = "vcs"
raw-options = { root = "../.." }

[tool.hatch.build.hooks.vcs]
version-file = "python/haforu/_version.py"
</document_content>
</document>

# File: /Users/adam/Developer/vcs/github.fontlaborg/haforu/python/tests/test_batch.py
# Language: python

import json
import pytest
import haforu
import haforu
import haforu
import haforu
import haforu
import haforu
import haforu
import haforu
import haforu

def test_import_haforu(()):

def test_process_jobs_function_exists(()):

def test_process_jobs_empty_list(()):

def test_process_jobs_invalid_json(()):

def test_process_jobs_invalid_version(()):

def test_process_jobs_basic_structure(()):

def test_process_jobs_result_format(()):

def test_process_jobs_invalid_rendering_yields_error_payload(()):

def test_process_jobs_metrics_format_returns_metrics_payload(()):


# File: /Users/adam/Developer/vcs/github.fontlaborg/haforu/python/tests/test_errors.py
# Language: python

import json
import tempfile
from pathlib import Path
import pytest
import haforu

class TestMissingFontErrors:
    def test_process_jobs_missing_font((self)):
    def test_streaming_session_missing_font((self)):
    def test_render_to_numpy_missing_font((self)):

class TestInvalidFontErrors:
    def test_corrupted_font_file((self, tmp_path)):
    def test_empty_font_file((self, tmp_path)):

class TestJSONValidationErrors:
    def test_invalid_json_syntax((self)):
    def test_missing_version_field((self)):
    def test_invalid_version((self)):
    def test_empty_jobs_list((self)):
    def test_streaming_invalid_json((self)):

class TestRenderParameterValidation:
    def test_invalid_dimensions_zero_width((self)):
    def test_invalid_dimensions_zero_height((self)):
    def test_invalid_font_size_zero((self)):
    def test_invalid_font_size_negative((self)):

class TestEmptyTextHandling:
    def test_empty_text_content((self)):
    def test_whitespace_only_text((self)):

class TestVariationCoordinateErrors:
    def test_invalid_variation_axis_name((self)):
    def test_numpy_invalid_variation_type((self)):

class TestErrorMessageQuality:
    def test_error_includes_font_path((self)):
    def test_batch_error_includes_job_id((self)):
    def test_json_error_indicates_parse_issue((self)):
    def test_validation_error_indicates_reason((self)):

class TestContextManagerErrorHandling:
    def test_exception_in_context_manager((self)):
    def test_context_manager_cleanup_after_error((self)):

class TestEdgeCases:
    def test_very_large_dimensions((self)):
    def test_unicode_text_in_errors((self)):
    def test_multiple_jobs_some_failing((self)):

def test_process_jobs_missing_font((self)):

def test_streaming_session_missing_font((self)):

def test_render_to_numpy_missing_font((self)):

def test_corrupted_font_file((self, tmp_path)):

def test_empty_font_file((self, tmp_path)):

def test_invalid_json_syntax((self)):

def test_missing_version_field((self)):

def test_invalid_version((self)):

def test_empty_jobs_list((self)):

def test_streaming_invalid_json((self)):

def test_invalid_dimensions_zero_width((self)):

def test_invalid_dimensions_zero_height((self)):

def test_invalid_font_size_zero((self)):

def test_invalid_font_size_negative((self)):

def test_empty_text_content((self)):

def test_whitespace_only_text((self)):

def test_invalid_variation_axis_name((self)):

def test_numpy_invalid_variation_type((self)):

def test_error_includes_font_path((self)):

def test_batch_error_includes_job_id((self)):

def test_json_error_indicates_parse_issue((self)):

def test_validation_error_indicates_reason((self)):

def test_exception_in_context_manager((self)):

def test_context_manager_cleanup_after_error((self)):

def test_very_large_dimensions((self)):

def test_unicode_text_in_errors((self)):

def test_multiple_jobs_some_failing((self)):


# File: /Users/adam/Developer/vcs/github.fontlaborg/haforu/python/tests/test_numpy.py
# Language: python

import json
import pytest
import haforu
import haforu
import numpy as np
import haforu
import numpy as np
import haforu
import numpy as np
import haforu
import numpy as np
import haforu
import numpy as np
import haforu
import numpy as np
import haforu
import numpy as np
import haforu
import numpy as np
import haforu
import numpy as np
import haforu
import numpy as np
import haforu
import numpy as np
import base64

def test_render_to_numpy_import(()):

def test_render_to_numpy_basic(()):

def test_render_to_numpy_array_shape(()):

def test_render_to_numpy_dtype(()):

def test_render_to_numpy_with_variations(()):

def test_render_to_numpy_with_script_params(()):

def test_render_to_numpy_array_contiguous(()):

def test_render_to_numpy_value_range(()):

def test_render_to_numpy_context_manager(()):

def test_render_to_numpy_multiple_calls(()):

def test_render_to_numpy_parameter_validation(()):

def test_render_to_numpy_vs_base64_consistency(()):


# File: /Users/adam/Developer/vcs/github.fontlaborg/haforu/python/tests/test_streaming.py
# Language: python

import json
import pytest
import haforu
import haforu
import haforu
import haforu
import haforu
import haforu
import haforu
import haforu
import haforu
import haforu
import haforu
import haforu
import haforu
from pathlib import Path
import haforu
import haforu
import haforu
import haforu

def test_streaming_session_import(()):

def test_streaming_session_creation(()):

def test_streaming_session_custom_cache_size(()):

def test_streaming_session_cache_stats_and_resize(()):

def test_streaming_session_glyph_cache_reuses_results(()):

def test_streaming_session_can_disable_glyph_cache(()):

def test_streaming_session_close(()):

def test_streaming_session_context_manager(()):

def test_streaming_session_render_method_exists(()):

def test_streaming_session_render_invalid_json(()):

def test_streaming_session_warm_up_ping(()):

def test_streaming_session_render_single_job(()):

def test_streaming_session_multiple_renders(()):

def test_streaming_session_result_format(()):

def test_streaming_session_error_handling(()):

def test_streaming_session_metrics_format_returns_metrics_payload(()):

def test_haforu_module_is_available_probe(()):


<document index="22">
<source>run.sh</source>
<document_content>
#!/bin/bash
# this_file: run.sh

set -e

MODE="${1:-smoke}"

echo "Running haforu in '$MODE' mode..."
exec ./scripts/run.sh "$MODE"
</document_content>
</document>

<document index="23">
<source>scripts/batch_smoke.sh</source>
<document_content>
#!/usr/bin/env bash
# this_file: scripts/batch_smoke.sh

set -euo pipefail

ROOT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")/.." && pwd)"
cd "$ROOT_DIR"

JOBS_FILE="${JOBS_FILE:-$ROOT_DIR/scripts/jobs_smoke.jsonl}"
CACHE_SIZE="${CACHE_SIZE:-256}"
GLYPH_CACHE_SIZE="${GLYPH_CACHE_SIZE:-512}"
JOB_THREADS="${JOB_THREADS:-4}"

if [[ ! -r "$JOBS_FILE" ]]; then
  echo "Smoke jobs file not found: $JOBS_FILE" >&2
  exit 1
fi

BIN_PATH="${HAFORU_BIN:-$ROOT_DIR/target/release/haforu}"
if [[ ! -x "$BIN_PATH" ]]; then
  cargo build --release >/dev/null 2>&1
fi

if [[ ! -x "$BIN_PATH" ]]; then
  echo "haforu binary not found at $BIN_PATH" >&2
  exit 1
fi

OUTPUT_FILE="$(mktemp)"
trap 'rm -f "$OUTPUT_FILE"' EXIT

if ! "$BIN_PATH" batch \
  --max-fonts "$CACHE_SIZE" \
  --max-glyphs "$GLYPH_CACHE_SIZE" \
  --jobs "$JOB_THREADS" \
  < "$JOBS_FILE" | tee "$OUTPUT_FILE"; then
  echo "haforu batch run failed" >&2
  exit 1
fi

python3 <<'PY' "$OUTPUT_FILE"
import json
import pathlib
import sys

lines = [ln.strip() for ln in pathlib.Path(sys.argv[1]).read_text().splitlines() if ln.strip()]
if not lines:
    raise SystemExit("Smoke run produced no JSONL output")

expected = {
    "smoke-1": "success",
    "smoke-2": "success",
    "smoke-metrics": "success",
    "smoke-invalid": "error",
}

seen = {}
for raw in lines:
    try:
        payload = json.loads(raw)
    except json.JSONDecodeError as exc:
        raise SystemExit(f"Invalid JSONL line from haforu: {exc}: {raw!r}") from exc
    job_id = payload.get("id")
    status = payload.get("status")
    if job_id is None or status is None:
        raise SystemExit(f"Missing id/status in payload: {payload}")
    seen[job_id] = payload
    if job_id not in expected:
        raise SystemExit(f"Unexpected job id {job_id}; expected {sorted(expected)}")
    if status != expected[job_id]:
        raise SystemExit(
            f"Job {job_id} returned status {status}, expected {expected[job_id]}"
        )

invalid_error = seen["smoke-invalid"].get("error", "")
if "Font size" not in invalid_error:
    raise SystemExit(
        f"smoke-invalid should report font-size validation error, got: {invalid_error!r}"
    )

metrics_payload = seen["smoke-metrics"]
if "metrics" not in metrics_payload:
    raise SystemExit(f"smoke-metrics missing metrics payload: {metrics_payload}")
if "rendering" in metrics_payload:
    raise SystemExit("metrics format should not emit rendering field")
metrics = metrics_payload["metrics"]
for key in ("density", "beam"):
    value = metrics.get(key)
    if value is None:
        raise SystemExit(f"metrics payload missing {key}: {metrics}")
    if not isinstance(value, (int, float)) or not (0 <= value <= 1):
        raise SystemExit(f"{key} should be 0<=x<=1, got {value!r}")

print("âœ“ batch_smoke JSON contract verified")
PY
</document_content>
</document>

<document index="24">
<source>scripts/build.sh</source>
<document_content>
#!/usr/bin/env bash
# this_file: scripts/build.sh

set -euo pipefail

ROOT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")/.." && pwd)"
PROFILE="${HAFORU_PROFILE:-release}"
RUN_TESTS=1
RUN_SMOKE=1
SKIP_WHEELS=0
TARGETS="auto"

usage() {
    cat <<'EOF'
Usage: scripts/build.sh [options]

Options:
  --profile <name>     Cargo profile to build/test (default: release)
  --skip-tests         Skip cargo/uvx test suites
  --skip-smoke         Skip scripts/batch_smoke.sh
  --skip-wheels        Skip Python wheel builds
  --targets "<list>"   Wheel targets (auto|universal2|manylinux|windows|all)
  -h, --help           Show this help

Environment:
  ARTIFACT_DIR     Override target/artifacts output root
  HAFORU_PROFILE   Alias for --profile
EOF
}

while (($#)); do
    case "$1" in
        --profile) PROFILE="$2"; shift ;;
        --skip-tests) RUN_TESTS=0 ;;
        --skip-smoke) RUN_SMOKE=0 ;;
        --skip-wheels) SKIP_WHEELS=1 ;;
        --targets) TARGETS="$2"; shift ;;
        -h|--help)
            usage
            exit 0
            ;;
        *)
            printf 'Unknown option: %s\n\n' "$1" >&2
            usage
            exit 1
            ;;
    esac
    shift
done

cd "$ROOT_DIR"

if [[ -z "${CARGO_BUILD_JOBS:-}" ]]; then
    if command -v getconf >/dev/null 2>&1; then
        CARGO_BUILD_JOBS="$(getconf _NPROCESSORS_ONLN 2>/dev/null || echo 1)"
    else
        CARGO_BUILD_JOBS="${NUMBER_OF_PROCESSORS:-1}"
    fi
    [[ "$CARGO_BUILD_JOBS" -ge 1 ]] 2>/dev/null || CARGO_BUILD_JOBS=1
    export CARGO_BUILD_JOBS
fi

if [[ -z "${CARGO_SOURCE_CRATES_IO_REPLACE_WITH:-}" ]]; then
    export CARGO_SOURCE_CRATES_IO_REPLACE_WITH="crates-io"
fi

if [[ -z "${CARGO_SOURCE_VENDORED_SOURCES_DIRECTORY:-}" ]]; then
    export CARGO_SOURCE_VENDORED_SOURCES_DIRECTORY="$ROOT_DIR/target/vendor-empty"
    mkdir -p "$CARGO_SOURCE_VENDORED_SOURCES_DIRECTORY"
fi

ARTIFACT_ROOT="${ARTIFACT_DIR:-$ROOT_DIR/target/artifacts}"
RUN_STAMP="$(date +%Y%m%d-%H%M%S)"
RUN_DIR="$ARTIFACT_ROOT/$RUN_STAMP"
BIN_DIR="$RUN_DIR/bin"
WHEEL_DIR="$RUN_DIR/wheels"
LOG_DIR="$RUN_DIR/logs"
TIMINGS_FILE="$LOG_DIR/timings.txt"
mkdir -p "$BIN_DIR" "$WHEEL_DIR" "$LOG_DIR"
ln -sfn "$RUN_DIR" "$ARTIFACT_ROOT/latest"

log() {
    printf '\n[%s] %s\n' "$(date +%H:%M:%S)" "$*"
}

require_cmd() {
    if ! command -v "$1" >/dev/null 2>&1; then
        printf 'Missing required tool: %s\n' "$1" >&2
        exit 1
    fi
}

run_step() {
    local label="$1"
    shift
    log "$label"
    local start end
    start=$(date +%s)
    "$@"
    end=$(date +%s)
    printf '%s\t%ss\n' "$label" "$((end - start))" >> "$TIMINGS_FILE"
}

detect_platform() {
    local uname_out
    uname_out="$(uname -s)"
    case "$uname_out" in
        Darwin) PLATFORM="mac" ;;
        Linux) PLATFORM="linux" ;;
        MINGW*|MSYS*|CYGWIN*) PLATFORM="windows" ;;
        *) PLATFORM="unknown" ;;
    esac
    ARCH="$(uname -m)"
    BIN_NAME="haforu"
    [[ "$PLATFORM" == "windows" ]] && BIN_NAME="haforu.exe"
    BUILD_DIR_NAME=$([[ "$PROFILE" == "release" ]] && echo "release" || echo "$PROFILE")
    SOURCE_BIN="$ROOT_DIR/target/$BUILD_DIR_NAME/$BIN_NAME"
    HAFORU_BIN="$BIN_DIR/$BIN_NAME"
    export HAFORU_BIN
}

resolve_targets() {
    TARGET_SET=()
    if [[ "$TARGETS" == "auto" ]]; then
        case "$PLATFORM" in
            mac) TARGET_SET=("universal2") ;;
            linux) TARGET_SET=("manylinux") ;;
            windows) TARGET_SET=("windows") ;;
        esac
    elif [[ "$TARGETS" == "all" ]]; then
        TARGET_SET=("universal2" "manylinux" "windows")
    else
        read -r -a TARGET_SET <<<"$TARGETS"
    fi
}

build_cli() {
    local args=(build --locked --bin haforu)
    if [[ "$PROFILE" == "release" ]]; then
        args+=(--release)
    else
        args+=(--profile "$PROFILE")
    fi
    run_step "cargo ${args[*]}" cargo "${args[@]}"
    if [[ ! -f "$SOURCE_BIN" ]]; then
        printf 'Unable to locate built binary at %s\n' "$SOURCE_BIN" >&2
        exit 1
    fi
    cp "$SOURCE_BIN" "$HAFORU_BIN"
    chmod +x "$HAFORU_BIN"
    log "CLI ready at $HAFORU_BIN"
}

build_wheels() {
    [[ "$SKIP_WHEELS" -eq 1 ]] && return
    if [[ "${#TARGET_SET[@]}" -eq 0 ]]; then
        log "No wheel targets selected for $PLATFORM; skipping wheel build."
        return
    fi
    mkdir -p "$WHEEL_DIR"
    local rel_out="/io${WHEEL_DIR#$ROOT_DIR}"
    for target in "${TARGET_SET[@]}"; do
        case "$target" in
            universal2)
                run_step "maturin universal2" \
                    uvx maturin build --release --target universal2-apple-darwin \
                    --features python --out "$WHEEL_DIR"
                ;;
            manylinux)
                if command -v docker >/dev/null 2>&1; then
                    run_step "maturin manylinux (docker)" \
                        docker run --rm -v "$ROOT_DIR":/io ghcr.io/pyo3/maturin \
                        build --release --features python --compatibility manylinux_2_28 \
                        --out "$rel_out"
                else
                    run_step "maturin manylinux host" \
                        uvx maturin build --release --features python \
                        --compatibility manylinux_2_28 --out "$WHEEL_DIR"
                fi
                ;;
            windows)
                run_step "maturin windows" \
                    uvx maturin build --release --features python --out "$WHEEL_DIR"
                ;;
            *)
                printf 'Unknown wheel target: %s\n' "$target" >&2
                exit 1
                ;;
        esac
    done
    log "Wheels stored in $WHEEL_DIR"
}

run_rust_tests() {
    [[ "$RUN_TESTS" -eq 0 ]] && return
    local args=(test --locked --workspace)
    if [[ "$PROFILE" == "release" ]]; then
        args+=(--release)
    else
        args+=(--profile "$PROFILE")
    fi
    run_step "cargo ${args[*]}" cargo "${args[@]}"
}

run_python_tests() {
    [[ "$RUN_TESTS" -eq 0 ]] && return
    run_step "uvx hatch test" uvx hatch test
}

run_smoke() {
    [[ "$RUN_SMOKE" -eq 0 ]] && return
    export HAFORU_BIN
    run_step "scripts/batch_smoke.sh" bash "$ROOT_DIR/scripts/batch_smoke.sh"
}

write_summary() {
    local summary="$LOG_DIR/summary.txt"
    {
        printf "timestamp=%s\n" "$RUN_STAMP"
        printf "profile=%s\n" "$PROFILE"
        printf "platform=%s\n" "$PLATFORM"
        printf "arch=%s\n" "$ARCH"
        printf "cli=%s\n" "$HAFORU_BIN"
        printf "wheels=%s\n" "$WHEEL_DIR"
        printf "tests=%s\n" "$([[ "$RUN_TESTS" -eq 1 ]] && echo on || echo off)"
        printf "smoke=%s\n" "$([[ "$RUN_SMOKE" -eq 1 ]] && echo on || echo off)"
    } >"$summary"
    log "Summary written to $summary"
    log "Timings recorded in $TIMINGS_FILE"
}

main() {
    require_cmd cargo
    require_cmd uvx
    detect_platform
    resolve_targets
    log "Haforu build start (profile=$PROFILE, platform=$PLATFORM, arch=$ARCH)"
    build_cli
    build_wheels
    run_rust_tests
    run_python_tests
    run_smoke
    write_summary
}

main "$@"
</document_content>
</document>

<document index="25">
<source>scripts/jobs_smoke.jsonl</source>
<document_content>
{"id":"smoke-1","font":{"path":"testdata/fonts/Arial-Black.ttf","size":1000,"variations":{}},"text":{"content":"Haforu"},"rendering":{"format":"pgm","encoding":"base64","width":256,"height":128}}
{"id":"smoke-2","font":{"path":"testdata/fonts/Arial-Black.ttf","size":1000,"variations":{}},"text":{"content":"Integration"},"rendering":{"format":"pgm","encoding":"base64","width":256,"height":128}}
{"id":"smoke-metrics","font":{"path":"testdata/fonts/Arial-Black.ttf","size":640,"variations":{}},"text":{"content":"Metrics"},"rendering":{"format":"metrics","encoding":"json","width":128,"height":128}}
{"id":"smoke-invalid","font":{"path":"testdata/fonts/Arial-Black.ttf","size":0,"variations":{"wght":1400}},"text":{"content":"Invalid"},"rendering":{"format":"pgm","encoding":"base64","width":256,"height":128}}

... (Data file content truncated to first 5 lines)
</document_content>
</document>

<document index="26">
<source>scripts/profile-cli.sh</source>
<document_content>
#!/usr/bin/env bash
# this_file: scripts/profile-cli.sh
#
# Profile haforu CLI hot paths:
# - Argument parsing overhead
# - JSON batch parsing
# - JSONL streaming throughput
# - Job validation
# - End-to-end rendering

set -euo pipefail

HAFORU_BIN="${HAFORU_BIN:-./target/release/haforu}"
TESTDATA="./testdata/fonts/Arial-Black.ttf"

echo "=== Profiling haforu CLI hot paths ==="
echo "Binary: $HAFORU_BIN"
echo "Test font: $TESTDATA"
echo

# Check for hyperfine
if ! command -v hyperfine &> /dev/null; then
    echo "Note: hyperfine not found, using basic timing instead"
    echo "Install with: brew install hyperfine"
    USE_HYPERFINE=0
else
    USE_HYPERFINE=1
fi

# 1. Argument parsing overhead
echo "## 1. Argument Parsing Overhead"
echo "Measuring help/version commands (startup + arg parsing only):"
echo

if [ $USE_HYPERFINE -eq 1 ]; then
    hyperfine --warmup 3 \
        "$HAFORU_BIN --help" \
        "$HAFORU_BIN --version" \
        "$HAFORU_BIN diagnostics --format json"
else
    for cmd in "--help" "--version" "diagnostics --format json"; do
        echo "Timing: $HAFORU_BIN $cmd"
        time $HAFORU_BIN $cmd > /dev/null
    done
fi

echo

# 2. JSON batch parsing
echo "## 2. JSON Batch Parsing (hot path: serde_json parse)"
echo "Measuring batch mode with varying input sizes:"
echo

# Create test jobs with different sizes
create_batch_jobs() {
    local count=$1
    echo '{"version":"1.0","jobs":['
    for i in $(seq 1 $count); do
        cat <<EOF
{"id":"job-$i","font":{"path":"$TESTDATA","size":256,"variations":{}},"text":{"content":"A","script":"Latn"},"rendering":{"format":"metrics","encoding":"json","width":64,"height":64}}$([ $i -lt $count ] && echo ",")
EOF
    done
    echo ']}'
}

for count in 1 10 100; do
    echo "Batch with $count jobs:"
    create_batch_jobs $count > /tmp/batch_$count.json

    if [ $USE_HYPERFINE -eq 1 ]; then
        hyperfine --warmup 2 --runs 10 \
            "$HAFORU_BIN batch < /tmp/batch_$count.json"
    else
        echo "Timing: $HAFORU_BIN batch < /tmp/batch_$count.json"
        time $HAFORU_BIN batch < /tmp/batch_$count.json > /dev/null
    fi
    echo
done

# 3. JSONL streaming parsing
echo "## 3. JSONL Streaming (hot path: line-by-line JSON parse + dispatch)"
echo "Measuring stream mode with varying line counts:"
echo

# Create JSONL test data
create_jsonl_jobs() {
    local count=$1
    for i in $(seq 1 $count); do
        echo '{"id":"job-'$i'","font":{"path":"'$TESTDATA'","size":256,"variations":{}},"text":{"content":"A","script":"Latn"},"rendering":{"format":"metrics","encoding":"json","width":64,"height":64}}'
    done
}

for count in 10 100 1000; do
    echo "JSONL stream with $count lines:"
    create_jsonl_jobs $count > /tmp/stream_$count.jsonl

    if [ $USE_HYPERFINE -eq 1 ]; then
        hyperfine --warmup 2 --runs 10 \
            "$HAFORU_BIN stream < /tmp/stream_$count.jsonl"
    else
        echo "Timing: $HAFORU_BIN stream < /tmp/stream_$count.jsonl"
        time $HAFORU_BIN stream < /tmp/stream_$count.jsonl > /dev/null
    fi
    echo
done

# 4. End-to-end rendering (with vs without image encoding)
echo "## 4. End-to-End Rendering Performance"
echo "Comparing metrics-only vs full PGM rendering:"
echo

# Metrics only (fast path)
echo "Metrics-only format:"
if [ $USE_HYPERFINE -eq 1 ]; then
    hyperfine --warmup 5 --runs 50 \
        "$HAFORU_BIN render -f $TESTDATA -s 256 -t A --format metrics"
else
    echo "Timing: $HAFORU_BIN render -f $TESTDATA -s 256 -t A --format metrics"
    time for i in {1..50}; do $HAFORU_BIN render -f $TESTDATA -s 256 -t A --format metrics > /dev/null; done
fi

echo

# PGM rendering (full path)
echo "PGM rendering format:"
if [ $USE_HYPERFINE -eq 1 ]; then
    hyperfine --warmup 5 --runs 50 \
        "$HAFORU_BIN render -f $TESTDATA -s 256 -t A --format pgm -o /tmp/test.pgm"
else
    echo "Timing: $HAFORU_BIN render -f $TESTDATA -s 256 -t A --format pgm -o /tmp/test.pgm"
    time for i in {1..50}; do $HAFORU_BIN render -f $TESTDATA -s 256 -t A --format pgm -o /tmp/test.pgm; done
fi

echo

# Summary
echo "=== Profile Complete ==="
echo
echo "Hot paths profiled:"
echo "1. Argument parsing - baseline CLI startup overhead"
echo "2. JSON batch parsing - serde_json deserialize throughput"
echo "3. JSONL streaming - line-by-line parse + job dispatch"
echo "4. End-to-end rendering - metrics vs PGM output comparison"
echo
echo "Next steps:"
echo "- Review results above for any outliers"
echo "- Use flamegraph/perf for deeper profiling if needed"
echo "- Add regression tests for critical paths"
</document_content>
</document>

<document index="27">
<source>scripts/regression-test.sh</source>
<document_content>
#!/usr/bin/env bash
# this_file: scripts/regression-test.sh
#
# Performance regression tests for haforu CLI
# Runs key performance benchmarks and compares against baseline thresholds
# Exit code 0 = pass, 1 = regression detected

set -euo pipefail

HAFORU_BIN="${HAFORU_BIN:-./target/release/haforu}"
TESTDATA="./testdata/fonts/Arial-Black.ttf"
BASELINE_FILE="${BASELINE_FILE:-.baseline-perf.json}"

# Color output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[0;33m'
NC='\033[0m' # No Color

echo "=== Performance Regression Tests ==="
echo "Binary: $HAFORU_BIN"
echo "Baseline: $BASELINE_FILE"
echo

# Check if binary exists
if [ ! -f "$HAFORU_BIN" ]; then
    echo -e "${RED}ERROR: Binary not found at $HAFORU_BIN${NC}"
    echo "Run: cargo build --release"
    exit 1
fi

# Check for hyperfine
if ! command -v hyperfine &> /dev/null; then
    echo -e "${YELLOW}WARNING: hyperfine not found${NC}"
    echo "Install with: brew install hyperfine"
    echo "Skipping regression tests"
    exit 0
fi

# Performance thresholds (in milliseconds)
# Based on profiling results from 2025-11-14
# Note: bash -c wrapper adds ~5-7ms overhead
THRESHOLD_HELP=10          # --help should be <10ms
THRESHOLD_BATCH_1=15       # 1 job batch should be <15ms (includes bash -c overhead)
THRESHOLD_STREAM_100=15    # 100 line stream should be <15ms (includes bash -c overhead)
THRESHOLD_METRICS=10       # Single metrics render should be <10ms

FAILED=0

# Helper function to run benchmark and check threshold
check_perf() {
    local name=$1
    local threshold=$2
    shift 2
    local cmd="$@"

    echo "Testing: $name"
    echo "  Command: $cmd"
    echo "  Threshold: ${threshold}ms"

    # Run hyperfine and extract mean time
    result=$(hyperfine --warmup 3 --runs 10 --export-json /tmp/bench.json "$cmd" 2>&1)
    mean_ms=$(jq '.results[0].mean * 1000' /tmp/bench.json)

    # Compare (bash doesn't have floating point, so use bc)
    passed=$(echo "$mean_ms < $threshold" | bc -l)

    if [ "$passed" -eq 1 ]; then
        echo -e "  ${GREEN}âœ“ PASS${NC} (${mean_ms}ms < ${threshold}ms)"
    else
        echo -e "  ${RED}âœ— FAIL${NC} (${mean_ms}ms >= ${threshold}ms)"
        FAILED=1
    fi
    echo
}

# Test 1: Argument parsing (--help)
check_perf "Argument parsing (--help)" $THRESHOLD_HELP \
    "$HAFORU_BIN --help"

# Test 2: Batch processing (1 job)
echo '{"version":"1.0","jobs":[{"id":"test","font":{"path":"'$TESTDATA'","size":256,"variations":{}},"text":{"content":"A","script":"Latn"},"rendering":{"format":"metrics","encoding":"json","width":64,"height":64}}]}' > /tmp/batch_1.json
check_perf "Batch processing (1 job)" $THRESHOLD_BATCH_1 \
    "bash -c '$HAFORU_BIN batch < /tmp/batch_1.json'"

# Test 3: JSONL streaming (100 lines)
for i in $(seq 1 100); do
    echo '{"id":"job-'$i'","font":{"path":"'$TESTDATA'","size":256,"variations":{}},"text":{"content":"A","script":"Latn"},"rendering":{"format":"metrics","encoding":"json","width":64,"height":64}}'
done > /tmp/stream_100.jsonl
check_perf "JSONL streaming (100 lines)" $THRESHOLD_STREAM_100 \
    "bash -c '$HAFORU_BIN stream < /tmp/stream_100.jsonl'"

# Test 4: Single metrics render
check_perf "Metrics rendering (single glyph)" $THRESHOLD_METRICS \
    "$HAFORU_BIN render -f $TESTDATA -s 256 -t A --format metrics"

# Summary
echo "=== Regression Test Summary ==="
if [ $FAILED -eq 0 ]; then
    echo -e "${GREEN}âœ“ All tests passed!${NC}"
    exit 0
else
    echo -e "${RED}âœ— Performance regression detected!${NC}"
    echo
    echo "Some benchmarks exceeded their thresholds."
    echo "This may indicate a performance regression."
    echo
    echo "Next steps:"
    echo "1. Review recent changes for performance impact"
    echo "2. Run 'scripts/profile-cli.sh' for detailed profiling"
    echo "3. Use flamegraph/perf for deep analysis if needed"
    exit 1
fi
</document_content>
</document>

<document index="28">
<source>scripts/run.sh</source>
<document_content>
#!/usr/bin/env bash
# this_file: scripts/run.sh

set -euo pipefail

ROOT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")/.." && pwd)"
JOBS_FILE="${JOBS_FILE:-$ROOT_DIR/scripts/jobs_smoke.jsonl}"
HAFORU_BIN="${HAFORU_BIN:-$ROOT_DIR/target/release/haforu}"
PYTHON_BIN="${PYTHON_BIN:-python3}"
CONVERTER_PY="${CONVERTER_PY:-python3}"
MODE="${1:-smoke}"

RUN_LOG_DIR="$ROOT_DIR/target/run-log"
RUN_STAMP="$(date +%Y%m%d-%H%M%S)"
RUN_LOG="$RUN_LOG_DIR/$MODE-$RUN_STAMP.log"
TIMINGS_FILE="$RUN_LOG_DIR/$MODE-$RUN_STAMP.timings"
TMP_DIR="$(mktemp -d)"
trap 'rm -rf "$TMP_DIR"' EXIT
mkdir -p "$RUN_LOG_DIR"
touch "$RUN_LOG" "$TIMINGS_FILE"

log() {
    local line="[$(date +%H:%M:%S)] $*"
    printf '\n%s\n' "$line"
    printf '%s\n' "$line" >> "$RUN_LOG"
}

require_file() {
    if [[ ! -f "$1" ]]; then
        printf 'Missing file: %s\n' "$1" >&2
        exit 1
    fi
}

ensure_cli() {
    if [[ -x "$HAFORU_BIN" ]]; then
        return
    fi
    log "haforu binary not found at $HAFORU_BIN, building release binary"
    (cd "$ROOT_DIR" && cargo build --release >/dev/null)
    HAFORU_BIN="$ROOT_DIR/target/release/haforu"
    export HAFORU_BIN
}

convert_jobs() {
    local mode="$1"
    local dest="$2"
    "$CONVERTER_PY" - "$JOBS_FILE" "$mode" "$dest" <<'PY'
import json, sys
from pathlib import Path

src = Path(sys.argv[1])
mode = sys.argv[2]
dest = Path(sys.argv[3])
jobs = []
for line in src.read_text().splitlines():
    line = line.strip()
    if not line:
        continue
    job = json.loads(line)
    fmt = job.get("rendering", {}).get("format")
    if mode == "metrics" and fmt != "metrics":
        continue
    if mode == "nonmetrics" and fmt == "metrics":
        continue
    jobs.append(job)
dest.write_text(json.dumps({"version": "1.0", "jobs": jobs}))
PY
}

summarize_jobs() {
    local label="$1"
    local file="$2"
    "$CONVERTER_PY" - "$file" "$label" <<'PY'
import json, sys
from pathlib import Path

path = Path(sys.argv[1])
label = sys.argv[2]
print(f"{label} summaries:")
for line in path.read_text().splitlines():
    line = line.strip()
    if not line:
        continue
    job = json.loads(line)
    status = job.get("status")
    job_id = job.get("id")
    metrics = job.get("metrics")
    err = job.get("error")
    if metrics:
        metrics_text = f"density={metrics.get('density'):.3f}, beam={metrics.get('beam'):.3f}"
        print(f"  {job_id}: {status} ({metrics_text})")
    elif err:
        print(f"  {job_id}: {status} -> {err}")
    else:
        fmt = job.get("rendering", {}).get("format")
        print(f"  {job_id}: {status} ({fmt})")
PY
}

summarize_stream() {
    local file="$1"
    "$CONVERTER_PY" - "$file" <<'PY'
import json, sys
from pathlib import Path

path = Path(sys.argv[1])
print("Streaming summaries:")
for line in path.read_text().splitlines():
    line = line.strip()
    if not line:
        continue
    job = json.loads(line)
    job_id = job.get("id")
    status = job.get("status")
    err = job.get("error")
    if err:
        print(f"  {job_id}: {status} -> {err}")
    else:
        print(f"  {job_id}: {status}")
PY
}

run_cli() {
    local label="$1"
    local input="$2"
    local output="$3"
    shift 3
    log "$label"
    local start end
    start=$(date +%s)
    if [[ -n "$input" ]]; then
        "$HAFORU_BIN" "$@" < "$input" > "$output"
    else
        "$HAFORU_BIN" "$@" > "$output"
    fi
    end=$(date +%s)
    printf '%s\t%ss\n' "$label" "$((end - start))" >> "$TIMINGS_FILE"
}

batch_demo() {
    local batch_json="$TMP_DIR/batch.json"
    local output="$TMP_DIR/batch.out"
    convert_jobs all "$batch_json"
    run_cli "haforu batch (jobs_smoke)" "$batch_json" "$output" batch
    summarize_jobs "Batch" "$output" | tee -a "$RUN_LOG"
}

metrics_demo() {
    local metrics_json="$TMP_DIR/metrics.json"
    local output="$TMP_DIR/metrics.out"
    convert_jobs metrics "$metrics_json"
    run_cli "haforu batch (metrics only)" "$metrics_json" "$output" batch
    summarize_jobs "Metrics" "$output" | tee -a "$RUN_LOG"
}

stream_demo() {
    local output="$TMP_DIR/stream.out"
    run_cli "haforu stream (jobs_smoke)" "$JOBS_FILE" "$output" stream
    summarize_stream "$output" | tee -a "$RUN_LOG"
}

python_demo() {
    log "Python StreamingSession demo"
    if ! "$PYTHON_BIN" -c "import haforu" >/dev/null 2>&1; then
        log "haforu Python module not found for $PYTHON_BIN; skip demo (install the wheel first)."
        return
    fi
    local status
    "$PYTHON_BIN" - "$JOBS_FILE" <<'PY' | tee -a "$RUN_LOG"
import json, sys, haforu, pathlib

jobs = [json.loads(line) for line in pathlib.Path(sys.argv[1]).read_text().splitlines() if line.strip()]
first = jobs[0]
print(f"haforu {haforu.__version__}, available={haforu.is_available()}")
session = haforu.StreamingSession(max_fonts=8, max_glyphs=128)
session.warm_up()
result = json.loads(session.render(json.dumps(first)))
print(f"session render -> {result['id']} {result['status']}")
session.close()
PY
    status=${PIPESTATUS[0]}
    if [[ $status -ne 0 ]]; then
        exit $status
    fi
}

smoke_suite() {
    ensure_cli
    batch_demo
    metrics_demo
    stream_demo
}

main() {
    require_file "$JOBS_FILE"
    case "$MODE" in
        smoke)
            smoke_suite
            ;;
        batch)
            ensure_cli
            batch_demo
            ;;
        metrics)
            ensure_cli
            metrics_demo
            ;;
        stream)
            ensure_cli
            stream_demo
            ;;
        python)
            python_demo
            ;;
        all)
            smoke_suite
            python_demo
            ;;
        *)
            printf 'Usage: %s [smoke|batch|metrics|stream|python|all]\n' "$0"
            exit 1
            ;;
    esac
    log "Run artifacts: $RUN_LOG (timings: $TIMINGS_FILE)"
}

main
</document_content>
</document>

<document index="29">
<source>scripts/sync-version.sh</source>
<document_content>
#!/usr/bin/env bash
# this_file: scripts/sync-version.sh

set -euo pipefail

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
NC='\033[0m' # No Color

echo -e "${GREEN}===== Version Sync Script =====${NC}"
echo ""

# Get version from git tag or provide default
if git describe --tags --exact-match 2>/dev/null; then
    VERSION=$(git describe --tags --exact-match | sed 's/^v//')
    echo -e "${GREEN}Found git tag: v$VERSION${NC}"
else
    # Try to get from most recent tag
    if git describe --tags --abbrev=0 2>/dev/null; then
        LAST_TAG=$(git describe --tags --abbrev=0 | sed 's/^v//')
        # Count commits since last tag
        COMMITS_SINCE=$(git rev-list $(git describe --tags --abbrev=0)..HEAD --count)

        if [ "$COMMITS_SINCE" -gt 0 ]; then
            # Development version
            VERSION="${LAST_TAG}.dev${COMMITS_SINCE}"
            echo -e "${YELLOW}No exact tag, using development version: $VERSION${NC}"
        else
            VERSION="$LAST_TAG"
            echo -e "${GREEN}Using most recent tag: v$VERSION${NC}"
        fi
    else
        VERSION="0.0.0.dev"
        echo -e "${YELLOW}No tags found, using default: $VERSION${NC}"
    fi
fi

echo ""
echo "Syncing version: $VERSION"
echo ""

# Update Cargo.toml
if [ -f "Cargo.toml" ]; then
    echo "Updating Cargo.toml..."

    # Create backup
    cp Cargo.toml Cargo.toml.bak

    # Update version line
    if [[ "$OSTYPE" == "darwin"* ]]; then
        # macOS
        sed -i '' "s/^version = \".*\"/version = \"$VERSION\"/" Cargo.toml
    else
        # Linux
        sed -i "s/^version = \".*\"/version = \"$VERSION\"/" Cargo.toml
    fi

    echo -e "${GREEN}âœ“ Updated Cargo.toml${NC}"
else
    echo -e "${RED}âœ— Cargo.toml not found${NC}"
fi

# Check if pyproject.toml uses dynamic versioning
if [ -f "pyproject.toml" ]; then
    if grep -q "dynamic.*version" pyproject.toml; then
        echo "Python version is managed by hatch-vcs (dynamic)"
        echo -e "${GREEN}âœ“ pyproject.toml uses git-based versioning${NC}"
    else
        echo -e "${YELLOW}Warning: pyproject.toml doesn't use dynamic versioning${NC}"
        echo "Consider adding: dynamic = [\"version\"]"
    fi
fi

echo ""
echo "Version sync complete!"
echo ""
echo "Current versions:"
echo "  Git tag:     $(git describe --tags --abbrev=0 2>/dev/null || echo 'none')"
echo "  Cargo.toml:  $(grep '^version = ' Cargo.toml | head -1 | cut -d'"' -f2)"

if [ -f "python/haforu/__init__.py" ]; then
    if grep -q "__version__" python/haforu/__init__.py 2>/dev/null; then
        echo "  Python:      $(grep '__version__' python/haforu/__init__.py | cut -d'"' -f2 || echo 'dynamic')"
    else
        echo "  Python:      dynamic (from git tags via hatch-vcs)"
    fi
fi

echo ""
echo "To create a new release:"
echo "  1. git tag v$VERSION"
echo "  2. git push --tags"
echo "  3. GitHub Actions will build and publish automatically"
echo ""

# Cleanup backup
if [ -f "Cargo.toml.bak" ]; then
    rm Cargo.toml.bak
fi
</document_content>
</document>

<document index="30">
<source>scripts/test-cli-parity.sh</source>
<document_content>
#!/usr/bin/env bash
# this_file: scripts/test-cli-parity.sh
#
# Test Python Fire CLI parity with Rust CLI
# Verifies that both CLIs expose the same functionality

set -uo pipefail

RUST_CLI="${HAFORU_BIN:-./target/release/haforu}"
PYTHON_CLI="python -m haforu"
TESTDATA="./testdata/fonts/Arial-Black.ttf"

# Colors
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[0;33m'
NC='\033[0m'

echo "=== Testing CLI Parity: Rust vs Python Fire ==="
echo "Rust CLI: $RUST_CLI"
echo "Python CLI: $PYTHON_CLI"
echo

PASSED=0
FAILED=0

# Helper function to test command availability
test_command() {
    local cli=$1
    local cmd=$2
    local description=$3

    echo -n "Testing $description... "

    set +e
    if [[ "$cli" == *"python"* ]]; then
        $cli $cmd --help >/dev/null 2>&1
    else
        $cli $cmd --help >/dev/null 2>&1
    fi
    local exit_code=$?
    set -e

    if [[ $exit_code -eq 0 ]]; then
        echo -e "${GREEN}âœ“${NC}"
        PASSED=$((PASSED + 1))
        return 0
    else
        echo -e "${RED}âœ—${NC}"
        FAILED=$((FAILED + 1))
        return 1
    fi
}

# Test command availability
echo "## 1. Command Availability"
echo

# Rust CLI commands
rust_commands=(
    "batch:Batch processing"
    "stream:Streaming mode"
    "validate:Job validation"
    "version:Version display"
    "diagnostics:System diagnostics"
    "render:Single render"
)

# Python CLI commands (should match Rust)
python_commands=(
    "batch:Batch processing"
    "stream:Streaming mode"
    "validate:Job validation"
    "version:Version display"
    "diagnostics:System diagnostics"
    "render:Single render"
    "metrics:Metrics computation"
)

for cmd_desc in "${rust_commands[@]}"; do
    IFS=':' read -r cmd desc <<< "$cmd_desc"
    test_command "$RUST_CLI" "$cmd" "Rust: $desc"
done

echo

for cmd_desc in "${python_commands[@]}"; do
    IFS=':' read -r cmd desc <<< "$cmd_desc"
    test_command "$PYTHON_CLI" "$cmd" "Python: $desc"
done

echo

# Test functional equivalence
echo "## 2. Functional Equivalence Tests"
echo

# Test 2.1: Version command
echo -n "Testing version command output... "
rust_version=$($RUST_CLI version 2>&1 | head -1 || true)
python_version=$($PYTHON_CLI version 2>&1 | grep -v "INFO:" | head -1 || true)

if [[ -n "$rust_version" ]] && [[ -n "$python_version" ]]; then
    echo -e "${GREEN}âœ“${NC}"
    echo "  Rust:   $rust_version"
    echo "  Python: $python_version"
    PASSED=$((PASSED + 1))
else
    echo -e "${RED}âœ—${NC}"
    FAILED=$((FAILED + 1))
fi
echo

# Test 2.2: Diagnostics JSON output
echo -n "Testing diagnostics JSON output... "
rust_diag=$($RUST_CLI diagnostics --format json 2>&1 | grep -v "^$" || true)
python_diag=$($PYTHON_CLI diagnostics --format json 2>&1 | grep -v "INFO:" | grep -v "^$" || true)

if echo "$rust_diag" | jq . >/dev/null 2>&1 && echo "$python_diag" | jq . >/dev/null 2>&1; then
    echo -e "${GREEN}âœ“${NC}"
    PASSED=$((PASSED + 1))
else
    echo -e "${RED}âœ—${NC}"
    FAILED=$((FAILED + 1))
fi
echo

# Test 2.3: Validate command
echo -n "Testing validate command... "
cat > /tmp/test_job.json <<EOF
{
  "version": "1.0",
  "jobs": [{
    "id": "test",
    "font": {"path": "$TESTDATA", "size": 256, "variations": {}},
    "text": {"content": "A"},
    "rendering": {"format": "metrics", "encoding": "json", "width": 64, "height": 64}
  }]
}
EOF

rust_validate_exit=0
$RUST_CLI validate < /tmp/test_job.json >/dev/null 2>&1 || rust_validate_exit=$?

python_validate_exit=0
$PYTHON_CLI validate < /tmp/test_job.json 2>&1 | grep -v "INFO:" >/dev/null || python_validate_exit=$?

if [[ $rust_validate_exit -eq 0 ]] && [[ $python_validate_exit -eq 0 ]]; then
    echo -e "${GREEN}âœ“${NC}"
    PASSED=$((PASSED + 1))
else
    echo -e "${RED}âœ—${NC}"
    echo "  Rust exit: $rust_validate_exit"
    echo "  Python exit: $python_validate_exit"
    FAILED=$((FAILED + 1))
fi
echo

# Test 2.4: Batch processing
echo -n "Testing batch command... "
rust_batch_output=$($RUST_CLI batch < /tmp/test_job.json 2>/dev/null | grep -v "^$" || true)
python_batch_output=$($PYTHON_CLI batch < /tmp/test_job.json 2>&1 | grep -v "INFO:" | grep -v "^$" || true)

rust_batch_valid=0
python_batch_valid=0

if echo "$rust_batch_output" | jq . >/dev/null 2>&1; then
    rust_batch_valid=1
fi

if echo "$python_batch_output" | jq . >/dev/null 2>&1; then
    python_batch_valid=1
fi

if [[ $rust_batch_valid -eq 1 ]] && [[ $python_batch_valid -eq 1 ]]; then
    echo -e "${GREEN}âœ“${NC}"
    PASSED=$((PASSED + 1))
else
    echo -e "${RED}âœ—${NC}"
    echo "  Rust valid: $rust_batch_valid"
    echo "  Python valid: $python_batch_valid"
    FAILED=$((FAILED + 1))
fi
echo

# Test 2.5: Stream mode
echo -n "Testing stream command... "
echo '{"id":"test","font":{"path":"'$TESTDATA'","size":256,"variations":{}},"text":{"content":"A"},"rendering":{"format":"metrics","encoding":"json","width":64,"height":64}}' > /tmp/test_stream.jsonl

rust_stream_output=$($RUST_CLI stream < /tmp/test_stream.jsonl 2>/dev/null | grep -v "^$" || true)
python_stream_output=$($PYTHON_CLI stream < /tmp/test_stream.jsonl 2>&1 | grep -v "INFO:" | grep -v "^$" || true)

rust_stream_valid=0
python_stream_valid=0

if echo "$rust_stream_output" | jq . >/dev/null 2>&1; then
    rust_stream_valid=1
fi

if echo "$python_stream_output" | jq . >/dev/null 2>&1; then
    python_stream_valid=1
fi

if [[ $rust_stream_valid -eq 1 ]] && [[ $python_stream_valid -eq 1 ]]; then
    echo -e "${GREEN}âœ“${NC}"
    PASSED=$((PASSED + 1))
else
    echo -e "${RED}âœ—${NC}"
    echo "  Rust valid: $rust_stream_valid"
    echo "  Python valid: $python_stream_valid"
    FAILED=$((FAILED + 1))
fi
echo

# Test 2.6: Render command (metrics mode)
echo -n "Testing render command (metrics mode)... "
rust_render=$($RUST_CLI render -f $TESTDATA -s 256 -t A --format metrics 2>&1 | grep -v "^$" || true)
python_render=$($PYTHON_CLI render --font $TESTDATA --size 256 --text A --format metrics 2>&1 | grep -v "INFO:" | grep -v "^$" || true)

# Both should output density/beam metrics
if echo "$rust_render" | grep -q "density" && echo "$python_render" | grep -q "Density"; then
    echo -e "${GREEN}âœ“${NC}"
    PASSED=$((PASSED + 1))
else
    echo -e "${RED}âœ—${NC}"
    FAILED=$((FAILED + 1))
fi
echo

# Test 2.7: Cache knobs (batch mode)
echo -n "Testing cache knobs (--max-fonts, --max-glyphs)... "
rust_cache=$($RUST_CLI batch --max-fonts 128 --max-glyphs 1024 < /tmp/test_job.json 2>/dev/null || true)
python_cache=$($PYTHON_CLI batch --max_fonts 128 --max_glyphs 1024 < /tmp/test_job.json 2>&1 | grep -v "INFO:" || true)

# Both should succeed
if echo "$rust_cache" | jq . >/dev/null 2>&1 && echo "$python_cache" | jq . >/dev/null 2>&1; then
    echo -e "${GREEN}âœ“${NC}"
    PASSED=$((PASSED + 1))
else
    echo -e "${RED}âœ—${NC}"
    FAILED=$((FAILED + 1))
fi
echo

# Summary
echo "=== CLI Parity Test Summary ==="
echo -e "Passed: ${GREEN}$PASSED${NC}"
echo -e "Failed: ${RED}$FAILED${NC}"
echo

if [[ $FAILED -eq 0 ]]; then
    echo -e "${GREEN}âœ“ All parity tests passed!${NC}"
    echo
    echo "Python Fire CLI successfully mirrors Rust CLI functionality."
    echo "Both CLIs can be used interchangeably."
    exit 0
else
    echo -e "${RED}âœ— Some parity tests failed!${NC}"
    echo
    echo "Review the failures above and update the Python CLI to match Rust CLI."
    exit 1
fi
</document_content>
</document>

# File: /Users/adam/Developer/vcs/github.fontlaborg/haforu/smoke_test.rs
# Language: rust



# File: /Users/adam/Developer/vcs/github.fontlaborg/haforu/src/batch.rs
# Language: rust

mod tests;

struct JobSpec {
}

struct Job {
}

struct FontConfig {
}

struct TextConfig {
}

struct RenderingConfig {
}

struct JobResult {
}

struct RenderingOutput {
}

struct MetricsOutput {
}

struct TimingInfo {
}

struct MemoryInfo {
}

struct FontResult {
}


# File: /Users/adam/Developer/vcs/github.fontlaborg/haforu/src/cache.rs
# Language: rust

mod tests;

struct GlyphCacheKey {
}

struct GlyphCacheStats {
}

struct GlyphCache {
}


# File: /Users/adam/Developer/vcs/github.fontlaborg/haforu/src/error.rs
# Language: rust

mod tests;


# File: /Users/adam/Developer/vcs/github.fontlaborg/haforu/src/fonts.rs
# Language: rust

mod tests;

struct FontLoader {
}

struct CacheStats {
}

struct FontInstance {
}

struct FontCacheKey {
}


# File: /Users/adam/Developer/vcs/github.fontlaborg/haforu/src/input.rs
# Language: rust

mod tests;


# File: /Users/adam/Developer/vcs/github.fontlaborg/haforu/src/lib.rs
# Language: rust

mod batch;

mod cache;

mod error;

mod fonts;

mod output;

mod render;

mod security;

mod shaping;

mod python;

mod tests;

struct ExecutionOptions {
}


# File: /Users/adam/Developer/vcs/github.fontlaborg/haforu/src/main.rs
# Language: rust

mod input;

mod tests;

struct Cli {
}

struct DiagnosticsReport {
}

struct BatchStatsReport {
}

struct StreamStatsReport {
}

struct StreamCounters {
}

struct BatchRunSummary {
}


# File: /Users/adam/Developer/vcs/github.fontlaborg/haforu/src/output.rs
# Language: rust

mod tests;

struct ImageOutput {
}


# File: /Users/adam/Developer/vcs/github.fontlaborg/haforu/src/python/batch.rs
# Language: rust

mod tests;

struct ProcessJobsIterator {
}


# File: /Users/adam/Developer/vcs/github.fontlaborg/haforu/src/python/errors.rs
# Language: rust

mod tests;

struct ErrorConverter {
}


# File: /Users/adam/Developer/vcs/github.fontlaborg/haforu/src/python/mod.rs
# Language: rust

mod batch;

mod errors;

mod streaming;

mod types;

mod tests;


# File: /Users/adam/Developer/vcs/github.fontlaborg/haforu/src/python/streaming.rs
# Language: rust

mod tests;

struct StreamingSession {
}


# File: /Users/adam/Developer/vcs/github.fontlaborg/haforu/src/python/types.rs
# Language: rust



# File: /Users/adam/Developer/vcs/github.fontlaborg/haforu/src/render.rs
# Language: rust

mod tests;

struct Image {
}

struct GlyphRasterizer {
}

struct ZenoPen {
}


# File: /Users/adam/Developer/vcs/github.fontlaborg/haforu/src/security.rs
# Language: rust

struct TimeoutGuard {
}


# File: /Users/adam/Developer/vcs/github.fontlaborg/haforu/src/shaping.rs
# Language: rust

mod tests;

struct ShapedText {
}

struct ShapedGlyph {
}

struct ShapeRequest {
}

struct TextShaper {
}


# File: /Users/adam/Developer/vcs/github.fontlaborg/haforu/tests/__init__.py
# Language: python



# File: /Users/adam/Developer/vcs/github.fontlaborg/haforu/tests/cli_stats.rs
# Language: rust



# File: /Users/adam/Developer/vcs/github.fontlaborg/haforu/tests/test_batch.py
# Language: python

from python.tests.test_batch import *


# File: /Users/adam/Developer/vcs/github.fontlaborg/haforu/tests/test_errors.py
# Language: python

from python.tests.test_errors import *


# File: /Users/adam/Developer/vcs/github.fontlaborg/haforu/tests/test_numpy.py
# Language: python

from python.tests.test_numpy import *


# File: /Users/adam/Developer/vcs/github.fontlaborg/haforu/tests/test_streaming.py
# Language: python

from python.tests.test_streaming import *


</documents>